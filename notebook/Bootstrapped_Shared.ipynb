{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from models.BootstrappedNN import BootstrappedNN\n",
    "from utils.plot import plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils.gen_data import gen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_x, data_y = gen_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-4, 4, 100)\n",
    "bst= BootstrappedNN(num_models=15, num_epochs=200, batch_size=32, bootstrapped_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "shared (Dense)               (None, 64)                128       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "pred (Dense)                 (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,241\n",
      "Trainable params: 2,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 571us/step - loss: 48.2921 - val_loss: 32.3377\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 21.2928 - val_loss: 11.9511\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 8.1997 - val_loss: 8.7039\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.9505 - val_loss: 8.8137\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.9000 - val_loss: 8.4797\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.8445 - val_loss: 8.4372\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.8153 - val_loss: 8.4284\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 6.8158 - val_loss: 8.4031\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.7754 - val_loss: 8.2862\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.7645 - val_loss: 8.3370\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.7603 - val_loss: 8.3146\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.7462 - val_loss: 8.2423\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.7562 - val_loss: 8.1253\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.7128 - val_loss: 8.2525\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 6.6650 - val_loss: 8.1250\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 6.6418 - val_loss: 8.1081\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 6.6364 - val_loss: 7.9958\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 6.6244 - val_loss: 8.0084\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 6.5607 - val_loss: 7.9062\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 6.5716 - val_loss: 8.0162\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 6.5119 - val_loss: 7.8470\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.5232 - val_loss: 7.8507\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.5591 - val_loss: 7.6869\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.4014 - val_loss: 7.7728\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 6.4009 - val_loss: 7.7217\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 91us/step - loss: 6.3632 - val_loss: 7.6637\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 6.3265 - val_loss: 7.5670\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.2918 - val_loss: 7.6147\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.1951 - val_loss: 7.4066\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 6.2054 - val_loss: 7.3482\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 6.1758 - val_loss: 7.4681\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 6.1310 - val_loss: 7.1495\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 6.0495 - val_loss: 7.2752\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 5.9668 - val_loss: 7.0012\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 5.8972 - val_loss: 6.9189\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 5.8460 - val_loss: 6.9537\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 5.7788 - val_loss: 6.7317\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 5.6905 - val_loss: 6.7403\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 5.6524 - val_loss: 6.6176\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 5.5503 - val_loss: 6.4484\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 5.4753 - val_loss: 6.3981\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 5.4293 - val_loss: 6.1006\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 91us/step - loss: 5.3957 - val_loss: 6.2762\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 5.2350 - val_loss: 5.8909\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 5.1494 - val_loss: 5.8686\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 5.0685 - val_loss: 5.7015\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 91us/step - loss: 4.9730 - val_loss: 5.5040\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 4.8465 - val_loss: 5.6070\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 4.7634 - val_loss: 5.2002\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 91us/step - loss: 4.6578 - val_loss: 5.0521\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 4.5527 - val_loss: 5.0167\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 4.4419 - val_loss: 4.7543\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 4.3264 - val_loss: 4.6101\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 4.2383 - val_loss: 4.4950\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 4.1054 - val_loss: 4.2213\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 4.0226 - val_loss: 4.1556\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 3.9169 - val_loss: 4.0426\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 3.8258 - val_loss: 3.7256\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 3.6701 - val_loss: 3.7052\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 3.5973 - val_loss: 3.5375\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 3.5400 - val_loss: 3.3770\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 3.4306 - val_loss: 3.2658\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 3.3567 - val_loss: 3.1253\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 3.2797 - val_loss: 3.0115\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 91us/step - loss: 3.1735 - val_loss: 2.9754\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 3.1250 - val_loss: 2.9263\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 3.0686 - val_loss: 2.8790\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.9997 - val_loss: 2.6710\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.9855 - val_loss: 2.5867\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 91us/step - loss: 2.9286 - val_loss: 2.5593\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.8769 - val_loss: 2.5360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.8290 - val_loss: 2.5146\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.8252 - val_loss: 2.4436\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 105us/step - loss: 2.7786 - val_loss: 2.3553\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.7586 - val_loss: 2.3273\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 106us/step - loss: 2.7480 - val_loss: 2.3015\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 106us/step - loss: 2.7111 - val_loss: 2.3075\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 107us/step - loss: 2.7215 - val_loss: 2.2287\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 110us/step - loss: 2.6962 - val_loss: 2.2285\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 109us/step - loss: 2.6670 - val_loss: 2.2425\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 108us/step - loss: 2.6500 - val_loss: 2.1926\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 105us/step - loss: 2.6305 - val_loss: 2.1979\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.6189 - val_loss: 2.1309\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.6043 - val_loss: 2.2086\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 91us/step - loss: 2.6272 - val_loss: 2.1328\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.5978 - val_loss: 2.1256\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.6942 - val_loss: 2.0763\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.6175 - val_loss: 2.0844\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.5457 - val_loss: 2.0689\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.5600 - val_loss: 2.1223\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.5394 - val_loss: 2.0345\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.5266 - val_loss: 2.0208\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.5297 - val_loss: 2.0044\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.5135 - val_loss: 2.0288\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.4930 - val_loss: 2.0143\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.5020 - val_loss: 1.9861\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.4953 - val_loss: 1.9889\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.4699 - val_loss: 2.0026\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.4699 - val_loss: 1.9650\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.4698 - val_loss: 1.9425\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.4776 - val_loss: 1.9488\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.4606 - val_loss: 1.9420\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.4398 - val_loss: 1.9279\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.4671 - val_loss: 1.9413\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 105us/step - loss: 2.4906 - val_loss: 1.9549\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 110us/step - loss: 2.4381 - val_loss: 1.9097\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 109us/step - loss: 2.4352 - val_loss: 1.9084\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 106us/step - loss: 2.4501 - val_loss: 1.9200\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 113us/step - loss: 2.4401 - val_loss: 1.9015\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 113us/step - loss: 2.4320 - val_loss: 1.9106\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 111us/step - loss: 2.4274 - val_loss: 1.8986\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 108us/step - loss: 2.4174 - val_loss: 1.8829\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 107us/step - loss: 2.4055 - val_loss: 1.8765\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 108us/step - loss: 2.4046 - val_loss: 1.9471\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 110us/step - loss: 2.4403 - val_loss: 1.9007\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 109us/step - loss: 2.4077 - val_loss: 1.8855\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 112us/step - loss: 2.4000 - val_loss: 1.8859\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 105us/step - loss: 2.3800 - val_loss: 1.8764\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 104us/step - loss: 2.3864 - val_loss: 1.8520\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 107us/step - loss: 2.4082 - val_loss: 1.8599\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 105us/step - loss: 2.3801 - val_loss: 1.8868\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 109us/step - loss: 2.4009 - val_loss: 1.8657\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 112us/step - loss: 2.4016 - val_loss: 1.8513\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 110us/step - loss: 2.3863 - val_loss: 1.8391\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 120us/step - loss: 2.3556 - val_loss: 1.8444\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 108us/step - loss: 2.3572 - val_loss: 1.8472\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 113us/step - loss: 2.3749 - val_loss: 1.9097\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 107us/step - loss: 2.3916 - val_loss: 1.8464\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 106us/step - loss: 2.3755 - val_loss: 1.8360\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 107us/step - loss: 2.3950 - val_loss: 1.8374\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 112us/step - loss: 2.4094 - val_loss: 1.8659\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 112us/step - loss: 2.3897 - val_loss: 1.8829\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 114us/step - loss: 2.3692 - val_loss: 1.8406\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 114us/step - loss: 2.3364 - val_loss: 1.8494\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 114us/step - loss: 2.4179 - val_loss: 1.8596\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 115us/step - loss: 2.3685 - val_loss: 1.8247\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 111us/step - loss: 2.3891 - val_loss: 1.8258\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 113us/step - loss: 2.4098 - val_loss: 1.8436\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 108us/step - loss: 2.3332 - val_loss: 1.8352\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 108us/step - loss: 2.3513 - val_loss: 1.8468\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 116us/step - loss: 2.3626 - val_loss: 1.8330\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 118us/step - loss: 2.3654 - val_loss: 1.8661\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 122us/step - loss: 2.3410 - val_loss: 1.8213\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.3152 - val_loss: 1.8303\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.3278 - val_loss: 1.8370\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 2.3808 - val_loss: 1.8323\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.3311 - val_loss: 1.8263\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 2.3246 - val_loss: 1.8239\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.3386 - val_loss: 1.8233\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 143us/step - loss: 2.3515 - val_loss: 1.8151\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.3270 - val_loss: 1.8785\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 134us/step - loss: 2.3234 - val_loss: 1.8203\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.3154 - val_loss: 1.8055\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.3275 - val_loss: 1.8938\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 2.3301 - val_loss: 1.8170\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.3183 - val_loss: 1.8588\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.3068 - val_loss: 1.8084\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.3248 - val_loss: 1.8034\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.3375 - val_loss: 1.8568\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.3323 - val_loss: 1.7946\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.3263 - val_loss: 1.8166\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.3278 - val_loss: 1.8191\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.3693 - val_loss: 1.8120\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 2.3282 - val_loss: 1.8088\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.3237 - val_loss: 1.8606\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.3515 - val_loss: 1.8179\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 2.3050 - val_loss: 1.8247\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.3261 - val_loss: 1.7928\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 134us/step - loss: 2.3191 - val_loss: 1.7973\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.3307 - val_loss: 1.8273\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.3061 - val_loss: 1.8041\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.2875 - val_loss: 1.7978\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 2.2903 - val_loss: 1.7931\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.2966 - val_loss: 1.7967\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.2993 - val_loss: 1.8003\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 134us/step - loss: 2.2866 - val_loss: 1.8387\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 2.3196 - val_loss: 1.8079\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.2821 - val_loss: 1.7882\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.2999 - val_loss: 1.7949\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.2859 - val_loss: 1.8029\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 2.3051 - val_loss: 1.7876\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.3006 - val_loss: 1.8847\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.3030 - val_loss: 1.8152\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 2.2766 - val_loss: 1.8120\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 2.3077 - val_loss: 1.8171\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 134us/step - loss: 2.3165 - val_loss: 1.8311\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.3086 - val_loss: 1.8017\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.3605 - val_loss: 1.8272\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.3350 - val_loss: 1.8135\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 2.3588 - val_loss: 1.8442\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.3162 - val_loss: 1.8121\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.3221 - val_loss: 1.8225\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.2719 - val_loss: 1.8139\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.2988 - val_loss: 1.7917\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.2967 - val_loss: 1.8446\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.2689 - val_loss: 1.7982\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.2862 - val_loss: 1.8224\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.3802 - val_loss: 1.8050\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 159us/step - loss: 2.3392 - val_loss: 1.9081\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.3505 - val_loss: 1.7915\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 498us/step - loss: 23.9831 - val_loss: 10.7809\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 9.7077 - val_loss: 6.7374\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 7.8797 - val_loss: 5.9372\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 7.7835 - val_loss: 5.7592\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 7.7689 - val_loss: 5.8387\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 131us/step - loss: 7.6975 - val_loss: 5.7028\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 7.6596 - val_loss: 5.6275\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 7.5611 - val_loss: 5.6464\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 155us/step - loss: 7.5182 - val_loss: 5.5777\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 7.3978 - val_loss: 5.5547\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 7.2846 - val_loss: 5.3602\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 7.1666 - val_loss: 5.2012\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 7.0459 - val_loss: 5.1663\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 6.9284 - val_loss: 5.1514\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 6.7951 - val_loss: 4.8807\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 6.6331 - val_loss: 4.8659\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 6.4705 - val_loss: 4.6476\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 6.2272 - val_loss: 4.4927\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 5.9251 - val_loss: 4.3038\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 5.6939 - val_loss: 4.0601\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 5.4865 - val_loss: 3.8045\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 5.1908 - val_loss: 3.7882\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 4.9919 - val_loss: 3.5941\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 4.7323 - val_loss: 3.3786\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 4.5555 - val_loss: 3.2674\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 4.3446 - val_loss: 3.2266\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 4.2200 - val_loss: 3.0141\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 142us/step - loss: 4.0575 - val_loss: 3.0075\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 3.9354 - val_loss: 2.8780\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 3.8470 - val_loss: 2.7746\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 129us/step - loss: 3.7517 - val_loss: 2.7652\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 3.6753 - val_loss: 2.7279\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 3.5587 - val_loss: 2.6855\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 3.5423 - val_loss: 2.6950\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 3.4620 - val_loss: 2.6469\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 3.4250 - val_loss: 2.5505\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 3.3577 - val_loss: 2.6730\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 3.3049 - val_loss: 2.5674\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 3.2881 - val_loss: 2.5322\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 3.2558 - val_loss: 2.4576\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 3.2118 - val_loss: 2.4553\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 3.1659 - val_loss: 2.4571\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 3.1715 - val_loss: 2.3891\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 3.1157 - val_loss: 2.3812\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 3.0592 - val_loss: 2.5992\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 134us/step - loss: 3.0573 - val_loss: 2.4238\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 3.0406 - val_loss: 2.4218\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.9981 - val_loss: 2.3628\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.9616 - val_loss: 2.3488\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.9237 - val_loss: 2.3274\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 129us/step - loss: 2.8996 - val_loss: 2.2569\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 2.9200 - val_loss: 2.3032\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.8841 - val_loss: 2.2242\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.8270 - val_loss: 2.2140\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.7748 - val_loss: 2.2113\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.7774 - val_loss: 2.1926\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 2.7927 - val_loss: 2.2338\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.7077 - val_loss: 2.0998\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 134us/step - loss: 2.6922 - val_loss: 2.1813\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.7129 - val_loss: 2.1745\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.6546 - val_loss: 2.0846\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.6274 - val_loss: 2.1147\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.6100 - val_loss: 2.0364\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 2.5775 - val_loss: 2.0398\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.5879 - val_loss: 2.0056\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 156us/step - loss: 2.5304 - val_loss: 2.0254\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 2.5102 - val_loss: 1.9835\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 2.5136 - val_loss: 1.9912\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.4854 - val_loss: 1.9841\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.4940 - val_loss: 2.0037\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 2.5245 - val_loss: 1.9140\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.4360 - val_loss: 1.9041\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.4683 - val_loss: 1.9070\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 2.4352 - val_loss: 1.8949\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.3916 - val_loss: 1.8871\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.3605 - val_loss: 1.8760\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.4169 - val_loss: 1.8678\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 2.4604 - val_loss: 1.9823\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.4267 - val_loss: 1.8881\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.3168 - val_loss: 1.8989\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.3528 - val_loss: 1.8629\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 132us/step - loss: 2.3232 - val_loss: 1.8475\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.3787 - val_loss: 1.8456\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 163us/step - loss: 2.3302 - val_loss: 1.8352\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.2942 - val_loss: 1.8661\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.3412 - val_loss: 1.8646\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 2.3319 - val_loss: 1.9161\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.2924 - val_loss: 1.8707\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.3201 - val_loss: 1.8423\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.3072 - val_loss: 1.8748\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.2689 - val_loss: 1.8394\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.3036 - val_loss: 1.8200\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.2324 - val_loss: 1.8740\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 2.2382 - val_loss: 1.8010\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.2878 - val_loss: 1.8182\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.2744 - val_loss: 1.7972\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.2233 - val_loss: 1.8027\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.2122 - val_loss: 1.7983\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 2.2495 - val_loss: 1.7841\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 134us/step - loss: 2.2545 - val_loss: 1.8657\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 2.2473 - val_loss: 1.8003\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 2.2440 - val_loss: 1.8107\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.2164 - val_loss: 1.7862\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 128us/step - loss: 2.2214 - val_loss: 1.8053\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.2411 - val_loss: 1.8383\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.2484 - val_loss: 1.7772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.2327 - val_loss: 1.8076\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.2040 - val_loss: 1.7798\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.2102 - val_loss: 1.8472\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.2148 - val_loss: 1.8154\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.2045 - val_loss: 1.7796\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.1993 - val_loss: 1.8271\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.2770 - val_loss: 1.7709\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.2523 - val_loss: 1.8698\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.2849 - val_loss: 1.8296\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.1996 - val_loss: 1.7816\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.2277 - val_loss: 1.8762\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 2.2437 - val_loss: 1.7905\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.1960 - val_loss: 1.7731\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.1720 - val_loss: 1.8069\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.1973 - val_loss: 1.8271\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.2215 - val_loss: 1.7732\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.1920 - val_loss: 1.7839\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 2.1784 - val_loss: 1.7856\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 2.2114 - val_loss: 1.8245\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.2070 - val_loss: 1.8965\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.2219 - val_loss: 1.7852\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.2072 - val_loss: 1.7682\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.1891 - val_loss: 1.7668\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.2569 - val_loss: 1.7604\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.1728 - val_loss: 1.7762\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 134us/step - loss: 2.2143 - val_loss: 1.8271\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.1911 - val_loss: 1.8203\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.1868 - val_loss: 1.7711\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.2348 - val_loss: 1.7641\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.2505 - val_loss: 1.8004\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 2.1789 - val_loss: 1.7901\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.1832 - val_loss: 1.7751\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.1631 - val_loss: 1.7532\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 2.1717 - val_loss: 1.7752\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 124us/step - loss: 2.1594 - val_loss: 1.7578\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 118us/step - loss: 2.2052 - val_loss: 1.7591\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 125us/step - loss: 2.2393 - val_loss: 1.8934\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 123us/step - loss: 2.3136 - val_loss: 1.8061\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 115us/step - loss: 2.2743 - val_loss: 1.8525\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 127us/step - loss: 2.1935 - val_loss: 1.7595\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 130us/step - loss: 2.2100 - val_loss: 1.7884\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 126us/step - loss: 2.2082 - val_loss: 1.7569\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 123us/step - loss: 2.1935 - val_loss: 1.7570\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 119us/step - loss: 2.1568 - val_loss: 1.7860\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 91us/step - loss: 2.1893 - val_loss: 1.7735\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 91us/step - loss: 2.2272 - val_loss: 1.7744\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.2173 - val_loss: 1.7642\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1635 - val_loss: 1.7880\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.1620 - val_loss: 1.7568\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.2039 - val_loss: 1.8065\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 90us/step - loss: 2.1638 - val_loss: 1.7800\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.1806 - val_loss: 1.7826\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.2562 - val_loss: 1.7622\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 91us/step - loss: 2.2004 - val_loss: 1.7731\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 91us/step - loss: 2.1801 - val_loss: 1.7439\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 90us/step - loss: 2.1613 - val_loss: 1.7790\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 91us/step - loss: 2.2057 - val_loss: 1.7897\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 90us/step - loss: 2.2095 - val_loss: 1.8159\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.1578 - val_loss: 1.8267\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.2160 - val_loss: 1.8486\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.1698 - val_loss: 1.7499\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.1550 - val_loss: 1.7704\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 90us/step - loss: 2.1870 - val_loss: 1.7688\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 91us/step - loss: 2.2332 - val_loss: 1.8051\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.2338 - val_loss: 1.7717\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 90us/step - loss: 2.1942 - val_loss: 1.7453\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.1672 - val_loss: 1.7426\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.1338 - val_loss: 1.7489\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.1716 - val_loss: 1.7489\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.1726 - val_loss: 1.7896\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2168 - val_loss: 1.8151\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2048 - val_loss: 1.7728\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2579 - val_loss: 1.8218\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.1786 - val_loss: 1.7814\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.2017 - val_loss: 1.7857\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.1761 - val_loss: 1.7420\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.1843 - val_loss: 1.7569\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1934 - val_loss: 1.7887\n",
      "Epoch 185/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 95us/step - loss: 2.2154 - val_loss: 1.7553\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.1496 - val_loss: 1.7414\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.1844 - val_loss: 1.7432\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2028 - val_loss: 1.7475\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2077 - val_loss: 1.8877\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.1721 - val_loss: 1.7482\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.1419 - val_loss: 1.7864\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.1658 - val_loss: 1.7918\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.1302 - val_loss: 1.8126\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.3125 - val_loss: 1.8783\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2331 - val_loss: 1.7379\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.1730 - val_loss: 1.7375\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1755 - val_loss: 1.7689\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2334 - val_loss: 1.7796\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2086 - val_loss: 1.7328\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.1962 - val_loss: 1.8563\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 386us/step - loss: 30.8704 - val_loss: 13.3651\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 10.9608 - val_loss: 9.3217\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 8.9880 - val_loss: 8.8006\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 8.5079 - val_loss: 8.6039\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 8.2230 - val_loss: 8.3654\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 7.9225 - val_loss: 8.0652\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 7.6712 - val_loss: 7.6864\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 7.3117 - val_loss: 7.4734\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 6.7257 - val_loss: 6.8429\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 6.1521 - val_loss: 6.3574\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 5.7984 - val_loss: 6.0709\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 5.4634 - val_loss: 5.9479\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 5.2007 - val_loss: 5.6795\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 4.9136 - val_loss: 5.3440\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 4.7000 - val_loss: 5.5209\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 4.3876 - val_loss: 4.9126\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 4.1132 - val_loss: 4.7273\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 3.8686 - val_loss: 4.5532\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 3.5680 - val_loss: 4.4007\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 3.3073 - val_loss: 4.1233\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 3.0989 - val_loss: 3.9779\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.8784 - val_loss: 3.8477\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.6849 - val_loss: 3.7815\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.5809 - val_loss: 3.6561\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.5246 - val_loss: 3.6296\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3956 - val_loss: 3.5830\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2994 - val_loss: 3.5279\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2553 - val_loss: 3.5203\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2167 - val_loss: 3.5536\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2555 - val_loss: 3.4990\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2024 - val_loss: 3.5323\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.1680 - val_loss: 3.4383\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.1438 - val_loss: 3.4715\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1055 - val_loss: 3.4199\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.1063 - val_loss: 3.4775\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.0749 - val_loss: 3.4065\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0785 - val_loss: 3.3636\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.0958 - val_loss: 3.3841\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.0485 - val_loss: 3.4184\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0390 - val_loss: 3.3975\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0309 - val_loss: 3.3340\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.0545 - val_loss: 3.3736\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.0293 - val_loss: 3.3529\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.0296 - val_loss: 3.3941\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0115 - val_loss: 3.3799\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9880 - val_loss: 3.3829\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9817 - val_loss: 3.4300\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0521 - val_loss: 3.3809\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9770 - val_loss: 3.4005\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9523 - val_loss: 3.3529\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9475 - val_loss: 3.3244\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9583 - val_loss: 3.3543\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9658 - val_loss: 3.2585\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9718 - val_loss: 3.3134\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9668 - val_loss: 3.2530\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9258 - val_loss: 3.3460\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9587 - val_loss: 3.2622\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8966 - val_loss: 3.3452\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9185 - val_loss: 3.2810\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.8981 - val_loss: 3.4185\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 1.9146 - val_loss: 3.3434\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.8913 - val_loss: 3.2789\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.9095 - val_loss: 3.3054\n",
      "Epoch 64/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 97us/step - loss: 1.9332 - val_loss: 3.3527\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8765 - val_loss: 3.3144\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8845 - val_loss: 3.3605\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9878 - val_loss: 3.6664\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 104us/step - loss: 1.9115 - val_loss: 3.3382\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8732 - val_loss: 3.3347\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8814 - val_loss: 3.3170\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9124 - val_loss: 3.4039\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8981 - val_loss: 3.3647\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.8574 - val_loss: 3.3129\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9081 - val_loss: 3.3048\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8598 - val_loss: 3.3141\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8758 - val_loss: 3.2507\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9071 - val_loss: 3.4174\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.8837 - val_loss: 3.2171\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8787 - val_loss: 3.3067\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8773 - val_loss: 3.2643\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8661 - val_loss: 3.3042\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8765 - val_loss: 3.4254\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8689 - val_loss: 3.3738\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8640 - val_loss: 3.2331\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8322 - val_loss: 3.4205\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8527 - val_loss: 3.3985\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8878 - val_loss: 3.2842\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8617 - val_loss: 3.2855\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8697 - val_loss: 3.3206\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8593 - val_loss: 3.2753\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8467 - val_loss: 3.2718\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8560 - val_loss: 3.5183\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8678 - val_loss: 3.2183\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8679 - val_loss: 3.3731\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8680 - val_loss: 3.3636\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8837 - val_loss: 3.5316\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8851 - val_loss: 3.3348\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8455 - val_loss: 3.4717\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8687 - val_loss: 3.3643\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8628 - val_loss: 3.2608\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8625 - val_loss: 3.3785\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8637 - val_loss: 3.3803\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.8524 - val_loss: 3.4807\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8275 - val_loss: 3.2241\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8466 - val_loss: 3.4061\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8472 - val_loss: 3.3337\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8625 - val_loss: 3.3243\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.9097 - val_loss: 3.3762\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8557 - val_loss: 3.2935\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.9308 - val_loss: 3.4556\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8738 - val_loss: 3.2113\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8429 - val_loss: 3.5416\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8944 - val_loss: 3.3295\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8493 - val_loss: 3.2400\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8560 - val_loss: 3.4074\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8350 - val_loss: 3.2775\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.8611 - val_loss: 3.3216\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8540 - val_loss: 3.2752\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9244 - val_loss: 3.3629\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8841 - val_loss: 3.3729\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8686 - val_loss: 3.3856\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8776 - val_loss: 3.2428\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8897 - val_loss: 3.2912\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8961 - val_loss: 3.4346\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8567 - val_loss: 3.4405\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.8677 - val_loss: 3.3611\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8775 - val_loss: 3.3253\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8614 - val_loss: 3.3707\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8702 - val_loss: 3.3431\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8736 - val_loss: 3.3774\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8697 - val_loss: 3.3305\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8784 - val_loss: 3.3113\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8646 - val_loss: 3.2862\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8539 - val_loss: 3.3019\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8690 - val_loss: 3.4176\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8253 - val_loss: 3.2654\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8288 - val_loss: 3.2749\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8941 - val_loss: 3.2424\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8547 - val_loss: 3.3064\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8451 - val_loss: 3.4098\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8442 - val_loss: 3.2934\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.8448 - val_loss: 3.5302\n",
      "Epoch 143/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 95us/step - loss: 1.8504 - val_loss: 3.2078\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8539 - val_loss: 3.3713\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8784 - val_loss: 3.3942\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9627 - val_loss: 3.2083\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8851 - val_loss: 3.3284\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8756 - val_loss: 3.2852\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8807 - val_loss: 3.3676\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8642 - val_loss: 3.4128\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8553 - val_loss: 3.2795\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8636 - val_loss: 3.4186\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8455 - val_loss: 3.3371\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8691 - val_loss: 3.3391\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9559 - val_loss: 3.2575\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8355 - val_loss: 3.3556\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 1.8418 - val_loss: 3.2621\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8613 - val_loss: 3.2786\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8581 - val_loss: 3.3021\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8783 - val_loss: 3.5028\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9029 - val_loss: 3.4457\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8867 - val_loss: 3.4466\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.8559 - val_loss: 3.2708\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8741 - val_loss: 3.5412\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8436 - val_loss: 3.3113\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8510 - val_loss: 3.2510\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8693 - val_loss: 3.3652\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8456 - val_loss: 3.2795\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8279 - val_loss: 3.4268\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8447 - val_loss: 3.3955\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8692 - val_loss: 3.3968\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8679 - val_loss: 3.3432\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8620 - val_loss: 3.2635\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8582 - val_loss: 3.3519\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8324 - val_loss: 3.2539\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8758 - val_loss: 3.3237\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8416 - val_loss: 3.3174\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8631 - val_loss: 3.4827\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8642 - val_loss: 3.2832\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8532 - val_loss: 3.2928\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8437 - val_loss: 3.3434\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.8787 - val_loss: 3.2041\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8248 - val_loss: 3.4169\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8469 - val_loss: 3.5108\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9025 - val_loss: 3.2792\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8740 - val_loss: 3.2258\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8874 - val_loss: 3.2452\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8268 - val_loss: 3.4273\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.8491 - val_loss: 3.3216\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8364 - val_loss: 3.2580\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8372 - val_loss: 3.4060\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8320 - val_loss: 3.3026\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8313 - val_loss: 3.3003\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8703 - val_loss: 3.2229\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8715 - val_loss: 3.1911\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.9134 - val_loss: 3.2143\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8510 - val_loss: 3.4088\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8737 - val_loss: 3.3467\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8649 - val_loss: 3.4228\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8576 - val_loss: 3.3253\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 424us/step - loss: 19.5308 - val_loss: 13.6548\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 8.4165 - val_loss: 9.7935\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 7.5867 - val_loss: 9.6532\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 7.3451 - val_loss: 9.3741\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 6.9974 - val_loss: 8.9476\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 6.2349 - val_loss: 7.4839\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 4.8143 - val_loss: 6.1914\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 3.9813 - val_loss: 5.9871\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 3.8223 - val_loss: 5.8270\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 3.7070 - val_loss: 5.6768\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 3.6241 - val_loss: 5.5756\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 3.5342 - val_loss: 5.4089\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 3.3158 - val_loss: 4.8064\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 3.0233 - val_loss: 4.3720\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.7909 - val_loss: 4.2017\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.6546 - val_loss: 4.0751\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.5825 - val_loss: 3.9533\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.5436 - val_loss: 3.9197\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.4963 - val_loss: 3.8136\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.4265 - val_loss: 3.7350\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 96us/step - loss: 2.4132 - val_loss: 3.7352\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.3634 - val_loss: 3.6536\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.3330 - val_loss: 3.6046\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2996 - val_loss: 3.5011\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.2785 - val_loss: 3.4655\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.2508 - val_loss: 3.4506\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2022 - val_loss: 3.4111\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2210 - val_loss: 3.3534\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.1825 - val_loss: 3.3166\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.1726 - val_loss: 3.2777\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1458 - val_loss: 3.2068\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1344 - val_loss: 3.1810\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.1216 - val_loss: 3.1762\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1290 - val_loss: 3.1569\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.0947 - val_loss: 3.1195\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0823 - val_loss: 3.0690\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0629 - val_loss: 3.0620\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0595 - val_loss: 3.1951\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1167 - val_loss: 2.9906\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0281 - val_loss: 2.9987\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.0232 - val_loss: 2.9898\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0182 - val_loss: 2.9513\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0401 - val_loss: 2.9878\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0487 - val_loss: 2.9146\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9951 - val_loss: 2.8893\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9978 - val_loss: 2.8703\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0185 - val_loss: 2.8906\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.9825 - val_loss: 2.9001\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0056 - val_loss: 2.8362\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9624 - val_loss: 2.8550\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9750 - val_loss: 2.8235\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9727 - val_loss: 2.7935\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9947 - val_loss: 2.8249\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9766 - val_loss: 2.8261\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9584 - val_loss: 2.7929\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0171 - val_loss: 2.7969\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9601 - val_loss: 2.7651\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9938 - val_loss: 2.7631\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9546 - val_loss: 2.8158\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9876 - val_loss: 2.7820\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9592 - val_loss: 2.7292\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9523 - val_loss: 2.7400\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9399 - val_loss: 2.7688\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9631 - val_loss: 2.7561\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9516 - val_loss: 2.7206\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.0070 - val_loss: 2.7218\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9645 - val_loss: 2.7335\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9691 - val_loss: 2.7126\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9647 - val_loss: 2.6986\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9767 - val_loss: 2.6861\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9499 - val_loss: 2.7398\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.9588 - val_loss: 2.6874\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9624 - val_loss: 2.6849\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.9856 - val_loss: 2.7504\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9504 - val_loss: 2.6885\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9808 - val_loss: 2.7499\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9610 - val_loss: 2.7411\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9767 - val_loss: 2.7930\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9833 - val_loss: 2.6768\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0062 - val_loss: 2.7517\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.0174 - val_loss: 2.6800\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9643 - val_loss: 2.6431\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9460 - val_loss: 2.7330\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9686 - val_loss: 2.6726\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9587 - val_loss: 2.6771\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.9210 - val_loss: 2.7686\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9903 - val_loss: 2.6263\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9694 - val_loss: 2.6879\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9593 - val_loss: 2.6772\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9334 - val_loss: 2.6272\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9961 - val_loss: 2.6706\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9854 - val_loss: 2.6416\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9523 - val_loss: 2.6338\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9286 - val_loss: 2.6596\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9685 - val_loss: 2.6737\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9716 - val_loss: 2.6388\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9522 - val_loss: 2.6781\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9587 - val_loss: 2.6149\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.9719 - val_loss: 2.6460\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 95us/step - loss: 1.9534 - val_loss: 2.6470\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0218 - val_loss: 2.6444\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9595 - val_loss: 2.6309\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.9724 - val_loss: 2.6215\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9467 - val_loss: 2.6276\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9668 - val_loss: 2.6796\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9578 - val_loss: 2.6357\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9874 - val_loss: 2.6598\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9781 - val_loss: 2.6302\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9663 - val_loss: 2.5990\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9340 - val_loss: 2.6043\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9282 - val_loss: 2.6105\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9422 - val_loss: 2.6314\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9444 - val_loss: 2.6034\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9651 - val_loss: 2.6621\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9699 - val_loss: 2.5931\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9510 - val_loss: 2.6193\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9555 - val_loss: 2.6137\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9435 - val_loss: 2.7167\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0411 - val_loss: 2.7023\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9270 - val_loss: 2.7420\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0421 - val_loss: 2.7763\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0133 - val_loss: 2.5995\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9628 - val_loss: 2.7749\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9715 - val_loss: 2.5997\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9558 - val_loss: 2.6639\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9600 - val_loss: 2.6213\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9293 - val_loss: 2.5888\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9437 - val_loss: 2.6907\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9868 - val_loss: 2.7406\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.9658 - val_loss: 2.6298\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9429 - val_loss: 2.5956\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0009 - val_loss: 2.6043\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.9937 - val_loss: 2.6605\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.0002 - val_loss: 2.6296\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9812 - val_loss: 2.6037\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9685 - val_loss: 2.6888\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9729 - val_loss: 2.6647\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9467 - val_loss: 2.6149\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9361 - val_loss: 2.5824\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9628 - val_loss: 2.6805\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9781 - val_loss: 2.6073\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9572 - val_loss: 2.6246\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9928 - val_loss: 2.6154\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9580 - val_loss: 2.6084\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9566 - val_loss: 2.6567\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9567 - val_loss: 2.5860\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9664 - val_loss: 2.6124\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9491 - val_loss: 2.6954\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9823 - val_loss: 2.7243\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0119 - val_loss: 2.7161\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9550 - val_loss: 2.6425\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9950 - val_loss: 2.5894\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9513 - val_loss: 2.6314\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9500 - val_loss: 2.5985\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9395 - val_loss: 2.6270\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9257 - val_loss: 2.5751\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9652 - val_loss: 2.6835\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9930 - val_loss: 2.6370\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9832 - val_loss: 2.6443\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9493 - val_loss: 2.6813\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.9348 - val_loss: 2.5799\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9483 - val_loss: 2.6293\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9628 - val_loss: 2.6588\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 1.9569 - val_loss: 2.6766\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9878 - val_loss: 2.7267\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9488 - val_loss: 2.5882\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9778 - val_loss: 3.0440\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9903 - val_loss: 2.6288\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0269 - val_loss: 2.5783\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9367 - val_loss: 2.6787\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0298 - val_loss: 2.5878\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.0117 - val_loss: 2.8437\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.0000 - val_loss: 2.6457\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0299 - val_loss: 2.7210\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9769 - val_loss: 2.6153\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9484 - val_loss: 2.6453\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9472 - val_loss: 2.5794\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9314 - val_loss: 2.5739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9341 - val_loss: 2.6862\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 1.9895 - val_loss: 2.6077\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9837 - val_loss: 2.5830\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.0115 - val_loss: 2.5850\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9867 - val_loss: 2.5595\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9795 - val_loss: 2.6171\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9756 - val_loss: 2.5526\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9424 - val_loss: 2.5871\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9305 - val_loss: 2.5625\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9412 - val_loss: 2.6749\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9922 - val_loss: 2.7594\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9713 - val_loss: 2.6503\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9891 - val_loss: 2.6506\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9473 - val_loss: 2.6373\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9569 - val_loss: 2.5806\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9258 - val_loss: 2.5950\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9701 - val_loss: 2.6383\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9569 - val_loss: 2.5664\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9376 - val_loss: 2.5838\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9515 - val_loss: 2.5560\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9465 - val_loss: 2.6040\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9331 - val_loss: 2.5504\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 444us/step - loss: 10.0198 - val_loss: 7.8848\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 7.8942 - val_loss: 7.1990\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 7.2367 - val_loss: 6.2650\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 6.5305 - val_loss: 5.4581\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 6.1716 - val_loss: 5.2839\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 5.8229 - val_loss: 4.8701\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 5.3112 - val_loss: 4.3889\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 4.4127 - val_loss: 3.2873\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 3.4468 - val_loss: 2.6110\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.9351 - val_loss: 2.6429\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.7044 - val_loss: 2.4550\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.5992 - val_loss: 2.4269\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.5535 - val_loss: 2.2698\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.5081 - val_loss: 2.3251\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.4746 - val_loss: 2.2946\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.4711 - val_loss: 2.2336\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.4615 - val_loss: 2.3429\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.4471 - val_loss: 2.3296\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3915 - val_loss: 2.1301\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3826 - val_loss: 2.1877\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3904 - val_loss: 2.1444\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.4192 - val_loss: 2.3036\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3960 - val_loss: 2.0518\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3377 - val_loss: 2.1016\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3317 - val_loss: 2.0985\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3234 - val_loss: 1.9689\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3236 - val_loss: 2.1132\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3327 - val_loss: 2.0735\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3271 - val_loss: 1.9425\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.4066 - val_loss: 1.9194\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3317 - val_loss: 2.0852\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3496 - val_loss: 1.9437\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2905 - val_loss: 2.0654\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2858 - val_loss: 1.9075\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2876 - val_loss: 1.9781\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2776 - val_loss: 1.9417\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3444 - val_loss: 1.8987\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2999 - val_loss: 1.9286\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2912 - val_loss: 1.9871\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3106 - val_loss: 2.0447\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2944 - val_loss: 1.9021\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2871 - val_loss: 1.8057\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3235 - val_loss: 2.0502\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2793 - val_loss: 1.9872\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2691 - val_loss: 1.8207\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3330 - val_loss: 1.7919\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2513 - val_loss: 2.1278\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3202 - val_loss: 1.9689\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.2557 - val_loss: 1.8428\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2963 - val_loss: 2.0351\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2662 - val_loss: 1.8442\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.3151 - val_loss: 1.8009\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2478 - val_loss: 2.1021\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2988 - val_loss: 1.8573\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2791 - val_loss: 1.9370\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2712 - val_loss: 1.7666\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3153 - val_loss: 2.0363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2846 - val_loss: 1.8473\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2683 - val_loss: 1.8682\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2489 - val_loss: 2.0082\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3005 - val_loss: 1.8202\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3092 - val_loss: 1.9059\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2778 - val_loss: 1.8669\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2597 - val_loss: 1.8260\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2970 - val_loss: 1.7531\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3300 - val_loss: 1.7809\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2538 - val_loss: 2.1750\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3418 - val_loss: 1.7714\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2642 - val_loss: 1.8389\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3362 - val_loss: 2.1323\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3534 - val_loss: 2.1292\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2759 - val_loss: 1.8537\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2552 - val_loss: 2.0317\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2794 - val_loss: 1.9496\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2800 - val_loss: 1.7446\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2978 - val_loss: 1.7981\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3111 - val_loss: 1.7371\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2935 - val_loss: 1.8716\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3383 - val_loss: 2.1744\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2491 - val_loss: 1.7779\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 92us/step - loss: 2.2615 - val_loss: 2.0447\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.3038 - val_loss: 1.9453\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.2851 - val_loss: 1.8814\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2740 - val_loss: 1.7653\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2581 - val_loss: 1.9103\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2286 - val_loss: 1.8715\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2654 - val_loss: 1.7598\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2376 - val_loss: 2.0860\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2590 - val_loss: 1.8248\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3057 - val_loss: 1.9647\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2841 - val_loss: 1.9761\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2677 - val_loss: 2.0204\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2755 - val_loss: 1.9167\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.3182 - val_loss: 1.9523\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2600 - val_loss: 1.9197\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2622 - val_loss: 2.0651\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2411 - val_loss: 1.7894\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2809 - val_loss: 1.9737\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2565 - val_loss: 1.7628\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2957 - val_loss: 1.7619\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.2448 - val_loss: 2.2203\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2820 - val_loss: 1.8413\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2651 - val_loss: 1.8193\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3334 - val_loss: 1.8555\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2725 - val_loss: 1.8135\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2472 - val_loss: 1.7627\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2526 - val_loss: 1.9934\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2541 - val_loss: 1.8834\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2952 - val_loss: 2.1183\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2557 - val_loss: 1.8029\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2796 - val_loss: 1.7570\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3195 - val_loss: 2.1642\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2122 - val_loss: 1.7989\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2595 - val_loss: 1.8689\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2461 - val_loss: 1.8226\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2547 - val_loss: 2.0504\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3242 - val_loss: 1.7995\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.3349 - val_loss: 1.8124\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3605 - val_loss: 1.8328\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2570 - val_loss: 1.8599\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2659 - val_loss: 1.8926\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2743 - val_loss: 1.7769\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2399 - val_loss: 1.9150\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2528 - val_loss: 1.8753\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2761 - val_loss: 1.9064\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2866 - val_loss: 1.9576\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2534 - val_loss: 1.8345\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2875 - val_loss: 2.0192\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2685 - val_loss: 1.8766\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2331 - val_loss: 2.1328\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3238 - val_loss: 1.9415\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2691 - val_loss: 2.1010\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2614 - val_loss: 1.7468\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2511 - val_loss: 1.9137\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2254 - val_loss: 1.8163\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2853 - val_loss: 2.0158\n",
      "Epoch 137/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 96us/step - loss: 2.2855 - val_loss: 1.8201\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2532 - val_loss: 1.9035\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2672 - val_loss: 1.7596\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2608 - val_loss: 1.8981\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2441 - val_loss: 1.7947\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.2542 - val_loss: 1.8811\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2693 - val_loss: 1.7545\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2441 - val_loss: 1.9042\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2417 - val_loss: 1.7921\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2531 - val_loss: 1.9395\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2601 - val_loss: 1.8475\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3122 - val_loss: 1.9033\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2504 - val_loss: 2.0916\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3185 - val_loss: 1.8116\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2727 - val_loss: 2.0481\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2624 - val_loss: 2.1045\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3340 - val_loss: 2.1468\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3413 - val_loss: 2.1401\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2997 - val_loss: 1.8738\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2589 - val_loss: 1.8452\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.3152 - val_loss: 1.7725\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2383 - val_loss: 1.9423\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2870 - val_loss: 1.7337\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2504 - val_loss: 1.8818\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3070 - val_loss: 1.7382\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2231 - val_loss: 2.1009\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3040 - val_loss: 1.7625\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2973 - val_loss: 1.7926\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3103 - val_loss: 1.9147\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2934 - val_loss: 1.8083\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3054 - val_loss: 1.8858\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2988 - val_loss: 1.7695\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2881 - val_loss: 1.8379\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2803 - val_loss: 1.8134\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2765 - val_loss: 1.7579\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3178 - val_loss: 1.9666\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2850 - val_loss: 1.9639\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2882 - val_loss: 1.8301\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2815 - val_loss: 1.7418\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 2.2578 - val_loss: 1.9071\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2530 - val_loss: 1.8009\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3270 - val_loss: 1.7270\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3291 - val_loss: 1.9907\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2535 - val_loss: 2.0527\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3136 - val_loss: 2.0014\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2773 - val_loss: 1.7128\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2477 - val_loss: 1.9829\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2579 - val_loss: 2.1929\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3566 - val_loss: 1.7453\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2582 - val_loss: 1.7731\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2666 - val_loss: 1.8696\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2500 - val_loss: 2.0267\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2678 - val_loss: 2.0441\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2813 - val_loss: 1.9051\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2638 - val_loss: 1.7190\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2768 - val_loss: 1.8491\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2302 - val_loss: 1.9110\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2407 - val_loss: 1.8893\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.2833 - val_loss: 1.9015\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2690 - val_loss: 1.8033\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3155 - val_loss: 1.7095\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2488 - val_loss: 1.9624\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2488 - val_loss: 1.8340\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2380 - val_loss: 1.8472\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 482us/step - loss: 36.2506 - val_loss: 19.2588\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 13.3359 - val_loss: 9.0698\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 8.4546 - val_loss: 7.1499\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 6.7492 - val_loss: 6.1545\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 5.3337 - val_loss: 5.5234\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 4.5855 - val_loss: 5.4258\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 4.3795 - val_loss: 5.4818\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 4.2501 - val_loss: 5.2105\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 4.1245 - val_loss: 5.2352\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 4.0717 - val_loss: 5.1775\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 3.9510 - val_loss: 4.8548\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 3.8092 - val_loss: 4.4353\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 3.3188 - val_loss: 3.3914\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.7585 - val_loss: 2.9958\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 96us/step - loss: 2.4700 - val_loss: 2.8089\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3460 - val_loss: 2.7435\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2740 - val_loss: 2.7151\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2013 - val_loss: 2.6086\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1155 - val_loss: 2.5511\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0841 - val_loss: 2.5154\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0120 - val_loss: 2.5154\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9820 - val_loss: 2.5120\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9757 - val_loss: 2.5467\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9221 - val_loss: 2.5012\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9053 - val_loss: 2.4614\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9026 - val_loss: 2.4780\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8677 - val_loss: 2.4771\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8643 - val_loss: 2.4288\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.8302 - val_loss: 2.4806\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.8394 - val_loss: 2.4673\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8103 - val_loss: 2.4674\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8297 - val_loss: 2.4344\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8174 - val_loss: 2.4868\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8068 - val_loss: 2.4819\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8054 - val_loss: 2.4515\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8162 - val_loss: 2.4640\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7829 - val_loss: 2.4338\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8156 - val_loss: 2.4590\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8067 - val_loss: 2.4902\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7772 - val_loss: 2.4903\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7869 - val_loss: 2.4639\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7880 - val_loss: 2.5305\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.8037 - val_loss: 2.5233\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7495 - val_loss: 2.4543\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8093 - val_loss: 2.4827\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7599 - val_loss: 2.4577\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7846 - val_loss: 2.4880\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7607 - val_loss: 2.4458\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.7671 - val_loss: 2.4530\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7958 - val_loss: 2.5145\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.8015 - val_loss: 2.5422\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7987 - val_loss: 2.5242\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7935 - val_loss: 2.4583\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7567 - val_loss: 2.4524\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7607 - val_loss: 2.4977\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7638 - val_loss: 2.4810\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7772 - val_loss: 2.4571\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7595 - val_loss: 2.5029\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7747 - val_loss: 2.5082\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7660 - val_loss: 2.4439\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7710 - val_loss: 2.4629\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7868 - val_loss: 2.4835\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7835 - val_loss: 2.5660\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7723 - val_loss: 2.4599\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.8060 - val_loss: 2.4646\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7834 - val_loss: 2.4093\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7518 - val_loss: 2.4763\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7776 - val_loss: 2.4540\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.8047 - val_loss: 2.4259\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7638 - val_loss: 2.4579\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8142 - val_loss: 2.4323\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7610 - val_loss: 2.4675\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7798 - val_loss: 2.4250\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7799 - val_loss: 2.4961\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7916 - val_loss: 2.5393\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7725 - val_loss: 2.4427\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7567 - val_loss: 2.4193\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7688 - val_loss: 2.4940\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7845 - val_loss: 2.4249\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.8469 - val_loss: 2.5048\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8504 - val_loss: 2.5089\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7557 - val_loss: 2.4544\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7760 - val_loss: 2.4563\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7759 - val_loss: 2.4017\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7676 - val_loss: 2.4369\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7877 - val_loss: 2.4404\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7555 - val_loss: 2.4640\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7603 - val_loss: 2.4731\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.7907 - val_loss: 2.4901\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7968 - val_loss: 2.4548\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7891 - val_loss: 2.4380\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7823 - val_loss: 2.4338\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7778 - val_loss: 2.5439\n",
      "Epoch 94/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 95us/step - loss: 1.8042 - val_loss: 2.4891\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7543 - val_loss: 2.5406\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8003 - val_loss: 2.4413\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7498 - val_loss: 2.4594\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8079 - val_loss: 2.5475\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7638 - val_loss: 2.4525\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7494 - val_loss: 2.5567\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7624 - val_loss: 2.4391\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7617 - val_loss: 2.4276\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7868 - val_loss: 2.5196\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7902 - val_loss: 2.5352\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7723 - val_loss: 2.4563\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7568 - val_loss: 2.4293\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7536 - val_loss: 2.4092\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7923 - val_loss: 2.6697\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8277 - val_loss: 2.4061\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7754 - val_loss: 2.4055\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7881 - val_loss: 2.4710\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7891 - val_loss: 2.4567\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7700 - val_loss: 2.4973\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.8221 - val_loss: 2.5870\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8325 - val_loss: 2.4643\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7504 - val_loss: 2.4013\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7974 - val_loss: 2.4285\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8055 - val_loss: 2.4665\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7939 - val_loss: 2.4269\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7698 - val_loss: 2.4630\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.7491 - val_loss: 2.4439\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7645 - val_loss: 2.4705\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7721 - val_loss: 2.4192\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.7945 - val_loss: 2.5448\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7820 - val_loss: 2.5245\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7763 - val_loss: 2.4937\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7552 - val_loss: 2.4828\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7448 - val_loss: 2.4780\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7811 - val_loss: 2.5445\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8886 - val_loss: 2.4217\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8077 - val_loss: 2.4894\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7674 - val_loss: 2.4506\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7540 - val_loss: 2.4379\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7510 - val_loss: 2.4823\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7713 - val_loss: 2.5617\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7642 - val_loss: 2.4574\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7599 - val_loss: 2.4657\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7625 - val_loss: 2.4252\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.7548 - val_loss: 2.5207\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7726 - val_loss: 2.4888\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7682 - val_loss: 2.6023\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8170 - val_loss: 2.4365\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7981 - val_loss: 2.4533\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7359 - val_loss: 2.5450\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7644 - val_loss: 2.5439\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7660 - val_loss: 2.4183\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8356 - val_loss: 2.4669\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8369 - val_loss: 2.4342\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7775 - val_loss: 2.5615\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7704 - val_loss: 2.4508\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7514 - val_loss: 2.4460\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7545 - val_loss: 2.4745\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7817 - val_loss: 2.5991\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7944 - val_loss: 2.5811\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8430 - val_loss: 2.5242\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7933 - val_loss: 2.6941\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.8104 - val_loss: 2.4391\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7419 - val_loss: 2.4327\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7650 - val_loss: 2.4535\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7708 - val_loss: 2.4214\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7696 - val_loss: 2.4249\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7834 - val_loss: 2.4478\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.8539 - val_loss: 2.4327\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7918 - val_loss: 2.4918\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7776 - val_loss: 2.4450\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7771 - val_loss: 2.4429\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7632 - val_loss: 2.4257\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.8037 - val_loss: 2.5253\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7912 - val_loss: 2.6853\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8013 - val_loss: 2.6071\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7713 - val_loss: 2.5162\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7782 - val_loss: 2.4156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7723 - val_loss: 2.4303\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8105 - val_loss: 2.5292\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.8436 - val_loss: 2.7149\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.8294 - val_loss: 2.4678\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7769 - val_loss: 2.4398\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7687 - val_loss: 2.4648\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7634 - val_loss: 2.4625\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7521 - val_loss: 2.5058\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7569 - val_loss: 2.4200\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7656 - val_loss: 2.5478\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7848 - val_loss: 2.4343\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7956 - val_loss: 2.4568\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8058 - val_loss: 2.8029\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.8659 - val_loss: 2.4464\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7761 - val_loss: 2.5324\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.7909 - val_loss: 2.4299\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7874 - val_loss: 2.4341\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7841 - val_loss: 2.4610\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7949 - val_loss: 2.7226\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7920 - val_loss: 2.4563\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7506 - val_loss: 2.5153\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7689 - val_loss: 2.5089\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.7661 - val_loss: 2.4659\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7694 - val_loss: 2.4574\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.7419 - val_loss: 2.4613\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7433 - val_loss: 2.4860\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7558 - val_loss: 2.4916\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7910 - val_loss: 2.4650\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 501us/step - loss: 35.8733 - val_loss: 23.2893\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 12.4392 - val_loss: 11.3323\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 8.4033 - val_loss: 8.5710\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 7.1943 - val_loss: 7.3827\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 5.5524 - val_loss: 6.3797\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 4.5636 - val_loss: 5.8321\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 4.1043 - val_loss: 5.6223\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 3.9559 - val_loss: 5.4295\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 3.7939 - val_loss: 5.2199\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 3.4281 - val_loss: 4.3423\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.8646 - val_loss: 3.6061\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.4925 - val_loss: 3.3140\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3669 - val_loss: 3.1263\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2872 - val_loss: 3.0466\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2515 - val_loss: 2.9860\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2138 - val_loss: 2.9605\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1942 - val_loss: 2.9350\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.2270 - val_loss: 2.8960\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1819 - val_loss: 2.8553\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1532 - val_loss: 2.8604\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1367 - val_loss: 2.8196\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1143 - val_loss: 2.8289\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0953 - val_loss: 2.8353\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.1038 - val_loss: 2.8252\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0768 - val_loss: 2.7922\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0913 - val_loss: 2.7729\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0952 - val_loss: 2.7611\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0634 - val_loss: 2.7883\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0645 - val_loss: 2.7462\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 110us/step - loss: 2.0498 - val_loss: 2.7733\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0422 - val_loss: 2.7586\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.1025 - val_loss: 2.7839\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0786 - val_loss: 2.7475\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0417 - val_loss: 2.7422\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0708 - val_loss: 2.7509\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0350 - val_loss: 2.7276\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0193 - val_loss: 2.7577\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0336 - val_loss: 2.7250\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 93us/step - loss: 2.1116 - val_loss: 2.7339\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0533 - val_loss: 2.7521\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0455 - val_loss: 2.7184\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0464 - val_loss: 2.7148\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0182 - val_loss: 2.6974\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0795 - val_loss: 2.8097\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0631 - val_loss: 2.7081\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0495 - val_loss: 2.7072\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0308 - val_loss: 2.6905\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0742 - val_loss: 2.7113\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0706 - val_loss: 2.7735\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0481 - val_loss: 2.7088\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0641 - val_loss: 2.7125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0421 - val_loss: 2.7612\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0372 - val_loss: 2.6661\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0161 - val_loss: 2.7202\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0232 - val_loss: 2.6973\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0112 - val_loss: 2.7083\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0739 - val_loss: 2.6923\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0205 - val_loss: 2.6679\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0059 - val_loss: 2.6848\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0183 - val_loss: 2.6961\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0428 - val_loss: 2.7242\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0121 - val_loss: 2.6919\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0313 - val_loss: 2.6519\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.0234 - val_loss: 2.7264\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0756 - val_loss: 2.6595\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0083 - val_loss: 2.6933\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0293 - val_loss: 2.6515\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0432 - val_loss: 2.7098\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0473 - val_loss: 2.6957\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0075 - val_loss: 2.7104\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9897 - val_loss: 2.6862\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0041 - val_loss: 2.6710\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0088 - val_loss: 2.6558\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9914 - val_loss: 2.6709\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0047 - val_loss: 2.6682\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0472 - val_loss: 2.6490\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0538 - val_loss: 2.7166\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0712 - val_loss: 2.6845\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0317 - val_loss: 2.7262\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0175 - val_loss: 2.6631\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0196 - val_loss: 2.7679\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0353 - val_loss: 2.6654\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0030 - val_loss: 2.6580\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0116 - val_loss: 2.6779\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0243 - val_loss: 2.6579\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9911 - val_loss: 2.6598\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0036 - val_loss: 2.6963\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.0120 - val_loss: 2.6869\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0064 - val_loss: 2.7040\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0157 - val_loss: 2.7154\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0069 - val_loss: 2.6912\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0181 - val_loss: 2.6771\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0458 - val_loss: 2.6913\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0064 - val_loss: 2.6655\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0062 - val_loss: 2.6543\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0143 - val_loss: 2.6664\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9943 - val_loss: 2.6577\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0808 - val_loss: 2.8523\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0499 - val_loss: 2.7312\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0189 - val_loss: 2.6976\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9819 - val_loss: 2.6680\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9885 - val_loss: 2.7010\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0054 - val_loss: 2.6664\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0307 - val_loss: 2.6702\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0358 - val_loss: 2.6740\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0214 - val_loss: 2.7214\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0363 - val_loss: 2.6564\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9942 - val_loss: 2.7231\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0338 - val_loss: 2.6321\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0287 - val_loss: 2.7039\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0164 - val_loss: 2.6906\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.0402 - val_loss: 2.6861\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0373 - val_loss: 2.7947\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9865 - val_loss: 2.6775\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0196 - val_loss: 2.6820\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0287 - val_loss: 2.6400\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0184 - val_loss: 2.7228\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9898 - val_loss: 2.6377\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9866 - val_loss: 2.6935\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0178 - val_loss: 2.6597\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9855 - val_loss: 2.7197\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0218 - val_loss: 2.6565\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0379 - val_loss: 2.8478\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0445 - val_loss: 2.7166\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0324 - val_loss: 2.6720\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0645 - val_loss: 2.6686\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9782 - val_loss: 2.7406\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9800 - val_loss: 2.7001\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0918 - val_loss: 2.8192\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0431 - val_loss: 2.6927\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 97us/step - loss: 1.9746 - val_loss: 2.6998\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9903 - val_loss: 2.7075\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9767 - val_loss: 2.6521\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9818 - val_loss: 2.6428\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9945 - val_loss: 2.6909\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0035 - val_loss: 2.7344\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9948 - val_loss: 2.6471\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0035 - val_loss: 2.7159\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9925 - val_loss: 2.6703\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9933 - val_loss: 2.6505\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9962 - val_loss: 2.6690\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1031 - val_loss: 2.7623\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0142 - val_loss: 2.6814\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.0076 - val_loss: 2.6918\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0549 - val_loss: 2.6969\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0383 - val_loss: 2.6480\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9960 - val_loss: 2.6679\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0471 - val_loss: 2.6824\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0039 - val_loss: 2.6673\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9894 - val_loss: 2.7367\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0025 - val_loss: 2.6948\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9913 - val_loss: 2.6855\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9865 - val_loss: 2.7277\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9837 - val_loss: 2.6986\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0330 - val_loss: 2.8499\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0527 - val_loss: 2.6602\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9712 - val_loss: 2.6481\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0340 - val_loss: 2.6539\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9972 - val_loss: 2.7929\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0294 - val_loss: 2.7342\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9885 - val_loss: 2.6790\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0246 - val_loss: 2.7655\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0260 - val_loss: 2.7728\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0124 - val_loss: 2.6776\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9913 - val_loss: 2.6630\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9855 - val_loss: 2.7326\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9831 - val_loss: 2.6438\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0023 - val_loss: 2.6561\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9929 - val_loss: 2.7018\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9871 - val_loss: 2.6514\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9905 - val_loss: 2.7187\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0040 - val_loss: 2.7109\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9691 - val_loss: 2.6980\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9822 - val_loss: 2.6700\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9710 - val_loss: 2.7198\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0224 - val_loss: 2.7670\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0692 - val_loss: 2.6812\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0170 - val_loss: 2.7560\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0482 - val_loss: 2.7510\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0911 - val_loss: 2.7044\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0077 - val_loss: 2.6929\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0130 - val_loss: 2.7203\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0056 - val_loss: 2.6989\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9999 - val_loss: 2.6837\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9987 - val_loss: 2.6765\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0072 - val_loss: 2.7595\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0425 - val_loss: 2.6913\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9886 - val_loss: 2.7113\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9825 - val_loss: 2.6737\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0010 - val_loss: 2.7497\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9795 - val_loss: 2.7581\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0056 - val_loss: 2.6452\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0029 - val_loss: 2.6891\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 2.0097 - val_loss: 2.6608\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9885 - val_loss: 2.7402\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0487 - val_loss: 2.7254\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9954 - val_loss: 2.6913\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0178 - val_loss: 2.6777\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0071 - val_loss: 2.6557\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.9903 - val_loss: 2.6942\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 536us/step - loss: 57.6852 - val_loss: 28.9450\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 18.0403 - val_loss: 14.2123\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 9.6557 - val_loss: 8.6538\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 7.6774 - val_loss: 7.7334\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 7.4143 - val_loss: 7.4139\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 7.1879 - val_loss: 7.1636\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 6.8159 - val_loss: 6.5772\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 5.7271 - val_loss: 5.2883\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 98us/step - loss: 4.3772 - val_loss: 4.5612\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 3.8852 - val_loss: 4.2398\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 3.7600 - val_loss: 4.1043\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 3.6677 - val_loss: 4.0460\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 3.5894 - val_loss: 3.9367\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 3.5400 - val_loss: 3.8862\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 3.5077 - val_loss: 3.7868\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 3.4084 - val_loss: 3.7261\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 3.3976 - val_loss: 3.6863\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 3.3321 - val_loss: 3.5580\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 3.2668 - val_loss: 3.5330\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 3.1880 - val_loss: 3.4252\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 3.1282 - val_loss: 3.3743\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 3.1015 - val_loss: 3.2938\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 3.0598 - val_loss: 3.2463\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.9925 - val_loss: 3.2015\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.9413 - val_loss: 3.1518\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.9077 - val_loss: 3.0745\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.8456 - val_loss: 3.0031\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.8285 - val_loss: 3.0166\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.7772 - val_loss: 2.9210\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.7483 - val_loss: 2.8846\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.7197 - val_loss: 2.8878\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.6678 - val_loss: 2.8500\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.6569 - val_loss: 2.7435\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.6105 - val_loss: 2.7487\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.6055 - val_loss: 2.6857\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.5583 - val_loss: 2.6332\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.5341 - val_loss: 2.6174\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.5234 - val_loss: 2.6126\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.4994 - val_loss: 2.5830\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.4904 - val_loss: 2.5141\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.4810 - val_loss: 2.4944\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.4287 - val_loss: 2.4564\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.4247 - val_loss: 2.4280\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3914 - val_loss: 2.4288\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3814 - val_loss: 2.4668\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.4091 - val_loss: 2.5075\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3524 - val_loss: 2.3864\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3446 - val_loss: 2.3535\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3220 - val_loss: 2.3092\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3165 - val_loss: 2.3619\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3210 - val_loss: 2.3065\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2897 - val_loss: 2.3167\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2631 - val_loss: 2.2663\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2821 - val_loss: 2.2413\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2622 - val_loss: 2.2110\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2622 - val_loss: 2.2639\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2551 - val_loss: 2.2572\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2321 - val_loss: 2.1738\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1997 - val_loss: 2.1770\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2162 - val_loss: 2.1372\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1984 - val_loss: 2.1207\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1862 - val_loss: 2.1103\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2082 - val_loss: 2.1669\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1918 - val_loss: 2.1175\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1854 - val_loss: 2.0806\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1630 - val_loss: 2.1493\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1443 - val_loss: 2.0929\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1271 - val_loss: 2.0739\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1301 - val_loss: 2.0771\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1169 - val_loss: 2.0262\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.1056 - val_loss: 2.0400\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.1090 - val_loss: 2.0241\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1131 - val_loss: 2.0189\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.1283 - val_loss: 2.1183\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.1103 - val_loss: 2.0310\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0792 - val_loss: 2.0172\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1120 - val_loss: 2.0189\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0804 - val_loss: 2.0161\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0880 - val_loss: 2.0140\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0991 - val_loss: 2.0441\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0954 - val_loss: 1.9607\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0622 - val_loss: 1.9595\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0771 - val_loss: 1.9736\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0480 - val_loss: 1.9804\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0833 - val_loss: 1.9829\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0570 - val_loss: 1.9466\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0325 - val_loss: 1.9294\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 99us/step - loss: 2.0820 - val_loss: 1.9238\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0136 - val_loss: 1.9368\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0718 - val_loss: 1.9578\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0444 - val_loss: 1.9097\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0584 - val_loss: 1.9184\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0168 - val_loss: 1.9295\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0593 - val_loss: 1.9902\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0960 - val_loss: 1.8874\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0588 - val_loss: 1.9519\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0710 - val_loss: 1.8764\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0680 - val_loss: 1.8937\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0534 - val_loss: 2.0664\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0938 - val_loss: 1.8894\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0501 - val_loss: 1.8731\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0287 - val_loss: 1.8842\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0255 - val_loss: 1.8634\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0222 - val_loss: 1.8627\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0264 - val_loss: 1.9339\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0011 - val_loss: 1.8545\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0295 - val_loss: 2.0792\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0359 - val_loss: 1.8859\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0135 - val_loss: 1.9060\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0026 - val_loss: 1.8494\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0144 - val_loss: 1.9211\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0013 - val_loss: 1.8478\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0141 - val_loss: 1.8591\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9860 - val_loss: 1.8762\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9936 - val_loss: 1.9126\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0651 - val_loss: 1.8374\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0180 - val_loss: 1.8879\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0582 - val_loss: 1.8946\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0911 - val_loss: 1.8288\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9719 - val_loss: 1.8199\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9923 - val_loss: 1.8231\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0011 - val_loss: 1.8843\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9819 - val_loss: 1.8350\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9662 - val_loss: 1.8818\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0433 - val_loss: 1.9549\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9649 - val_loss: 1.9544\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0311 - val_loss: 1.8879\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0127 - val_loss: 1.8301\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9903 - val_loss: 1.8786\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0358 - val_loss: 1.9307\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0121 - val_loss: 1.7966\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9848 - val_loss: 1.8368\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9792 - val_loss: 1.7965\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0361 - val_loss: 1.8452\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9797 - val_loss: 1.8135\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0035 - val_loss: 1.8177\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 94us/step - loss: 1.9988 - val_loss: 1.8733\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9897 - val_loss: 1.8596\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9954 - val_loss: 1.8254\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0211 - val_loss: 1.9907\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9613 - val_loss: 1.8776\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9576 - val_loss: 1.8434\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9884 - val_loss: 1.8740\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9916 - val_loss: 1.8207\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9574 - val_loss: 1.7812\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0402 - val_loss: 2.0280\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0444 - val_loss: 1.8150\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1110 - val_loss: 1.9208\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9718 - val_loss: 1.7991\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.9743 - val_loss: 1.7818\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9462 - val_loss: 1.8743\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0370 - val_loss: 1.8340\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9520 - val_loss: 1.8706\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9618 - val_loss: 1.8247\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9583 - val_loss: 1.8261\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9802 - val_loss: 1.8256\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0304 - val_loss: 1.7815\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0390 - val_loss: 1.8483\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0283 - val_loss: 1.8373\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9767 - val_loss: 1.7977\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0883 - val_loss: 1.8280\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9390 - val_loss: 1.8680\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0057 - val_loss: 1.7730\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0241 - val_loss: 1.7951\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9946 - val_loss: 1.7625\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9708 - val_loss: 1.9368\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 96us/step - loss: 1.9585 - val_loss: 1.7689\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9790 - val_loss: 1.7674\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0241 - val_loss: 1.8275\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0550 - val_loss: 1.8091\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 1.9568 - val_loss: 1.9226\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0053 - val_loss: 1.7747\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9798 - val_loss: 1.8420\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9566 - val_loss: 1.7582\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.9737 - val_loss: 1.7577\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9788 - val_loss: 1.8855\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9737 - val_loss: 1.7777\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9495 - val_loss: 1.7425\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9719 - val_loss: 1.7814\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9561 - val_loss: 1.8198\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9680 - val_loss: 1.8400\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9585 - val_loss: 1.8067\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9819 - val_loss: 1.7999\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0411 - val_loss: 1.8633\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9618 - val_loss: 1.8227\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9656 - val_loss: 1.8687\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9479 - val_loss: 1.7626\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9513 - val_loss: 1.8616\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9912 - val_loss: 1.7883\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9706 - val_loss: 1.8428\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9438 - val_loss: 1.8097\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9762 - val_loss: 1.8108\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9810 - val_loss: 1.8259\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9461 - val_loss: 1.7632\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9626 - val_loss: 1.8127\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9863 - val_loss: 1.7362\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9630 - val_loss: 1.7712\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9745 - val_loss: 1.7532\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0105 - val_loss: 1.9492\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9645 - val_loss: 1.7632\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 585us/step - loss: 6.5856 - val_loss: 5.8127\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 5.0818 - val_loss: 5.2468\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 4.6725 - val_loss: 4.6349\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 4.2115 - val_loss: 4.0889\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 3.9852 - val_loss: 3.9279\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 3.7760 - val_loss: 3.6493\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 3.6343 - val_loss: 3.5359\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 3.5000 - val_loss: 3.3208\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 3.4050 - val_loss: 3.2323\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 3.2660 - val_loss: 3.0915\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.9734 - val_loss: 2.5850\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.5551 - val_loss: 2.5545\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.4753 - val_loss: 2.2851\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.4186 - val_loss: 2.2539\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3658 - val_loss: 2.4193\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3651 - val_loss: 2.2761\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3320 - val_loss: 2.3086\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3515 - val_loss: 2.2882\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3337 - val_loss: 2.3235\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.4009 - val_loss: 2.1676\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3267 - val_loss: 2.1856\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3349 - val_loss: 2.1561\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3070 - val_loss: 2.3364\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3495 - val_loss: 2.4942\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3151 - val_loss: 2.2725\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.3854 - val_loss: 2.4136\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3317 - val_loss: 2.1366\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3217 - val_loss: 2.2658\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3249 - val_loss: 2.2092\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3156 - val_loss: 2.3975\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3553 - val_loss: 2.2658\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2864 - val_loss: 2.1360\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3096 - val_loss: 2.2133\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2976 - val_loss: 2.3182\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3078 - val_loss: 2.3027\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3158 - val_loss: 2.2196\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2788 - val_loss: 2.2194\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.2977 - val_loss: 2.3695\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3065 - val_loss: 2.0879\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3869 - val_loss: 2.1373\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3289 - val_loss: 2.3502\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3112 - val_loss: 2.3198\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3061 - val_loss: 2.1692\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2879 - val_loss: 2.2789\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2681 - val_loss: 2.4369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3337 - val_loss: 2.2914\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2780 - val_loss: 2.3944\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3362 - val_loss: 2.4473\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2336 - val_loss: 2.1422\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2975 - val_loss: 2.4397\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3103 - val_loss: 2.2594\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2448 - val_loss: 2.1666\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2818 - val_loss: 2.0865\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3179 - val_loss: 2.2243\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.2776 - val_loss: 2.1064\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2713 - val_loss: 2.2771\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2391 - val_loss: 2.1514\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3089 - val_loss: 2.1994\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2945 - val_loss: 2.2951\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2538 - val_loss: 2.2506\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.3215 - val_loss: 2.2081\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2283 - val_loss: 2.1560\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.2847 - val_loss: 2.5040\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2574 - val_loss: 2.1695\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2425 - val_loss: 2.2261\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2277 - val_loss: 2.2636\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2477 - val_loss: 2.2893\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2173 - val_loss: 2.3266\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2589 - val_loss: 2.1722\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3275 - val_loss: 2.0661\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2241 - val_loss: 2.1818\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2361 - val_loss: 2.3489\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2026 - val_loss: 2.0909\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2526 - val_loss: 2.1883\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2380 - val_loss: 2.1361\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2189 - val_loss: 2.1277\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2017 - val_loss: 2.5278\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.2938 - val_loss: 2.0717\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2048 - val_loss: 2.2564\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2239 - val_loss: 2.1503\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2815 - val_loss: 2.3954\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2942 - val_loss: 2.4864\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1741 - val_loss: 2.1249\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2804 - val_loss: 2.1449\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.2985 - val_loss: 2.2424\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2154 - val_loss: 2.1588\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.2198 - val_loss: 2.1695\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2323 - val_loss: 2.1588\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.1924 - val_loss: 2.2400\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2804 - val_loss: 2.0389\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2324 - val_loss: 2.4622\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2510 - val_loss: 2.2587\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2203 - val_loss: 2.2295\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.2240 - val_loss: 2.1950\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2756 - val_loss: 2.3785\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2388 - val_loss: 2.0322\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2140 - val_loss: 2.2166\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2061 - val_loss: 2.2180\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2238 - val_loss: 2.4808\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2248 - val_loss: 2.3266\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.1825 - val_loss: 2.0172\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2252 - val_loss: 2.2248\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2614 - val_loss: 1.9900\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2640 - val_loss: 2.4500\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2736 - val_loss: 2.2176\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2030 - val_loss: 2.2277\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.1927 - val_loss: 2.0953\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.2319 - val_loss: 2.0578\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2463 - val_loss: 2.0577\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1965 - val_loss: 2.1579\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2196 - val_loss: 2.2545\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2110 - val_loss: 2.2024\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.2031 - val_loss: 2.4756\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2293 - val_loss: 2.0002\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2865 - val_loss: 2.0472\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2142 - val_loss: 2.1078\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2549 - val_loss: 2.3389\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.2234 - val_loss: 2.1505\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.2161 - val_loss: 2.0392\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.2168 - val_loss: 2.4217\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.1611 - val_loss: 2.1247\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1689 - val_loss: 2.2187\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1785 - val_loss: 2.4507\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2363 - val_loss: 2.1871\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 96us/step - loss: 2.2216 - val_loss: 2.4081\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2244 - val_loss: 2.1739\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1865 - val_loss: 2.2667\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2221 - val_loss: 2.2991\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1841 - val_loss: 2.1481\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2130 - val_loss: 2.0220\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1300 - val_loss: 2.6157\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.2371 - val_loss: 2.1227\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2366 - val_loss: 2.0813\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1674 - val_loss: 2.3425\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1890 - val_loss: 2.1994\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3077 - val_loss: 2.3434\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.1550 - val_loss: 2.1534\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.1506 - val_loss: 2.2614\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1902 - val_loss: 2.2232\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.1991 - val_loss: 2.2721\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1910 - val_loss: 2.1084\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1594 - val_loss: 2.3100\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2332 - val_loss: 2.0118\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.2114 - val_loss: 2.1004\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1614 - val_loss: 2.3750\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1772 - val_loss: 2.1170\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1698 - val_loss: 2.2312\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1414 - val_loss: 2.0972\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1581 - val_loss: 2.1937\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2012 - val_loss: 2.0955\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1757 - val_loss: 2.0179\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1638 - val_loss: 2.0591\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1690 - val_loss: 2.0787\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.1581 - val_loss: 2.1755\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.1939 - val_loss: 2.1967\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.2092 - val_loss: 2.5465\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2136 - val_loss: 2.3586\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1776 - val_loss: 2.0978\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2563 - val_loss: 1.9950\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.1892 - val_loss: 2.2478\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.1825 - val_loss: 1.9893\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2306 - val_loss: 2.2209\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1712 - val_loss: 2.1207\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1987 - val_loss: 1.9930\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1522 - val_loss: 2.0890\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1685 - val_loss: 2.6044\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1620 - val_loss: 1.9817\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1550 - val_loss: 2.1308\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1601 - val_loss: 2.3540\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2065 - val_loss: 2.1571\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2103 - val_loss: 2.0394\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1320 - val_loss: 2.3186\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1824 - val_loss: 2.1172\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1943 - val_loss: 2.1507\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2086 - val_loss: 2.1130\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1510 - val_loss: 2.0188\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1429 - val_loss: 2.2169\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1860 - val_loss: 2.1164\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2032 - val_loss: 2.0716\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.2042 - val_loss: 2.0103\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1867 - val_loss: 2.3705\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1931 - val_loss: 2.0353\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1665 - val_loss: 2.1050\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.1810 - val_loss: 2.2190\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1982 - val_loss: 2.0537\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1629 - val_loss: 2.0951\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2510 - val_loss: 1.9452\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1727 - val_loss: 1.9700\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1903 - val_loss: 2.0822\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.1920 - val_loss: 2.1618\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1867 - val_loss: 2.1349\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.2538 - val_loss: 2.1903\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2758 - val_loss: 2.3339\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1663 - val_loss: 2.1500\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1819 - val_loss: 2.0437\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1641 - val_loss: 2.0436\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1674 - val_loss: 2.1874\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1634 - val_loss: 2.0682\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1655 - val_loss: 2.0842\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.1319 - val_loss: 2.2249\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 0s 588us/step - loss: 16.1679 - val_loss: 5.8956\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 3.9301 - val_loss: 3.7157\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 99us/step - loss: 3.2726 - val_loss: 3.6038\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 3.1132 - val_loss: 3.4584\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 3.0473 - val_loss: 3.3529\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.9995 - val_loss: 3.3099\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.9246 - val_loss: 3.2632\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.8696 - val_loss: 3.1929\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.8747 - val_loss: 3.1096\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.7896 - val_loss: 3.0206\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.5135 - val_loss: 2.3396\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0934 - val_loss: 2.0425\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.8347 - val_loss: 1.9392\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7268 - val_loss: 2.0085\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6712 - val_loss: 1.9736\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.6687 - val_loss: 1.8843\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6313 - val_loss: 1.8679\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6254 - val_loss: 1.8726\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6214 - val_loss: 1.8601\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6072 - val_loss: 1.8574\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6187 - val_loss: 1.8662\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6003 - val_loss: 1.9318\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6282 - val_loss: 1.8525\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6216 - val_loss: 1.8812\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6058 - val_loss: 1.8642\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6066 - val_loss: 1.8550\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6505 - val_loss: 1.8894\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6410 - val_loss: 1.8502\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6377 - val_loss: 1.8765\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6250 - val_loss: 1.9277\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.5998 - val_loss: 1.8749\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6173 - val_loss: 1.8644\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6077 - val_loss: 1.8754\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6182 - val_loss: 1.8723\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6332 - val_loss: 1.8562\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 1.6522 - val_loss: 1.8977\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6108 - val_loss: 1.8577\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.5948 - val_loss: 1.8701\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 107us/step - loss: 1.6326 - val_loss: 1.8696\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.5974 - val_loss: 1.8714\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6076 - val_loss: 2.0113\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6224 - val_loss: 1.9455\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6249 - val_loss: 1.8460\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6310 - val_loss: 1.8515\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6375 - val_loss: 1.8890\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6260 - val_loss: 1.9739\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6243 - val_loss: 1.8764\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6573 - val_loss: 1.8773\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6639 - val_loss: 1.9184\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6052 - val_loss: 1.9209\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6616 - val_loss: 1.8674\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6037 - val_loss: 1.8523\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.5935 - val_loss: 1.9120\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6176 - val_loss: 1.9205\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6427 - val_loss: 1.8806\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6137 - val_loss: 1.8539\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6101 - val_loss: 1.8845\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6038 - val_loss: 1.8643\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6062 - val_loss: 1.8588\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6086 - val_loss: 1.8636\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6725 - val_loss: 1.8708\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 106us/step - loss: 1.6270 - val_loss: 1.8971\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 109us/step - loss: 1.6145 - val_loss: 1.8596\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 111us/step - loss: 1.6263 - val_loss: 1.9565\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 114us/step - loss: 1.6100 - val_loss: 1.8913\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 160us/step - loss: 1.6049 - val_loss: 1.8799\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 124us/step - loss: 1.5999 - val_loss: 1.8795\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 118us/step - loss: 1.6055 - val_loss: 1.8822\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 110us/step - loss: 1.6183 - val_loss: 1.9078\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 110us/step - loss: 1.6357 - val_loss: 1.8719\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 112us/step - loss: 1.6123 - val_loss: 1.8713\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6296 - val_loss: 1.8660\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6093 - val_loss: 1.8594\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6332 - val_loss: 1.9142\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6145 - val_loss: 1.9341\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7256 - val_loss: 1.8957\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7436 - val_loss: 1.9644\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6224 - val_loss: 1.8975\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6558 - val_loss: 2.0101\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6108 - val_loss: 1.8590\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.5936 - val_loss: 1.8599\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 97us/step - loss: 1.6664 - val_loss: 1.9488\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6002 - val_loss: 1.8609\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6167 - val_loss: 1.8644\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6259 - val_loss: 1.8641\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6013 - val_loss: 1.8888\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6056 - val_loss: 1.8724\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6060 - val_loss: 1.8849\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6270 - val_loss: 1.8750\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6219 - val_loss: 1.8694\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.5989 - val_loss: 1.8579\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6127 - val_loss: 1.9269\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6286 - val_loss: 1.8916\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6325 - val_loss: 1.8917\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 1.6187 - val_loss: 1.9259\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 125us/step - loss: 1.6089 - val_loss: 1.9525\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 111us/step - loss: 1.5983 - val_loss: 1.8977\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 120us/step - loss: 1.6280 - val_loss: 1.8799\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 119us/step - loss: 1.6222 - val_loss: 1.8732\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 120us/step - loss: 1.5914 - val_loss: 1.8994\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 119us/step - loss: 1.6102 - val_loss: 1.8607\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 122us/step - loss: 1.6478 - val_loss: 1.9384\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 114us/step - loss: 1.6038 - val_loss: 1.8604\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 113us/step - loss: 1.5989 - val_loss: 1.8855\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 110us/step - loss: 1.6310 - val_loss: 1.8653\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 116us/step - loss: 1.6206 - val_loss: 1.8752\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 117us/step - loss: 1.6213 - val_loss: 1.8996\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 117us/step - loss: 1.6256 - val_loss: 1.8827\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 120us/step - loss: 1.6270 - val_loss: 1.8791\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 117us/step - loss: 1.6252 - val_loss: 1.8974\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 110us/step - loss: 1.6196 - val_loss: 1.9810\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 116us/step - loss: 1.6765 - val_loss: 1.8655\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 119us/step - loss: 1.6427 - val_loss: 1.8822\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 115us/step - loss: 1.6114 - val_loss: 1.8627\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 122us/step - loss: 1.6198 - val_loss: 1.9273\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 114us/step - loss: 1.6300 - val_loss: 1.8879\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 115us/step - loss: 1.6412 - val_loss: 2.0307\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 111us/step - loss: 1.6721 - val_loss: 1.8912\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 112us/step - loss: 1.6421 - val_loss: 1.8719\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 118us/step - loss: 1.6351 - val_loss: 2.0059\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 131us/step - loss: 1.6182 - val_loss: 1.8886\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 128us/step - loss: 1.6414 - val_loss: 1.8922\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 130us/step - loss: 1.6330 - val_loss: 1.8784\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 112us/step - loss: 1.5856 - val_loss: 1.8889\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 115us/step - loss: 1.6228 - val_loss: 1.9171\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 116us/step - loss: 1.7113 - val_loss: 2.1226\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 115us/step - loss: 1.6689 - val_loss: 1.9182\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 122us/step - loss: 1.6352 - val_loss: 1.9127\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 1.7007 - val_loss: 1.9046\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 1.5984 - val_loss: 1.8783\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 1.6268 - val_loss: 1.8662\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 1.6862 - val_loss: 1.8892\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 161us/step - loss: 1.6083 - val_loss: 1.8841\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 1.6321 - val_loss: 1.8822\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 156us/step - loss: 1.6021 - val_loss: 1.8760\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 1.6069 - val_loss: 1.9446\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 1.7142 - val_loss: 1.9514\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 156us/step - loss: 1.6430 - val_loss: 1.8881\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 158us/step - loss: 1.6176 - val_loss: 1.9888\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 1.6968 - val_loss: 1.9562\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 156us/step - loss: 1.6290 - val_loss: 1.9335\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 1.6506 - val_loss: 1.8810\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 151us/step - loss: 1.6032 - val_loss: 1.8666\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 1.6365 - val_loss: 1.9163\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 1.6448 - val_loss: 1.8795\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 156us/step - loss: 1.6171 - val_loss: 1.8672\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 1.5846 - val_loss: 1.8928\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 156us/step - loss: 1.5929 - val_loss: 1.8676\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 160us/step - loss: 1.5875 - val_loss: 1.9154\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 1.6114 - val_loss: 1.9194\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 1.6256 - val_loss: 1.8661\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 1.6123 - val_loss: 1.8813\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 1.6034 - val_loss: 1.8951\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 1.6307 - val_loss: 1.8681\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 1.6082 - val_loss: 1.8745\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 1.6227 - val_loss: 1.8998\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 1.5867 - val_loss: 1.8811\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 1.6218 - val_loss: 2.0536\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 1.6678 - val_loss: 1.9298\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 144us/step - loss: 1.6690 - val_loss: 1.9517\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 1.6525 - val_loss: 1.8871\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 1.6231 - val_loss: 1.8753\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 1.7166 - val_loss: 1.8874\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 1.6278 - val_loss: 1.9276\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 157us/step - loss: 1.6498 - val_loss: 1.9232\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 1.6478 - val_loss: 1.9432\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 1.6436 - val_loss: 1.9486\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 1.6509 - val_loss: 1.8971\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 1.6322 - val_loss: 1.9220\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 1.5978 - val_loss: 1.9024\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 158us/step - loss: 1.6065 - val_loss: 1.8850\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 151us/step - loss: 1.6148 - val_loss: 1.9473\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 1.5942 - val_loss: 1.8879\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 1.6424 - val_loss: 1.9059\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 156us/step - loss: 1.6201 - val_loss: 1.9514\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 1.6421 - val_loss: 1.8810\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 1.5961 - val_loss: 1.9045\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 1.6016 - val_loss: 1.9311\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 1.5943 - val_loss: 1.9298\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 1.6088 - val_loss: 1.8959\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 151us/step - loss: 1.6304 - val_loss: 1.9528\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 1.6168 - val_loss: 1.8669\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 1.5993 - val_loss: 1.9020\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 1.5927 - val_loss: 1.8742\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 1.6076 - val_loss: 1.8751\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 1.5816 - val_loss: 2.0446\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 1.6235 - val_loss: 1.8719\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 1.6281 - val_loss: 1.9585\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 158us/step - loss: 1.6071 - val_loss: 1.8792\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 1.6372 - val_loss: 1.9411\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 1.6706 - val_loss: 1.9894\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 1.6200 - val_loss: 1.8918\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 1.6554 - val_loss: 1.8789\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 1.6335 - val_loss: 1.8788\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 1.6071 - val_loss: 1.9230\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 1.6043 - val_loss: 1.9136\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 1.6718 - val_loss: 1.9381\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 1.6517 - val_loss: 1.8936\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 1.6341 - val_loss: 1.8892\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 1.6110 - val_loss: 1.8797\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 1s 808us/step - loss: 23.4497 - val_loss: 11.6324\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 7.9463 - val_loss: 7.0924\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 5.6397 - val_loss: 4.9583\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 4.5320 - val_loss: 3.3333\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 3.9783 - val_loss: 2.3999\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 3.6056 - val_loss: 2.0449\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 3.4254 - val_loss: 1.9993\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 3.3291 - val_loss: 1.9451\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 3.2440 - val_loss: 1.9527\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 3.1286 - val_loss: 1.9024\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.8160 - val_loss: 1.8038\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.4302 - val_loss: 1.7419\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.2244 - val_loss: 1.6057\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 2.1466 - val_loss: 1.6424\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.1282 - val_loss: 1.6318\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.0908 - val_loss: 1.5915\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.0761 - val_loss: 1.6014\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.1346 - val_loss: 1.5101\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 157us/step - loss: 2.0575 - val_loss: 1.5289\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.0537 - val_loss: 1.6010\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 156us/step - loss: 2.0588 - val_loss: 1.5320\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.0731 - val_loss: 1.5914\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.0586 - val_loss: 1.5917\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 2.0419 - val_loss: 1.5467\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.0419 - val_loss: 1.5662\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.0378 - val_loss: 1.6111\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.0476 - val_loss: 1.6278\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 128us/step - loss: 2.0465 - val_loss: 1.5715\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.0510 - val_loss: 1.6587\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.0722 - val_loss: 1.5951\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 161us/step - loss: 2.0420 - val_loss: 1.6535\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.0761 - val_loss: 1.6656\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 2.0172 - val_loss: 1.6752\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.0582 - val_loss: 1.6571\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.0512 - val_loss: 1.6353\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 2.0572 - val_loss: 1.6545\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 2.0371 - val_loss: 1.6626\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 155us/step - loss: 2.0340 - val_loss: 1.7013\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 2.0125 - val_loss: 1.6814\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.0648 - val_loss: 1.6807\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 2.0737 - val_loss: 1.6839\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 2.0016 - val_loss: 1.6472\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 2.0141 - val_loss: 1.6389\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.0460 - val_loss: 1.6581\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.0306 - val_loss: 1.6321\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.0016 - val_loss: 1.7427\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.0040 - val_loss: 1.6476\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.0153 - val_loss: 1.7400\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 2.0573 - val_loss: 1.7085\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.0575 - val_loss: 1.7251\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 2.0195 - val_loss: 1.6824\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.0151 - val_loss: 1.7956\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.0079 - val_loss: 1.7135\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.0206 - val_loss: 1.7056\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 1.9962 - val_loss: 1.6653\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.0217 - val_loss: 1.7906\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 2.0579 - val_loss: 1.7908\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.0034 - val_loss: 1.7171\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 2.0376 - val_loss: 1.6461\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.0291 - val_loss: 1.6331\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.0789 - val_loss: 1.7896\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.0329 - val_loss: 1.7715\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 2.0238 - val_loss: 1.6683\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.1617 - val_loss: 1.6315\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.0256 - val_loss: 1.7882\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.0403 - val_loss: 1.7464\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 119us/step - loss: 2.0661 - val_loss: 1.6101\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 127us/step - loss: 2.0333 - val_loss: 1.7481\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 119us/step - loss: 2.0013 - val_loss: 1.6742\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 119us/step - loss: 2.0209 - val_loss: 1.6507\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.0290 - val_loss: 1.7441\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 2.0178 - val_loss: 1.7114\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.0448 - val_loss: 1.7697\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 136us/step - loss: 2.0100 - val_loss: 1.7377\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0610 - val_loss: 1.8046\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0631 - val_loss: 1.7945\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0251 - val_loss: 1.7631\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0148 - val_loss: 1.6763\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0329 - val_loss: 1.6746\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0343 - val_loss: 1.6415\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0151 - val_loss: 1.7300\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0125 - val_loss: 1.8052\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0263 - val_loss: 1.6879\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9981 - val_loss: 1.8010\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0473 - val_loss: 1.8019\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0263 - val_loss: 1.7323\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.9938 - val_loss: 1.7126\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0639 - val_loss: 1.6597\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0497 - val_loss: 1.6943\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0627 - val_loss: 1.8124\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0829 - val_loss: 1.6731\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0587 - val_loss: 1.8206\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0161 - val_loss: 1.7940\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0680 - val_loss: 1.7759\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0946 - val_loss: 1.6339\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 95us/step - loss: 2.0498 - val_loss: 1.6408\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0254 - val_loss: 1.8133\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0184 - val_loss: 1.7647\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0193 - val_loss: 1.7235\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0044 - val_loss: 1.7734\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0007 - val_loss: 1.6697\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0284 - val_loss: 1.7174\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0205 - val_loss: 1.6970\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9908 - val_loss: 1.6310\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0703 - val_loss: 1.6292\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0122 - val_loss: 1.7799\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0560 - val_loss: 1.7398\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0320 - val_loss: 1.6148\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0541 - val_loss: 1.8369\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0178 - val_loss: 1.6200\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0189 - val_loss: 1.6961\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9994 - val_loss: 1.6882\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9951 - val_loss: 1.7542\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0895 - val_loss: 1.7436\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0591 - val_loss: 1.6197\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0682 - val_loss: 1.7811\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 97us/step - loss: 2.0152 - val_loss: 1.6096\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.9864 - val_loss: 1.8248\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0206 - val_loss: 1.7535\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0338 - val_loss: 1.7576\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0179 - val_loss: 1.7033\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0703 - val_loss: 1.8391\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0665 - val_loss: 1.6933\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0075 - val_loss: 1.8008\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0120 - val_loss: 1.6958\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0286 - val_loss: 1.8054\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0826 - val_loss: 1.7683\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0064 - val_loss: 1.6309\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0223 - val_loss: 1.8799\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.0841 - val_loss: 1.7516\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0566 - val_loss: 1.6361\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0391 - val_loss: 1.8145\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0424 - val_loss: 1.7840\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0125 - val_loss: 1.7146\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0177 - val_loss: 1.6370\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.9982 - val_loss: 1.7929\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0190 - val_loss: 1.6832\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0825 - val_loss: 1.7862\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0802 - val_loss: 1.7517\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0547 - val_loss: 1.7223\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0205 - val_loss: 1.6451\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0967 - val_loss: 1.9470\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.1019 - val_loss: 1.6606\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0040 - val_loss: 1.6966\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0281 - val_loss: 1.7450\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0236 - val_loss: 1.6691\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0289 - val_loss: 1.7395\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0340 - val_loss: 1.6475\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0141 - val_loss: 1.7792\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0704 - val_loss: 1.8791\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0162 - val_loss: 1.6667\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0386 - val_loss: 1.7337\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9878 - val_loss: 1.7016\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9799 - val_loss: 1.6385\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0200 - val_loss: 1.8966\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0808 - val_loss: 1.6858\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.9799 - val_loss: 1.8583\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0176 - val_loss: 1.6423\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0314 - val_loss: 1.6150\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0097 - val_loss: 1.7238\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0750 - val_loss: 1.7514\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0410 - val_loss: 1.7212\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.9804 - val_loss: 1.7818\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0327 - val_loss: 1.8636\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0261 - val_loss: 1.7118\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0225 - val_loss: 1.8228\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.9861 - val_loss: 1.7299\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0301 - val_loss: 1.8173\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0519 - val_loss: 1.9089\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0369 - val_loss: 1.6141\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0402 - val_loss: 1.7859\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0194 - val_loss: 1.6998\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0092 - val_loss: 1.6862\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0243 - val_loss: 1.7721\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.9978 - val_loss: 1.7491\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.9745 - val_loss: 1.6930\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0204 - val_loss: 1.6344\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.9793 - val_loss: 1.9129\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0216 - val_loss: 1.6715\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.9844 - val_loss: 1.8159\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0166 - val_loss: 1.7167\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0677 - val_loss: 1.6768\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0871 - val_loss: 1.7546\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.0125 - val_loss: 1.6950\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0391 - val_loss: 1.7228\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0594 - val_loss: 1.6015\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.9873 - val_loss: 1.8658\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.0055 - val_loss: 1.6791\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 2.0323 - val_loss: 1.7584\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0403 - val_loss: 1.6587\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0513 - val_loss: 1.6801\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.1189 - val_loss: 1.8542\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0181 - val_loss: 1.6834\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.9923 - val_loss: 1.7518\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0273 - val_loss: 1.6754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0514 - val_loss: 1.6378\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0193 - val_loss: 1.8134\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0012 - val_loss: 1.6111\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.0056 - val_loss: 1.7191\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.0531 - val_loss: 1.7731\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 1s 656us/step - loss: 19.0754 - val_loss: 6.6947\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 5.3194 - val_loss: 2.7068\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 3.3980 - val_loss: 1.9750\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 3.2048 - val_loss: 1.9473\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 3.1650 - val_loss: 1.8648\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 3.0238 - val_loss: 1.8184\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.6965 - val_loss: 1.6440\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.2139 - val_loss: 1.5338\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.0242 - val_loss: 1.5068\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.9855 - val_loss: 1.4170\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.9185 - val_loss: 1.4064\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.8646 - val_loss: 1.4023\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.8454 - val_loss: 1.3942\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.8303 - val_loss: 1.3716\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.8796 - val_loss: 1.3937\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.8117 - val_loss: 1.3589\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.8016 - val_loss: 1.3799\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7891 - val_loss: 1.3937\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.8249 - val_loss: 1.3471\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.8716 - val_loss: 1.5249\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7869 - val_loss: 1.3535\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7471 - val_loss: 1.3393\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7550 - val_loss: 1.3708\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7534 - val_loss: 1.3674\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.8072 - val_loss: 1.3491\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7586 - val_loss: 1.4527\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7703 - val_loss: 1.3473\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7559 - val_loss: 1.4958\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7493 - val_loss: 1.4449\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7432 - val_loss: 1.3769\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7199 - val_loss: 1.3917\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7640 - val_loss: 1.4059\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7816 - val_loss: 1.4937\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7532 - val_loss: 1.4076\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7406 - val_loss: 1.5009\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7306 - val_loss: 1.4218\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7217 - val_loss: 1.3532\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7210 - val_loss: 1.3782\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7321 - val_loss: 1.3578\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7361 - val_loss: 1.5707\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.8022 - val_loss: 1.3755\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7023 - val_loss: 1.3407\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7417 - val_loss: 1.4175\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7671 - val_loss: 1.6604\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.8093 - val_loss: 1.3572\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7012 - val_loss: 1.4030\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7098 - val_loss: 1.3549\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7073 - val_loss: 1.5704\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6972 - val_loss: 1.4134\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7452 - val_loss: 1.4735\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7416 - val_loss: 1.4504\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7230 - val_loss: 1.4006\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7252 - val_loss: 1.4677\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7049 - val_loss: 1.3585\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7337 - val_loss: 1.3851\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6929 - val_loss: 1.4468\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7075 - val_loss: 1.4500\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7274 - val_loss: 1.3625\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7082 - val_loss: 1.3776\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7047 - val_loss: 1.3956\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6858 - val_loss: 1.4562\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6886 - val_loss: 1.3591\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7097 - val_loss: 1.4152\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7089 - val_loss: 1.3986\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7126 - val_loss: 1.4126\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7375 - val_loss: 1.4928\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.8458 - val_loss: 1.4018\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6986 - val_loss: 1.5386\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7316 - val_loss: 1.4162\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7059 - val_loss: 1.4440\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7187 - val_loss: 1.4382\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7178 - val_loss: 1.5702\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7097 - val_loss: 1.4249\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7350 - val_loss: 1.5493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7083 - val_loss: 1.4541\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6959 - val_loss: 1.3928\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6940 - val_loss: 1.3977\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6796 - val_loss: 1.4396\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.8061 - val_loss: 1.4412\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7148 - val_loss: 1.3761\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6936 - val_loss: 1.4773\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7146 - val_loss: 1.3886\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 1.7122 - val_loss: 1.3848\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7027 - val_loss: 1.5173\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7958 - val_loss: 1.5527\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7191 - val_loss: 1.3919\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7069 - val_loss: 1.4353\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7175 - val_loss: 1.3726\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7204 - val_loss: 1.4515\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7010 - val_loss: 1.4595\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7171 - val_loss: 1.4436\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7231 - val_loss: 1.5228\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6815 - val_loss: 1.4224\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7493 - val_loss: 1.5839\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7708 - val_loss: 1.4540\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7256 - val_loss: 1.4860\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6721 - val_loss: 1.4379\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6879 - val_loss: 1.5291\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7214 - val_loss: 1.4576\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7385 - val_loss: 1.4878\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7254 - val_loss: 1.5691\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7889 - val_loss: 1.4401\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7538 - val_loss: 1.3994\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7231 - val_loss: 1.4276\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.6841 - val_loss: 1.4686\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6840 - val_loss: 1.5742\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7170 - val_loss: 1.4457\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6987 - val_loss: 1.4633\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7036 - val_loss: 1.3863\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6968 - val_loss: 1.4139\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7007 - val_loss: 1.4192\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7028 - val_loss: 1.3830\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7047 - val_loss: 1.4752\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6936 - val_loss: 1.3953\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6926 - val_loss: 1.4673\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6976 - val_loss: 1.4660\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6786 - val_loss: 1.4225\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6909 - val_loss: 1.3956\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6818 - val_loss: 1.5105\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7164 - val_loss: 1.4778\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6743 - val_loss: 1.4659\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6864 - val_loss: 1.4009\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6681 - val_loss: 1.4228\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7008 - val_loss: 1.5362\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7100 - val_loss: 1.4045\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6864 - val_loss: 1.5670\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7256 - val_loss: 1.4180\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7126 - val_loss: 1.4414\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7230 - val_loss: 1.5092\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6708 - val_loss: 1.4412\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6855 - val_loss: 1.5772\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7063 - val_loss: 1.4622\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7952 - val_loss: 1.4592\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7336 - val_loss: 1.3626\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6795 - val_loss: 1.5408\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6740 - val_loss: 1.4091\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6776 - val_loss: 1.3783\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6904 - val_loss: 1.4972\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6971 - val_loss: 1.4339\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7329 - val_loss: 1.4240\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7070 - val_loss: 1.4222\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6623 - val_loss: 1.4115\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6524 - val_loss: 1.3734\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6640 - val_loss: 1.4599\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7754 - val_loss: 1.7111\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7660 - val_loss: 1.4521\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6554 - val_loss: 1.4760\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7122 - val_loss: 1.3786\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7096 - val_loss: 1.4107\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7517 - val_loss: 1.4148\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6481 - val_loss: 1.4790\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7067 - val_loss: 1.4045\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.6689 - val_loss: 1.4267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.6788 - val_loss: 1.4781\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6427 - val_loss: 1.4852\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7218 - val_loss: 1.4314\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6796 - val_loss: 1.4318\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6749 - val_loss: 1.4187\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7204 - val_loss: 1.4688\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6403 - val_loss: 1.3482\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6593 - val_loss: 1.3860\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.6729 - val_loss: 1.3780\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6967 - val_loss: 1.5024\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.6802 - val_loss: 1.4541\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6727 - val_loss: 1.4530\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 1.6542 - val_loss: 1.5317\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.6798 - val_loss: 1.3967\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6958 - val_loss: 1.4777\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.8087 - val_loss: 1.5486\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7040 - val_loss: 1.3872\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6903 - val_loss: 1.4509\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7380 - val_loss: 1.3742\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 1.7108 - val_loss: 1.4171\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6517 - val_loss: 1.4599\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6756 - val_loss: 1.4874\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 1.7304 - val_loss: 1.5754\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6759 - val_loss: 1.4112\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7125 - val_loss: 1.4701\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6558 - val_loss: 1.4688\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6698 - val_loss: 1.4459\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6583 - val_loss: 1.4557\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.6567 - val_loss: 1.3487\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6750 - val_loss: 1.3407\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6805 - val_loss: 1.3335\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6739 - val_loss: 1.3677\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6414 - val_loss: 1.5079\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6733 - val_loss: 1.3962\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6868 - val_loss: 1.5348\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7095 - val_loss: 1.3899\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6421 - val_loss: 1.3226\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6604 - val_loss: 1.3486\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.6838 - val_loss: 1.4497\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6950 - val_loss: 1.3957\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6434 - val_loss: 1.3570\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.6703 - val_loss: 1.4150\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.6516 - val_loss: 1.3600\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6746 - val_loss: 1.3583\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6480 - val_loss: 1.4011\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6836 - val_loss: 1.4844\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6496 - val_loss: 1.4066\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 1s 774us/step - loss: 20.7954 - val_loss: 8.0867\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 8.2943 - val_loss: 5.6046\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 6.3713 - val_loss: 3.8798\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 4.7122 - val_loss: 2.3909\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 104us/step - loss: 3.7524 - val_loss: 1.8347\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 3.4859 - val_loss: 1.6673\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 3.3501 - val_loss: 1.6623\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 3.2414 - val_loss: 1.6017\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 3.2243 - val_loss: 1.5424\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 3.1875 - val_loss: 1.5569\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 3.0706 - val_loss: 1.5028\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 3.0352 - val_loss: 1.5067\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 3.0272 - val_loss: 1.5732\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 3.0072 - val_loss: 1.5063\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.9760 - val_loss: 1.5169\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.9447 - val_loss: 1.5066\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.9195 - val_loss: 1.5025\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.9318 - val_loss: 1.5314\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 2.8895 - val_loss: 1.4828\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.8649 - val_loss: 1.4964\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.8380 - val_loss: 1.4599\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.8276 - val_loss: 1.4507\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.9302 - val_loss: 1.4547\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.8175 - val_loss: 1.4119\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 117us/step - loss: 2.7716 - val_loss: 1.4238\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 121us/step - loss: 2.7461 - val_loss: 1.4275\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 112us/step - loss: 2.7449 - val_loss: 1.4380\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 120us/step - loss: 2.6102 - val_loss: 1.3868\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 125us/step - loss: 2.4488 - val_loss: 1.3429\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 127us/step - loss: 2.3317 - val_loss: 1.3053\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 121us/step - loss: 2.3103 - val_loss: 1.2973\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 121us/step - loss: 2.2852 - val_loss: 1.3204\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 111us/step - loss: 2.2863 - val_loss: 1.3239\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 109us/step - loss: 2.4193 - val_loss: 1.3890\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 114us/step - loss: 2.3386 - val_loss: 1.3108\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 122us/step - loss: 2.2716 - val_loss: 1.3139\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 114us/step - loss: 2.2682 - val_loss: 1.3385\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 115us/step - loss: 2.2986 - val_loss: 1.3473\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 109us/step - loss: 2.2772 - val_loss: 1.3072\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 109us/step - loss: 2.2714 - val_loss: 1.3519\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 115us/step - loss: 2.2800 - val_loss: 1.2907\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 114us/step - loss: 2.2691 - val_loss: 1.3089\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 125us/step - loss: 2.2949 - val_loss: 1.3629\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 115us/step - loss: 2.2924 - val_loss: 1.2880\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 120us/step - loss: 2.2626 - val_loss: 1.3261\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 115us/step - loss: 2.2472 - val_loss: 1.2901\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 123us/step - loss: 2.2927 - val_loss: 1.3304\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 126us/step - loss: 2.3163 - val_loss: 1.3397\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 126us/step - loss: 2.2987 - val_loss: 1.2882\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 121us/step - loss: 2.3175 - val_loss: 1.3262\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 128us/step - loss: 2.3081 - val_loss: 1.3160\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 2.2416 - val_loss: 1.2941\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 2.2705 - val_loss: 1.3073\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 124us/step - loss: 2.2566 - val_loss: 1.3001\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 119us/step - loss: 2.2727 - val_loss: 1.2934\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 122us/step - loss: 2.2697 - val_loss: 1.2964\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 115us/step - loss: 2.3163 - val_loss: 1.2999\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 130us/step - loss: 2.3650 - val_loss: 1.3054\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 128us/step - loss: 2.2764 - val_loss: 1.3386\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 2.2572 - val_loss: 1.2876\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 2.3089 - val_loss: 1.3544\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 2.2569 - val_loss: 1.3552\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 157us/step - loss: 2.2744 - val_loss: 1.3307\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 158us/step - loss: 2.2581 - val_loss: 1.3060\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 159us/step - loss: 2.2473 - val_loss: 1.3138\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 2.3188 - val_loss: 1.3557\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 160us/step - loss: 2.2997 - val_loss: 1.3432\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 159us/step - loss: 2.2899 - val_loss: 1.3416\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.3308 - val_loss: 1.3053\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.2577 - val_loss: 1.3194\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 2.3277 - val_loss: 1.3753\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.3725 - val_loss: 1.3250\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 2.3908 - val_loss: 1.3878\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.2986 - val_loss: 1.3270\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.2746 - val_loss: 1.3078\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 2.2715 - val_loss: 1.3496\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 2.3140 - val_loss: 1.3231\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.3556 - val_loss: 1.2854\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 135us/step - loss: 2.2674 - val_loss: 1.3511\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.2924 - val_loss: 1.3846\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 156us/step - loss: 2.2806 - val_loss: 1.3531\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 161us/step - loss: 2.2520 - val_loss: 1.3671\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 157us/step - loss: 2.2865 - val_loss: 1.3166\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.3366 - val_loss: 1.3495\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.2625 - val_loss: 1.3144\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.2679 - val_loss: 1.2853\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.3578 - val_loss: 1.3801\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.2887 - val_loss: 1.3010\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.2593 - val_loss: 1.4379\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 2.2972 - val_loss: 1.3392\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 158us/step - loss: 2.2909 - val_loss: 1.3145\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 2.3178 - val_loss: 1.3779\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 2.2919 - val_loss: 1.3080\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 2.2823 - val_loss: 1.2931\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.3126 - val_loss: 1.4096\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.2872 - val_loss: 1.2873\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 2.2782 - val_loss: 1.3741\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 2.2896 - val_loss: 1.2853\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 158us/step - loss: 2.2661 - val_loss: 1.2886\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.2965 - val_loss: 1.3803\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.3321 - val_loss: 1.3269\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 2.2669 - val_loss: 1.3629\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.5193 - val_loss: 1.4780\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.2896 - val_loss: 1.2911\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.2831 - val_loss: 1.3580\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 2.3041 - val_loss: 1.3096\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.2686 - val_loss: 1.2788\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.3539 - val_loss: 1.3936\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 158us/step - loss: 2.2765 - val_loss: 1.3773\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.2804 - val_loss: 1.2772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 2.2827 - val_loss: 1.3083\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.2868 - val_loss: 1.3409\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.2901 - val_loss: 1.3320\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 156us/step - loss: 2.4285 - val_loss: 1.3619\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.2805 - val_loss: 1.3096\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 2.2718 - val_loss: 1.3748\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 159us/step - loss: 2.2882 - val_loss: 1.3041\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 161us/step - loss: 2.2478 - val_loss: 1.4412\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 161us/step - loss: 2.2719 - val_loss: 1.2848\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.3002 - val_loss: 1.3249\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.2446 - val_loss: 1.3720\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 160us/step - loss: 2.2690 - val_loss: 1.3318\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 163us/step - loss: 2.3064 - val_loss: 1.3994\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.3424 - val_loss: 1.3596\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 165us/step - loss: 2.2934 - val_loss: 1.2779\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.2778 - val_loss: 1.3378\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 2.2857 - val_loss: 1.3398\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 2.2741 - val_loss: 1.3284\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.2679 - val_loss: 1.2752\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.2225 - val_loss: 1.3698\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.2513 - val_loss: 1.3389\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.2585 - val_loss: 1.2934\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 158us/step - loss: 2.2693 - val_loss: 1.3596\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.3362 - val_loss: 1.3053\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.2976 - val_loss: 1.3520\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 2.2536 - val_loss: 1.2890\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 2.2518 - val_loss: 1.3426\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 157us/step - loss: 2.2794 - val_loss: 1.2972\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.3370 - val_loss: 1.3018\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 160us/step - loss: 2.2927 - val_loss: 1.3254\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.3298 - val_loss: 1.3293\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.2933 - val_loss: 1.3255\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.2626 - val_loss: 1.3456\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.2729 - val_loss: 1.3387\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.2650 - val_loss: 1.2908\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.2334 - val_loss: 1.3469\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.2352 - val_loss: 1.3229\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.3747 - val_loss: 1.3605\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.3035 - val_loss: 1.3524\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 137us/step - loss: 2.3218 - val_loss: 1.3075\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 2.2662 - val_loss: 1.2857\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.3107 - val_loss: 1.2978\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.2333 - val_loss: 1.3197\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 2.2854 - val_loss: 1.3034\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 2.2774 - val_loss: 1.2755\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 160us/step - loss: 2.2718 - val_loss: 1.3595\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.2472 - val_loss: 1.3084\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 140us/step - loss: 2.2592 - val_loss: 1.2772\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.2768 - val_loss: 1.2905\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.2438 - val_loss: 1.3198\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.3066 - val_loss: 1.3067\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 139us/step - loss: 2.2267 - val_loss: 1.3252\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.2926 - val_loss: 1.3209\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 2.2837 - val_loss: 1.2789\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 160us/step - loss: 2.2770 - val_loss: 1.2827\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 158us/step - loss: 2.2636 - val_loss: 1.3236\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 156us/step - loss: 2.2697 - val_loss: 1.3129\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.2706 - val_loss: 1.3032\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.2673 - val_loss: 1.2958\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 158us/step - loss: 2.2425 - val_loss: 1.3108\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 138us/step - loss: 2.2673 - val_loss: 1.2928\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 160us/step - loss: 2.2728 - val_loss: 1.3379\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.3612 - val_loss: 1.3326\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 152us/step - loss: 2.2911 - val_loss: 1.2704\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 2.2575 - val_loss: 1.3316\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.3711 - val_loss: 1.3772\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.4822 - val_loss: 1.4645\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 2.3488 - val_loss: 1.3708\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 143us/step - loss: 2.3151 - val_loss: 1.3434\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 144us/step - loss: 2.3076 - val_loss: 1.3249\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 151us/step - loss: 2.2664 - val_loss: 1.3840\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.2803 - val_loss: 1.3105\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 133us/step - loss: 2.2392 - val_loss: 1.2853\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 153us/step - loss: 2.2617 - val_loss: 1.3135\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.2586 - val_loss: 1.3303\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 154us/step - loss: 2.2525 - val_loss: 1.2750\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 147us/step - loss: 2.2632 - val_loss: 1.3091\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.3566 - val_loss: 1.4090\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 160us/step - loss: 2.2657 - val_loss: 1.3077\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.2417 - val_loss: 1.3424\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 145us/step - loss: 2.3313 - val_loss: 1.2765\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 141us/step - loss: 2.2849 - val_loss: 1.3025\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 142us/step - loss: 2.2798 - val_loss: 1.3087\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.2454 - val_loss: 1.3276\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 146us/step - loss: 2.2495 - val_loss: 1.3076\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 155us/step - loss: 2.3001 - val_loss: 1.3607\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 149us/step - loss: 2.2416 - val_loss: 1.3083\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 148us/step - loss: 2.2536 - val_loss: 1.3595\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 150us/step - loss: 2.3378 - val_loss: 1.2990\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 156us/step - loss: 2.3558 - val_loss: 1.3200\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 54.2395 - val_loss: 19.7975\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 15.3249 - val_loss: 8.1599\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 6.5893 - val_loss: 5.6823\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 5.0030 - val_loss: 5.2098\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 4.4947 - val_loss: 4.7681\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 4.0698 - val_loss: 4.4284\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 3.7225 - val_loss: 4.1582\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 3.4710 - val_loss: 3.9291\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 3.2318 - val_loss: 3.7228\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 96us/step - loss: 3.0503 - val_loss: 3.4860\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.6954 - val_loss: 2.8152\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.1463 - val_loss: 2.2564\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 1.9114 - val_loss: 2.0376\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.8134 - val_loss: 1.9513\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 1.7864 - val_loss: 1.9286\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7595 - val_loss: 1.8918\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7742 - val_loss: 1.9085\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7722 - val_loss: 1.9266\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7498 - val_loss: 1.8680\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7568 - val_loss: 1.9171\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7764 - val_loss: 1.8771\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7356 - val_loss: 1.8905\n",
      "Epoch 23/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7287 - val_loss: 1.8836\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7320 - val_loss: 1.8842\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7322 - val_loss: 1.8606\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7282 - val_loss: 1.8891\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7473 - val_loss: 1.8963\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7360 - val_loss: 1.8650\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7524 - val_loss: 1.8575\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 104us/step - loss: 1.7442 - val_loss: 1.8871\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7755 - val_loss: 1.8770\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7210 - val_loss: 1.8567\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7280 - val_loss: 1.8482\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7795 - val_loss: 1.8729\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7183 - val_loss: 1.8430\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7226 - val_loss: 1.8609\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7270 - val_loss: 1.8383\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7480 - val_loss: 1.8686\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7399 - val_loss: 1.8638\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7273 - val_loss: 1.8600\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7065 - val_loss: 1.8549\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7131 - val_loss: 1.8332\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7134 - val_loss: 1.8518\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7178 - val_loss: 1.8417\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7440 - val_loss: 1.8580\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7382 - val_loss: 1.8938\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7192 - val_loss: 1.8529\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7521 - val_loss: 1.9227\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 1.7985 - val_loss: 1.8583\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7338 - val_loss: 1.8323\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7404 - val_loss: 1.8983\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7413 - val_loss: 1.8359\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7010 - val_loss: 1.8596\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7272 - val_loss: 1.9223\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7080 - val_loss: 1.8293\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7147 - val_loss: 1.9068\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7248 - val_loss: 1.8670\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7252 - val_loss: 1.8620\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7110 - val_loss: 1.8468\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7177 - val_loss: 1.8410\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7381 - val_loss: 1.8986\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7895 - val_loss: 1.8563\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7225 - val_loss: 1.8234\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7401 - val_loss: 1.8154\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7179 - val_loss: 1.8794\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7248 - val_loss: 1.8544\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 101us/step - loss: 1.7359 - val_loss: 1.8474\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7236 - val_loss: 1.8708\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.8316 - val_loss: 1.8237\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7437 - val_loss: 1.8366\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7035 - val_loss: 1.8620\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7057 - val_loss: 1.8340\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7082 - val_loss: 1.8407\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7372 - val_loss: 1.8200\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7147 - val_loss: 1.9027\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7144 - val_loss: 1.8156\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6934 - val_loss: 1.8674\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7134 - val_loss: 1.8649\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 1.7022 - val_loss: 1.8264\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7278 - val_loss: 1.9109\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7603 - val_loss: 1.8659\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7128 - val_loss: 1.8702\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7228 - val_loss: 1.8160\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7196 - val_loss: 1.9306\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7333 - val_loss: 1.8660\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 1.7811 - val_loss: 1.8525\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7799 - val_loss: 1.8958\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7118 - val_loss: 1.8676\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7239 - val_loss: 1.8342\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7066 - val_loss: 1.8889\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7114 - val_loss: 1.8944\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7034 - val_loss: 1.8491\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7476 - val_loss: 1.9533\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7763 - val_loss: 1.9091\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7598 - val_loss: 1.8291\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7226 - val_loss: 1.9079\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7290 - val_loss: 1.8466\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7148 - val_loss: 1.8663\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7452 - val_loss: 1.8673\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.8168 - val_loss: 1.8601\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7313 - val_loss: 2.0501\n",
      "Epoch 102/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7476 - val_loss: 1.8021\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7186 - val_loss: 1.8515\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7254 - val_loss: 1.8482\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7062 - val_loss: 1.8546\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7228 - val_loss: 1.8627\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7651 - val_loss: 1.8404\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7487 - val_loss: 1.8476\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7514 - val_loss: 1.8985\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7128 - val_loss: 1.8575\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7480 - val_loss: 1.9509\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 1.7490 - val_loss: 1.8548\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7154 - val_loss: 1.9304\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7297 - val_loss: 1.8678\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.6923 - val_loss: 1.8808\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7578 - val_loss: 2.1018\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7759 - val_loss: 1.8214\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7068 - val_loss: 1.8847\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7095 - val_loss: 1.8544\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7202 - val_loss: 1.8709\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 1.6965 - val_loss: 1.9259\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7721 - val_loss: 1.8600\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7362 - val_loss: 1.8984\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7955 - val_loss: 2.0823\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7745 - val_loss: 1.8255\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7563 - val_loss: 1.9380\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7496 - val_loss: 1.9093\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7315 - val_loss: 1.8550\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6937 - val_loss: 1.8915\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7351 - val_loss: 1.8602\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7380 - val_loss: 1.8663\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6861 - val_loss: 1.8910\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7263 - val_loss: 1.8182\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 1.6906 - val_loss: 1.8753\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7208 - val_loss: 1.8604\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6880 - val_loss: 1.8653\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7422 - val_loss: 1.8810\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 1.7288 - val_loss: 1.8501\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6965 - val_loss: 2.0238\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7147 - val_loss: 1.8343\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7278 - val_loss: 1.9861\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.6961 - val_loss: 1.8257\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7132 - val_loss: 1.8877\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7406 - val_loss: 1.9376\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 100us/step - loss: 1.7745 - val_loss: 1.8703\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7194 - val_loss: 1.8799\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7031 - val_loss: 1.8320\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7414 - val_loss: 1.9434\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7337 - val_loss: 1.8726\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7071 - val_loss: 1.8685\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7050 - val_loss: 1.8563\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.8038 - val_loss: 1.9526\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 1.7453 - val_loss: 1.8348\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7189 - val_loss: 1.8223\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.6977 - val_loss: 1.8753\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7214 - val_loss: 1.8712\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7063 - val_loss: 1.8156\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7448 - val_loss: 1.9003\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7084 - val_loss: 1.8424\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7043 - val_loss: 1.8509\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7324 - val_loss: 1.9325\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7238 - val_loss: 1.9233\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7212 - val_loss: 1.8186\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7132 - val_loss: 1.9238\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7431 - val_loss: 1.8532\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7308 - val_loss: 1.8797\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7764 - val_loss: 1.8602\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7055 - val_loss: 1.8299\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7233 - val_loss: 1.8522\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7080 - val_loss: 1.8617\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 1.7034 - val_loss: 1.8823\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7105 - val_loss: 1.8569\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7096 - val_loss: 1.8373\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7081 - val_loss: 1.8535\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7005 - val_loss: 1.8407\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7564 - val_loss: 1.8908\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 1.7778 - val_loss: 1.9658\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.8131 - val_loss: 1.9804\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7691 - val_loss: 1.9544\n",
      "Epoch 180/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7052 - val_loss: 1.8013\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7104 - val_loss: 1.9021\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7030 - val_loss: 1.8712\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6981 - val_loss: 1.8426\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7018 - val_loss: 1.8440\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7303 - val_loss: 1.9385\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7045 - val_loss: 1.8474\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7465 - val_loss: 2.0334\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.8013 - val_loss: 1.8526\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.6973 - val_loss: 1.8158\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7001 - val_loss: 1.8813\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7026 - val_loss: 1.8485\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7055 - val_loss: 1.9081\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 1.7091 - val_loss: 1.8247\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7183 - val_loss: 1.9507\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 1.7467 - val_loss: 1.8207\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7436 - val_loss: 1.8577\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7240 - val_loss: 1.9905\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.7591 - val_loss: 1.8732\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 1.6977 - val_loss: 1.8435\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 1.7085 - val_loss: 1.9773\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/200\n",
      "800/800 [==============================] - 1s 770us/step - loss: 142.5156 - val_loss: 46.0152\n",
      "Epoch 2/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 33.9316 - val_loss: 18.5143\n",
      "Epoch 3/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 19.9553 - val_loss: 13.4467\n",
      "Epoch 4/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 14.9089 - val_loss: 11.1457\n",
      "Epoch 5/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 12.2334 - val_loss: 9.8986\n",
      "Epoch 6/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 10.8102 - val_loss: 8.9665\n",
      "Epoch 7/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 9.8136 - val_loss: 8.3245\n",
      "Epoch 8/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 9.1000 - val_loss: 7.9094\n",
      "Epoch 9/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 8.7032 - val_loss: 7.5882\n",
      "Epoch 10/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 8.4165 - val_loss: 7.4447\n",
      "Epoch 11/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 8.1757 - val_loss: 7.2196\n",
      "Epoch 12/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 7.9841 - val_loss: 7.0181\n",
      "Epoch 13/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 7.7899 - val_loss: 6.8237\n",
      "Epoch 14/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 7.6064 - val_loss: 6.6855\n",
      "Epoch 15/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 7.4244 - val_loss: 6.5110\n",
      "Epoch 16/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 7.2827 - val_loss: 6.3274\n",
      "Epoch 17/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 7.0792 - val_loss: 6.1499\n",
      "Epoch 18/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 6.9310 - val_loss: 6.0181\n",
      "Epoch 19/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 6.7833 - val_loss: 5.8662\n",
      "Epoch 20/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 6.6280 - val_loss: 5.7439\n",
      "Epoch 21/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 6.4875 - val_loss: 5.5842\n",
      "Epoch 22/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 6.3464 - val_loss: 5.4460\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 100us/step - loss: 6.2289 - val_loss: 5.3365\n",
      "Epoch 24/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 6.1099 - val_loss: 5.2163\n",
      "Epoch 25/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 6.0226 - val_loss: 5.1658\n",
      "Epoch 26/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 5.9177 - val_loss: 4.9859\n",
      "Epoch 27/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 5.7984 - val_loss: 4.8367\n",
      "Epoch 28/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 5.6087 - val_loss: 4.7378\n",
      "Epoch 29/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 5.5020 - val_loss: 4.6404\n",
      "Epoch 30/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 5.2796 - val_loss: 4.3783\n",
      "Epoch 31/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 5.0376 - val_loss: 4.0171\n",
      "Epoch 32/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 4.5226 - val_loss: 3.6150\n",
      "Epoch 33/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 4.1902 - val_loss: 3.4629\n",
      "Epoch 34/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 3.9664 - val_loss: 3.2624\n",
      "Epoch 35/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 3.8223 - val_loss: 3.0960\n",
      "Epoch 36/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 3.6653 - val_loss: 2.9509\n",
      "Epoch 37/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 3.5779 - val_loss: 2.8479\n",
      "Epoch 38/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 3.4473 - val_loss: 2.7593\n",
      "Epoch 39/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 3.3009 - val_loss: 2.6590\n",
      "Epoch 40/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 3.2619 - val_loss: 2.6223\n",
      "Epoch 41/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 3.1436 - val_loss: 2.5347\n",
      "Epoch 42/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 3.0587 - val_loss: 2.4486\n",
      "Epoch 43/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 3.0056 - val_loss: 2.4189\n",
      "Epoch 44/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.9567 - val_loss: 2.3780\n",
      "Epoch 45/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.9038 - val_loss: 2.3323\n",
      "Epoch 46/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.8625 - val_loss: 2.2730\n",
      "Epoch 47/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.8411 - val_loss: 2.2260\n",
      "Epoch 48/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.8018 - val_loss: 2.2377\n",
      "Epoch 49/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.7796 - val_loss: 2.1763\n",
      "Epoch 50/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.7407 - val_loss: 2.2048\n",
      "Epoch 51/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.7282 - val_loss: 2.1197\n",
      "Epoch 52/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.6903 - val_loss: 2.1706\n",
      "Epoch 53/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.6867 - val_loss: 2.1170\n",
      "Epoch 54/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.6918 - val_loss: 2.0813\n",
      "Epoch 55/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.6610 - val_loss: 2.0710\n",
      "Epoch 56/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.7532 - val_loss: 2.1602\n",
      "Epoch 57/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.6404 - val_loss: 2.0313\n",
      "Epoch 58/200\n",
      "800/800 [==============================] - 0s 107us/step - loss: 2.6232 - val_loss: 2.0699\n",
      "Epoch 59/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.6340 - val_loss: 2.0414\n",
      "Epoch 60/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 2.5891 - val_loss: 1.9930\n",
      "Epoch 61/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.5696 - val_loss: 1.9420\n",
      "Epoch 62/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.5521 - val_loss: 1.9307\n",
      "Epoch 63/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.5606 - val_loss: 1.9414\n",
      "Epoch 64/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.5839 - val_loss: 2.0631\n",
      "Epoch 65/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.6538 - val_loss: 1.9557\n",
      "Epoch 66/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.6228 - val_loss: 1.8975\n",
      "Epoch 67/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.5359 - val_loss: 1.9069\n",
      "Epoch 68/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.5161 - val_loss: 1.8678\n",
      "Epoch 69/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.5171 - val_loss: 1.8559\n",
      "Epoch 70/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.5146 - val_loss: 1.8999\n",
      "Epoch 71/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4890 - val_loss: 1.8425\n",
      "Epoch 72/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.5440 - val_loss: 1.8451\n",
      "Epoch 73/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4923 - val_loss: 1.8859\n",
      "Epoch 74/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.5121 - val_loss: 1.9098\n",
      "Epoch 75/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4766 - val_loss: 1.8603\n",
      "Epoch 76/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.4680 - val_loss: 1.8419\n",
      "Epoch 77/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4915 - val_loss: 1.8647\n",
      "Epoch 78/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.4446 - val_loss: 1.8187\n",
      "Epoch 79/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.4644 - val_loss: 1.8078\n",
      "Epoch 80/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.4476 - val_loss: 1.8152\n",
      "Epoch 81/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4803 - val_loss: 1.8483\n",
      "Epoch 82/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.4796 - val_loss: 1.7906\n",
      "Epoch 83/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4644 - val_loss: 1.7730\n",
      "Epoch 84/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4571 - val_loss: 1.7683\n",
      "Epoch 85/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.4400 - val_loss: 1.7782\n",
      "Epoch 86/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.5385 - val_loss: 1.7743\n",
      "Epoch 87/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.4618 - val_loss: 1.7715\n",
      "Epoch 88/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4408 - val_loss: 1.7824\n",
      "Epoch 89/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4307 - val_loss: 1.7479\n",
      "Epoch 90/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3989 - val_loss: 1.7716\n",
      "Epoch 91/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.4192 - val_loss: 1.7683\n",
      "Epoch 92/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.4580 - val_loss: 1.8763\n",
      "Epoch 93/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.4001 - val_loss: 1.7338\n",
      "Epoch 94/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.4141 - val_loss: 1.7488\n",
      "Epoch 95/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4166 - val_loss: 1.7235\n",
      "Epoch 96/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.4142 - val_loss: 1.7338\n",
      "Epoch 97/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3941 - val_loss: 1.7697\n",
      "Epoch 98/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3947 - val_loss: 1.7660\n",
      "Epoch 99/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3739 - val_loss: 1.7286\n",
      "Epoch 100/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3791 - val_loss: 1.7028\n",
      "Epoch 101/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3886 - val_loss: 1.7360\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 102us/step - loss: 2.3934 - val_loss: 1.7911\n",
      "Epoch 103/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.4156 - val_loss: 1.7413\n",
      "Epoch 104/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.4447 - val_loss: 1.7155\n",
      "Epoch 105/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3889 - val_loss: 1.7004\n",
      "Epoch 106/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4191 - val_loss: 1.7247\n",
      "Epoch 107/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3647 - val_loss: 1.6885\n",
      "Epoch 108/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.4265 - val_loss: 1.6986\n",
      "Epoch 109/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4497 - val_loss: 1.7057\n",
      "Epoch 110/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3953 - val_loss: 1.7053\n",
      "Epoch 111/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4309 - val_loss: 1.8179\n",
      "Epoch 112/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.4163 - val_loss: 1.6771\n",
      "Epoch 113/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4456 - val_loss: 1.8335\n",
      "Epoch 114/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.4520 - val_loss: 1.7307\n",
      "Epoch 115/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3895 - val_loss: 1.6449\n",
      "Epoch 116/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3413 - val_loss: 1.6411\n",
      "Epoch 117/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3716 - val_loss: 1.6593\n",
      "Epoch 118/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3734 - val_loss: 1.6358\n",
      "Epoch 119/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3597 - val_loss: 1.6099\n",
      "Epoch 120/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3694 - val_loss: 1.7073\n",
      "Epoch 121/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3675 - val_loss: 1.5856\n",
      "Epoch 122/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3476 - val_loss: 1.6390\n",
      "Epoch 123/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3903 - val_loss: 1.6976\n",
      "Epoch 124/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.2850 - val_loss: 1.7176\n",
      "Epoch 125/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.4056 - val_loss: 1.6438\n",
      "Epoch 126/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.3893 - val_loss: 1.7077\n",
      "Epoch 127/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 2.5475 - val_loss: 1.5840\n",
      "Epoch 128/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3900 - val_loss: 1.6532\n",
      "Epoch 129/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3679 - val_loss: 1.6235\n",
      "Epoch 130/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3797 - val_loss: 1.5938\n",
      "Epoch 131/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3201 - val_loss: 1.5903\n",
      "Epoch 132/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3328 - val_loss: 1.6014\n",
      "Epoch 133/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3435 - val_loss: 1.6087\n",
      "Epoch 134/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3351 - val_loss: 1.6034\n",
      "Epoch 135/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3959 - val_loss: 1.5663\n",
      "Epoch 136/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 2.3320 - val_loss: 1.6070\n",
      "Epoch 137/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3105 - val_loss: 1.5635\n",
      "Epoch 138/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3333 - val_loss: 1.6015\n",
      "Epoch 139/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3223 - val_loss: 1.5757\n",
      "Epoch 140/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3133 - val_loss: 1.6421\n",
      "Epoch 141/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3881 - val_loss: 1.5631\n",
      "Epoch 142/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 2.4071 - val_loss: 1.5912\n",
      "Epoch 143/200\n",
      "800/800 [==============================] - 0s 104us/step - loss: 2.3958 - val_loss: 1.5845\n",
      "Epoch 144/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 2.3859 - val_loss: 1.6764\n",
      "Epoch 145/200\n",
      "800/800 [==============================] - 0s 107us/step - loss: 2.3952 - val_loss: 1.6869\n",
      "Epoch 146/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4145 - val_loss: 1.5725\n",
      "Epoch 147/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.3656 - val_loss: 1.5919\n",
      "Epoch 148/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.2965 - val_loss: 1.5526\n",
      "Epoch 149/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3139 - val_loss: 1.5582\n",
      "Epoch 150/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.3606 - val_loss: 1.6074\n",
      "Epoch 151/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3356 - val_loss: 1.5547\n",
      "Epoch 152/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3352 - val_loss: 1.5659\n",
      "Epoch 153/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3081 - val_loss: 1.6066\n",
      "Epoch 154/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.2951 - val_loss: 1.5940\n",
      "Epoch 155/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3910 - val_loss: 1.5829\n",
      "Epoch 156/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3435 - val_loss: 1.6572\n",
      "Epoch 157/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3398 - val_loss: 1.5599\n",
      "Epoch 158/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3844 - val_loss: 1.5684\n",
      "Epoch 159/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3203 - val_loss: 1.5651\n",
      "Epoch 160/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3489 - val_loss: 1.5675\n",
      "Epoch 161/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.3659 - val_loss: 1.5564\n",
      "Epoch 162/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3661 - val_loss: 1.5598\n",
      "Epoch 163/200\n",
      "800/800 [==============================] - 0s 97us/step - loss: 2.3488 - val_loss: 1.7725\n",
      "Epoch 164/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.4089 - val_loss: 1.5484\n",
      "Epoch 165/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3130 - val_loss: 1.6380\n",
      "Epoch 166/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3841 - val_loss: 1.5650\n",
      "Epoch 167/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 2.3135 - val_loss: 1.5621\n",
      "Epoch 168/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3213 - val_loss: 1.5668\n",
      "Epoch 169/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3291 - val_loss: 1.6661\n",
      "Epoch 170/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3490 - val_loss: 1.5839\n",
      "Epoch 171/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3056 - val_loss: 1.5453\n",
      "Epoch 172/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3170 - val_loss: 1.5541\n",
      "Epoch 173/200\n",
      "800/800 [==============================] - 0s 98us/step - loss: 2.3800 - val_loss: 1.6156\n",
      "Epoch 174/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.2975 - val_loss: 1.5367\n",
      "Epoch 175/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3771 - val_loss: 1.5957\n",
      "Epoch 176/200\n",
      "800/800 [==============================] - 0s 99us/step - loss: 2.3890 - val_loss: 1.6726\n",
      "Epoch 177/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3760 - val_loss: 1.5461\n",
      "Epoch 178/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3352 - val_loss: 1.6133\n",
      "Epoch 179/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.3420 - val_loss: 1.5654\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 101us/step - loss: 2.4092 - val_loss: 1.7296\n",
      "Epoch 181/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3897 - val_loss: 1.6485\n",
      "Epoch 182/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.3239 - val_loss: 1.5736\n",
      "Epoch 183/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3362 - val_loss: 1.5686\n",
      "Epoch 184/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3380 - val_loss: 1.5573\n",
      "Epoch 185/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3642 - val_loss: 1.6481\n",
      "Epoch 186/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3241 - val_loss: 1.5493\n",
      "Epoch 187/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3024 - val_loss: 1.5457\n",
      "Epoch 188/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3140 - val_loss: 1.5577\n",
      "Epoch 189/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.3695 - val_loss: 1.5710\n",
      "Epoch 190/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3460 - val_loss: 1.6078\n",
      "Epoch 191/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.2913 - val_loss: 1.5584\n",
      "Epoch 192/200\n",
      "800/800 [==============================] - 0s 102us/step - loss: 2.2958 - val_loss: 1.5619\n",
      "Epoch 193/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3312 - val_loss: 1.5669\n",
      "Epoch 194/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3848 - val_loss: 1.5697\n",
      "Epoch 195/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.4021 - val_loss: 1.5284\n",
      "Epoch 196/200\n",
      "800/800 [==============================] - 0s 103us/step - loss: 2.2930 - val_loss: 1.5562\n",
      "Epoch 197/200\n",
      "800/800 [==============================] - 0s 101us/step - loss: 2.3127 - val_loss: 1.5377\n",
      "Epoch 198/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.2928 - val_loss: 1.6223\n",
      "Epoch 199/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.3617 - val_loss: 1.5588\n",
      "Epoch 200/200\n",
      "800/800 [==============================] - 0s 100us/step - loss: 2.4763 - val_loss: 1.5303\n"
     ]
    }
   ],
   "source": [
    "m, v = bst.fit_pred(data_x, data_y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAssAAAHiCAYAAAAeQ4G4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd8XNWZ+P/PmSKNZka9WZZlSe6yZEu40kwJG+IAm++SDWFJCAmhLaT9khAgZROSOAtJIJTQWQIBbCAmlBQTiMEU22CQjYx7kSxbvbcpkqac3x/3jiLZlqvsGcnP+/XSS5p7zz333BlbeubMc5+jtNYIIYQQQgghDmSJ9gCEEEIIIYSIVRIsCyGEEEIIMQwJloUQQgghhBiGBMtCCCGEEEIMQ4JlIYQQQgghhiHBshBCCCGEEMOQYFkIEZOUUtVKqX+L9jhGC6XU7UqpZ4/j+LeVUteO5JiO8vxaKTUlWucXQojhSLAshDhlHE1AqJR6Sim15ESPSRw58zXRSqkFg7ZNUUrpQY/fVkr1KqXyBm37N6VU9UkerhBijJBgWQghjoFSyhbtMcQqpZT1BHbfDhzuTYwX+J8TOAYhxClEgmUhRCybr5TaqpTqUEo9qZRyACilrlNK7VZKtSul/qKUGh85QCl1plLqI6VUl/n9THP7r4BFwANKKY9S6gFluEcp1ayU6lZKbVJKlSilrge+DNxitv2r2Ue1UupWpdQngFcpZVNK3aaUqlRK9ZhjvXTQWL6mlFpjnqtLKbVdKXXBoP1vK6XuUEp9aJ7/VaVU2qD9pyul1iqlOpVSG5VS5w3aV6iUesc87z+BjMM9mUoph1LqWaVUm9nnR0qp7EFN8s3x9iil3lBKZQw6drlSqtG8jneVUsWD9j2llHpYKbVCKeUFzldKxSul7lJK7VNKNSmlHlFKJQw65gdKqQalVL1S6uuHG/sgfwRmK6XOPUSb+4ErlFKTj6JfIYQ4KAmWhRCx7MvAZ4DJwDTgJ0qpTwF3AF8EcoC9wPMAZqD5d4xgKR34HfB3pVS61vrHwHvAN7XWbq31N4ELgXPMvpPNPtu01o8BS4HfmG3/fdCYrgAuBlK01kGgEiMITwZ+DjyrlMoZ1H6h2SYD+Bnw0uCAGLgK+Lp5LUFz7Cilcs1rWQKkATcDf1ZKZZrHLQPWm/3+EvjqETyfXzXHmWc+P/8N+Aft/xJwNZAFxJnnjHgNmGru22A+P+x37K+ARGA1cCfG81oGTAFygZ+a17bY7PvTZp9Hk5vuA/7XPNdw6oDHMV4PIYQ4LhIsCyFi2QNa6xqtdTtGcHQFRgD9B631Bq11H/BD4AylVAFGELtLa/2M1jqotX4O2A78+8G7J4AR3M0AlNZ6m9a64TBjut8ckx9Aa71ca12vtQ5rrV8AdgELBrVvBu7VWgfM/TvMcUY8o7XerLWOpA580UxjuBJYobVeYfb9T6AcuEgpNRGYD/yP1rpPa/0u8NfDjDtyvenAFK11SGu9XmvdPWj/k1rrnea1/Qkj0MW8zj9orXvM5/x2oFQplTzo2Fe11mu01mGgD7ge+K7Wul1r3YMR4P6X2faL5rki1337EYx9sEeBiUqpzx6izR3Avw+eARdCiGMhwbIQIpbVDPp5LzDe/Nob2ai19gBtGDOXQ/YNOi73YJ1rrd8CHgAeBJqVUo8ppZKOYkwopa5SSlWYaQ2dQAlDUyLqtNZ60OPIdQx3jXbz+Hzgski/Zt9nY8xAjwc6zEBz8LGH8wzwOvC8mf7wG6WUfdD+xkE/+wC3eY1WpdSdZrpJN1Btthl8nYOvIxNwAusHjf0f5nbM8e9/3UfMDNh/aX4N16YF47X9xdH0LYQQ+5NgWQgRy/IG/TwRqDe/8iMblVIujNnSuv33DTquzvxZ77cPrfX9Wuu5wEyMtIEfDNd2/+1KqXyMj/u/CaRrrVOAzYAa1D5XKTX4ceQ6hrvGANCKEUw+o7VOGfTl0lrfCTQAqea1Dz72kMzZ7Z9rrWcCZwKXYKSBHM6XgP+HkS6RDBSY2wdf1+DnqxUjvaN40NiTtdZuc3/DQa77aD0JpACfP0Sb3wLnA3OPoX8hhAAkWBZCxLZvKKUmmDm+PwZeAJ4DrlZKlSml4jE+3l+nta4GVgDTlFJfMm++uxwjCP6b2V8TMCnSuVJqvlJqoTm76gV6gfDB2g7DhREktpj9XY0xszxYFvBtpZRdKXUZUGSOM+JKpdRMpZQTYxb0Ra11CHgWI43gM+bMrkMpdZ5SaoLWei9GSsbPlVJxSqmzGT7VZIBS6nyl1CwzzaMbIzAPH+YwMFJV+jBm8J0Yz/mwzFSMx4F7lFJZ5rlzlVKfMZv8CfjaoOv+2RGMYf9zBM3jbj1Em07gbuCWo+1fCCEiJFgWQsSyZcAbQBXGTXJLtNYrMXJ7/4wxQzkZMxdWa92GMVv6fYzA7hbgEq11q9nffcAXlFFd434gCSOo68BIBWjDmI0EeAKYaaYRvHKwwWmtt2IEY+9jBNezgDX7NVuHcRNbK0be9RfMcUY8AzyFkQLhAL5t9l2DMZv7I4xgvAZj1jvye/tLGDcPtmMEjU8P+yz+yzjgRYxAeRvwjnn+w3ka4/mpA7YCHxzBMbcCu4EPzNSNlcB0AK31a8C9wFtmm7eOoL+DeQ7j38Ch3AeEjrF/IYRADU2lE0IIMVKUUl8DrtVanz3M/reBZ7XW/3cyxyWEEOLIycyyEEIIIYQQw5BgWQghxhCl1JeVsZDK/l9boj22I6GU2jLM+L8c7bEJIU5NkoYhhBBCCCHEMGRmWQghhBBCiGFIsCyEEEIIIcQwbNEewGAZGRm6oKAg2sMQQgghhBBj3Pr161u11pmHaxdTwXJBQQHl5eXRHoYQQgghhBjjlFJ7j6SdpGEIIYQQQggxDAmWhRBCCCGEGIYEy0IIIYQQQgwjpnKWhRBCCCFiQSAQoLa2lt7e3mgPRRwnh8PBhAkTsNvtx3S8BMtCCCGEEPupra0lMTGRgoIClFLRHo44Rlpr2traqK2tpbCw8Jj6kDQMIYQQQoj99Pb2kp6eLoHyKKeUIj09/bg+IZBgWQghhBDiICRQHhuO93WUYFkIIYQQQohhSLAshBBCCHE82uvB1zV0m6/L2H6MOjs7eeihh476uIsuuojOzs5jPi9AdXU1JSUlh22zbNmy4zrPaCHBshBCCCHE8XC4oGHXvwJmX5fx2OE65i6HC5aDweAhj1uxYgUpKSnHfN4jJcGyEEIIIYQ4Ms5kyJlqBMitNcb3nKnG9mN02223UVlZSVlZGfPnz2fRokV87nOfY+bMmQD8x3/8B3PnzqW4uJjHHnts4LiCggJaW1uprq6mqKiI6667juLiYi688EL8fv+w51u/fj2lpaWUlpby4IMPDmyvrq5m0aJFzJkzhzlz5rB27dqB8b333nuUlZVxzz33DNtuTNBax8zX3LlztRBCCCFEtG3duvXoD2rZp/WO943vx2nPnj26uLhYa631qlWrtNPp1FVVVQP729ratNZa+3w+XVxcrFtbW7XWWufn5+uWlha9Z88ebbVa9ccff6y11vqyyy7TzzzzzLDnmzVrln7nnXe01lrffPPNA+f2er3a7/drrbXeuXOnjsRqq1at0hdffPHA8cO1ixUHez2Bcn0E8anUWRZCCCGEOF6+LuhqgrRc47sz6bhmlve3YMGCIXWC77//fl5++WUAampq2LVrF+np6UOOKSwspKysDIC5c+dSXV190L47Ozvp7OzknHPOAeArX/kKr732GmAszvLNb36TiooKrFYrO3fuPGgfR9puNJJgWQghhBDieERylCOpF86kEUnFGMzl+lf+89tvv83KlSt5//33cTqdnHfeeQetIxwfHz/ws9VqPWQaxnDuuecesrOz2bhxI+FwGIfDcVztRiPJWRZCCCGEOB693qGBcSSHudd7zF0mJibS09Nz0H1dXV2kpqbidDrZvn07H3zwwTGfByAlJYWUlBRWr14NwNKlS4ecKycnB4vFwjPPPEMoFDro+IZrNxZIsCyEEEIIcTzSxh84g+xMNrYfo/T0dM466yxKSkr4wQ9+MGTf4sWLCQaDFBUVcdttt3H66acf83kinnzySb7xjW9QVlaGkc5ruOmmm/jjH/9IaWkp27dvH5jhnj17NlarldLSUu65555h240FavATEm3z5s3T5eXl0R6GEEIIIU5x27Zto6ioKNrDECPkYK+nUmq91nre4Y6VnGUhhBAiyrQGXx/0BaCv3/xufgWCEGcDRxwkxEO83fjuiAObNdojF2Lsk2BZCCGEOEn6A7C3CRrbob4N9jZCbSu0dkIgBFYLWBQotd+BkccawhpCYQiHweWAnHQoyIb8ccbPOemQmQwWSbQUB/GNb3yDNWvWDNn2ne98h6uvvjpKI4p9EiwLIYQQJ4jWUNMMn1TBB1thVx3YLMb2/qARA1ssxpfdepAgeaCjf/1oUWCxgrYYwXdVPeyuM/uwQShkzDiXFMLc6VBcADlph+hbnFIGLzgijowEy0IIIcQICoXhk0p4dyNs2GUExeGwMSNsN9MmlDLSKY6HMmegh8wga2N2OhSC8h1QsdvYHB8HpZPgrFkwZ6oRVAshjoz8dxFCCCFGQI8PVn0Mf1kLvl4jSLZZzdSKk5xbbLFAvBlEa23kQa/dYgTQFit8qgz+bS5MzD654xJiNJJgWQghhDgOexrgr+/D2s3GY62NIPl4Z45HilJgVUbQDhAMwmsfwhvlMC4NLjkdzigx8p+FEAeS9H8hhBDiGOxpgB//H/zwcXjvEzMotcR+hQqrxaiuYVFQ3wpPrIAb7oZX1xg50GLscrvdANTX1/OFL3zhkG3vvfdefD7fwOOLLrqIzs7OEzq+WCV1loUQQoij0N4Dz7wB728xcoPtttF/81wobHx3OuCqC2HR7H/NRJ+qRkud5VAohNV6ZO/Q3G43Ho/niNoWFBRQXl5ORkbG8QwvZhxPneVT/L+CEEIIcWR6++GFVfCNe2HNZmNmNs4++gNlMAJjqwW8fnjkL/Dt38OGnUZKiYie6upqZsyYwZe//GWKior4whe+gM/no6CggFtvvZU5c+awfPlyKisrWbx4MXPnzmXRokVs374dgD179nDGGWcwa9YsfvKTnwzpt6SkBDCC7ZtvvpmSkhJmz57N73//e+6//37q6+s5//zzOf/88wEjeG5tbQXgd7/7HSUlJZSUlHDvvfcO9FlUVMR1111HcXExF154IX6//2Q+XSeM5CwLIYQQh6A1rN5kpCv09hvl3uwxnmpxrGxW43pbOuA3z8PkXPjeZZCeFO2RRdcP/+8tNu1pHtE+ZxVmcce1nzpsux07dvDEE09w1lln8fWvf52HHnoIMJbD3rBhAwAXXHABjzzyCFOnTmXdunXcdNNNvPXWW3znO9/hxhtv5Kqrrhq2ZNxjjz1GdXU1FRUV2Gw22tvbSUtL43e/+x2rVq06YGZ5/fr1PPnkk6xbtw6tNQsXLuTcc88lNTWVXbt28dxzz/H444/zxS9+kT//+c9ceeWVx/lMRZ/MLAshhBDD6PLCHUvhwVfA32dWthjjfzmVMlJLLAp21cD/9wB8tD3aozp15eXlcdZZZwFw5ZVXsnr1agAuv/xyADweD2vXruWyyy6jrKyMG264gYaGBgDWrFnDFVdcAcBXvvKVg/a/cuVKbrjhBmw2Y/40LS3tkONZvXo1l156KS6XC7fbzec//3nee+89AAoLCykrKwNg7ty5VFdXH8eVx44RmVlWSv0BuARo1lqXmNtuB64DWsxmP9JarxiJ8wkhhBAn2oadcN+fwd9vLCSixniQvL9I0NwfgLv+ZJSbu/qzRurJqeZIZoBPFLVfnk/kscvlAiAcDpOSkkJFRcURHX8ixcfHD/xstVrHTBrGSP3XfwpYfJDt92ity8wvCZSFEELEPH8fPPgy/Pp5I+3ikCvrnQJsVqP03Fsfw/ceMlYkFCfPvn37eP/99wFYtmwZZ5999pD9SUlJFBYWsnz5cgC01mzcuBGAs846i+effx6ApUuXHrT/T3/60zz66KMEg0EA2tvbAUhMTKSnp+eA9osWLeKVV17B5/Ph9Xp5+eWXWbRo0QhcaewakWBZa/0u0D4SfQkhhBDRsrMWvvN7eHeTESDGehm4kyVSFq+pA255FP4phatOmunTp/Pggw9SVFRER0cHN9544wFtli5dyhNPPEFpaSnFxcW8+uqrANx33308+OCDzJo1i7q6uoP2f+211zJx4kRmz55NaWkpy5YtA+D6669n8eLFAzf4RcyZM4evfe1rLFiwgIULF3Lttddy2mmnjfBVx5YRKx2nlCoA/rZfGsbXgG6gHPi+1rrjUH1I6TghhBDRoDW8/hE89Q+jjFqc3P4+rFAYNHDRQvjKp8duDncslI6rrq7mkksuYfPmzVEdx1gQq6XjHgYmA2VAA3D3wRoppa5XSpUrpcpbWloO1kQIIYQ4YYIho1zak/8wHkugfGhWi3Hz34oP4L6XjOdPiLHshAXLWusmrXVIax0GHgcWDNPuMa31PK31vMzMzBM1HCGEEOIA3V746R/g7YqhS0KLQ7OYz9UHW+BXzxq53WLkFRQUyKxyDDhhvxaUUjmDHl4KyKsthBAiZuxrgu8/BLvrjcDvVL6J71hE8pi3VsNPnoAe32EPEWJUGpFgWSn1HPA+MF0pVauUugb4jVJqk1LqE+B84LsjcS4hhBDieJXvgNseN+oon+rVLo5HJGCuaYZbH4WWzmiPSIiRNyKZWVrrKw6y+YmR6FsIIYQYSf/40MxP1kYdYXF8lFk1pLXLCJj/9zoYd+h1LYQYVSQ7SwghxClBa3jxHSNQVkhZuJFmt4HHb6RkyAyzGEskWBZCCDHmhcNGkLz8beMPn9zId2LYbcZNkz/5A3QcuJ6FOAqdnZ089NBD0R6GQIJlIYQQY1woBA+8Aq9/aNQEHqt1gWOF3WYEyv/zB7np73gMFyxHVtoTJ4/8yhBCCDFm9QeNZavXbPpXfWBx4tksRirGz54Cb2+0RzM63XbbbVRWVlJWVsb8+fNZtGgRn/vc55g5cybV1dWUlJQMtL3rrru4/fbbAaisrGTx4sXMnTuXRYsWsX379ihdwdghtzYIIYQYk3r7jRrAO2ukNNzJFqmSUdsCv3wabv8aOOKiParj8Poj0FQ5sn1mT4bP/Pewu++88042b95MRUUFb7/9NhdffDGbN2+msLCQ6urqYY+7/vrreeSRR5g6dSrr1q3jpptu4q233hrZsZ9iJFgWQggx5vQFjCBtd50EytGilDHDvKcB7lgKP/mKVB85HgsWLKCwsPCQbTweD2vXruWyyy4b2NbX13eihzbmyT9bIYQQY0p/AJY8I4FyLIjMMG/fB79/Cb572Sh9PQ4xA3yyuFyugZ9tNhvhcHjgcW+vkesSDodJSUmhoqLipI9vLJOcZSGEEGNGfxD+d6mkXsSSSMC8bhu8sCraoxk9EhMT6ek5eEmR7OxsmpubaWtro6+vj7/97W8AJCUlUVhYyPLlywHQWrNx48aTNuaxSmaWhRBCjAmBIPx6GWzbK4FyrFHKuLny5dWQkwbnlkV7RLEvPT2ds846i5KSEhISEsjOzh7YZ7fb+elPf8qCBQvIzc1lxowZA/uWLl3KjTfeyJIlSwgEAvzXf/0XpaWl0biEMUNpraM9hgHz5s3T5eXl0R6GEEKIUSYYgt88BxsrJVCOZSEzc+B/roLigqgO5bC2bdtGUVFRtIchRsjBXk+l1Hqt9bzDHStpGEIIIUa1YAju/pMEyqOB1WIsEHPnMqhrjfZohDgyEiwLIYQYtbSGB1+BDTslUB4t7DajrN/Pn4Iub7RHI8ThSbAshBBi1HrmDVi7RQLl0SbOBp1eo2pJfyDaoxHi0CRYFkIIMSr9dS38fZ1x45gEyqOPzQL7muD+l4xPCISIVRIsCyGEGHXe+wSWrjT+iMkS1qNTpKTcRzvgldXRHo0Qw5NgWQghxKhSsdvIUwawyF+xUU0pIxB5fpWRdy5ELJJfM0IIIUaN3XVGiTitjVlJMfpZLICGu5dDbUu0RxNb7rvvPkpKSiguLubee+8d2H777beTm5tLWVkZZWVlrFixAoA1a9Ywe/Zs5s2bx65duwDo7OzkwgsvHLLi34mwfPlyioqKOP/88ykvL+fb3/72QdsVFBTQ2jq6SqHIoiRCCCFGhfo2+MUfjVJxdvnrNabYrMaNfr98Gu6+CdwJ0R7Rga6/G9q6Rq6/9GR47PvD79+8eTOPP/44H374IXFxcSxevJhLLrmEKVOmAPDd736Xm2++ecgxd999NytWrKC6uppHHnmEu+++myVLlvCjH/0Iywn+GOaJJ57g8ccf5+yzzwZg3rzDli8eNeR9uRBCiJjX7YXbnzRKjkmgPFS2rseth0Zxbt1Ftq6P0oiOTZwNOjzGJwehULRHc6C2LnDEjdzX4QLvbdu2sXDhQpxOJzabjXPPPZeXXnrpkMfY7XZ8Ph8+nw+73U5lZSU1NTWcd955wx7z0UcfceaZZ1JaWsqCBQvo6emht7eXq6++mlmzZnHaaaexapWxTvlTTz3F5z//eRYvXszUqVO55ZZbAPjFL37B6tWrueaaa/jBD37A22+/zSWXXGI8b21tXHjhhRQXF3PttdcyeDG8Z599lgULFlBWVsYNN9xAyHzh3W43P/7xjyktLeX000+nqakJgKamJi699FJKS0spLS1l7dq1h+xnpEiwLIQQIqb1B+FXS41SYxIoH8iLi0J2DQTMbt1FIbvw4oryyI6ezQI7auGPr0d7JNFXUlLCe++9R1tbGz6fjxUrVlBTUzOw/4EHHmD27Nl8/etfp6OjA4Af/vCHXHXVVdxxxx1885vf5Mc//jFLliwZ9hz9/f1cfvnl3HfffWzcuJGVK1eSkJDAgw8+iFKKTZs28dxzz/HVr36V3t5eACoqKnjhhRfYtGkTL7zwAjU1Nfz0pz9l3rx5LF26lN/+9rdDzvHzn/+cs88+my1btnDppZeyb98+wHgz8MILL7BmzRoqKiqwWq0sXboUAK/Xy+mnn87GjRs555xzePzxxwH49re/zbnnnsvGjRvZsGEDxcXFh+xnpEiwLIQQImZpDQ+8BNUNRiAlDuRRyexhKoXsIkfXUMgu9jAVj0qO9tCOmlJGdZPXy+HtimiPJrqKioq49dZbufDCC1m8eDFlZWVYrVYAbrzxRiorK6moqCAnJ4fvf9/I5ygrK+ODDz5g1apVVFVVkZOTg9aayy+/nCuvvHJghjZix44d5OTkMH/+fACSkpKw2WysXr2aK6+8EoAZM2aQn5/Pzp3GHZgXXHABycnJOBwOZs6cyd69ew95He++++5AXxdffDGpqakAvPnmm6xfv5758+dTVlbGm2++SVVVFQBxcXEDM9Nz586luroagLfeeosbb7wRAKvVSnJy8iH7GSnyHl0IIUTMWv4OfLhdFh05HBdefLgYRx2N5OJRybh1Fy68NKnx0R7eUbEo403So3+FvCyYPLqGP6KuueYarrnmGgB+9KMfMWHCBACys7MH2lx33XUDgWWE1polS5bw/PPP861vfYvf/OY3VFdXc//99/OrX/3quMYUHx8/8LPVaiUYDB5TP1prvvrVr3LHHXccsM9ut6PM//CHO8eh+hkp8j5dCCFETFqzCf78LijGfqB8tHnHB7YPcRofYKefDJrINmeYR2MqBhhvjoIh+NWzp/aS2M3NzQDs27ePl156iS996UsANDQ0DLR5+eWXKSkpGXLc008/zUUXXURaWho+nw+LxYLFYsHn8w1pN336dBoaGvjoo48A6OnpIRgMsmjRooFUhp07d7Jv3z6mT59+TNdwzjnnsGzZMgBee+21gZSRCy64gBdffHHgGtvb2w87S33BBRfw8MMPAxAKhejq6jqmfo6WzCwLIYSIOTtr4YFXQGmwWKM9GkO2rseLa0h6w0jN3kbyjvfoqQOzwpF0ikO19+pEvDjJp4pmxgEa0FzAa7zJZ0dlKkZEnA08fvj1c/CLq42KGaea//zP/6StrQ273c6DDz5ISkoKALfccgsVFRUopSgoKODRRx8dOMbn8/HUU0/xxhtvAPC9732Piy66iLi4uIGgNSIuLo4XXniBb33rW/j9fhISEli5ciU33XQTN954I7NmzcJms/HUU08NmVE+Gj/72c+44oorKC4u5swzz2TixIkAzJw5kyVLlgyUtYtcY35+/rB93XfffVx//fU88cQTWK1WHn74Yc4444yj7udoKR1Da0zOmzdPl5eXR3sYQgghoqipA255BPx9sXVD3+AAdv+AdiSC0kh/rWSTQdNh+3XrLmZSQTb1dJHCBs4km3pms57dTKeZ3FGXgrE/rSEUhgvnwzUXndxzb9u2jaKiooHHJ7t0nBhZ+7+eAEqp9Vrrw9a4i6FfQ0IIIU51vf1Grd1YC5TBvJFOGzfSteojC2gHO9zMtEcl06qzh+QdH248NXoSNkLY6SObOorZyCfMxYl31KZgDKaUsWjJG+UwbQIsmh29sUhge+qSnGUhhBAxQWu490Vo6Yzdj9w9KplWjIC2lezDBrSDc4sjqRPZumZg++C8YrfuIoMmGsklg6YDcpj3F2m/h6nE42cea9lCKZWqaKA6xuH6GA0sykjHeehVqG6M9mjEqUiCZSGEEDHhpfegYndsV744koB2uADZhZdmslnIatwMn9LRoPIOG+wObt9DEhpFB2mk04Jbdw2Uk3MxNu6Os1qNhUqWPAM9vsO3F2IkSbAshBAi6j7eBcvfju3KF27dxRzW0Uz2kIA2MlMcEQmQC/UOgEEBcif5VNFALkl0DZmZduEdktJxuGA30h6gkF28z6dYywW0MG4gyPao5FGfszyY3WYEyr953shjPhli6b4uceyO93WUYFkIIURUNbTB3X8y0jAsMfxXyYWXHRSRZc4oe1QyzWQzja1D8oMjgW4mjcxlLflUsYVSsmkglTZS6aCb5CEz015cBwTGhwp2IznOg4Nsj0pmj5p+0CB7rCyJbbUYlVKef/PEn8vhcNDW1iYB8yintaatrQ2Hw3HMfcTY7RNCCCFOJb4+46OSzH3lAAAgAElEQVT1voBRKiyWRQJXr04acpPfx5x+QO5y5Oa7QnaSSjsJ+HDgJ5EuNrBwICWjkF0062yyzNzjgznaknUelYyHoeM52tJ0sUopY5bvL2thxkSYe2ylf4/IhAkTqK2tpaWl5cSdRJwUDodjYEGXYxHjv5qEEEKMVeEw3LscWrtiP1Ae7EiqVkRym5sYTyG7qGcCdeTTQhZZNNGMESD7cDKNrQcE3IMDZC8uTuMD6nQeXlIGAt9mssnW9UeUanG8lTxiiUVBGLjnRbjrRhiXdmLOY7fbKSwsPDGdi1Elhj/wEkIIMZa9+C58UmV8tD6aHO4mv0l6B2ewimaySaWNFrKw008hu3Dho5lsMmillWyS6GY3MweC1ki6RCQgjvTtJ4F/YwVZ1A0Eylk0HVAe7lDpFoOXxI7kS++fijFa0jVsVugPwP8+a5QbFOJEGmW/ooQQQowFn1SOzqWs969a4SGRmVQMCTAT8BCPn+lsxkkPvSSQSBd2/EyginyqaCWDPKoIYD8gd7mQXQDsYSozqWAua7GgeZ9zmcIOFJr5rMWLc7/Z6BryqBoSZA8tTxeimIqBfOmDLYm9f5C+f3m7WGKzGgvYPPSqke8uxIkiwbIQQoiTqq0b7noBiPEb+g5m/6oVLYwDIAujALBbd5FGK1spJZ5eHPjNXOVu3PTgwI8XN/lUmcdn4SVxSAWLPUxlDusoYiMptBEgjjYyScCHFxellNNMNiVsJFvXAEagvJDV1JA/UKUjxwyGI3nJWTSxjrNx4sWHk4Wspnm/WtGR8+9/fCymayhlfCqxbiu8/lG0RyPGslGUJSaEEGK0C4bgzmXg74/dPOUjvaEu0q6FcWTSiF87yaOKDjLIoIVO0kikhwya8JCIh0QyaaaDdBz4aDPzl41gdhwuvLi0sfJeHXmcyVu46WILpVzIX/CSQJB4dlDEZHawm2l8lleo0lNJoYN1nE2TygM4IKc6W9cPBL0WDeOoYwulwIGrvxztSoLRpJTx9dQ/YPJ4mHrs93AJMaxR9p5eCCHEaPb067CvGewxukIfHHkqQqSdDycJ+FjAO6SYOcoOfExlG+k0k89u8qmijnz6iGcW68mmgfHUDMz6RgJxLy5mUkEu1TSRQwA7Z7OKfizkU42Nfhz42cRpzGMdmhCF7KSTVJpUHm7dxSS944Cc6kipucH51k5zpnp/R7uSYLRZLcbNoncshe6xsQaLiDEx+r5eCCHEWLNuG7xRbi5fHMN5ykdaOSLSbiYVxOM3ayi3AdBLAh6SSKaDKqbipoe5vE8YmEANPlrZzqVk0cgEqqhl0kC/WdSTSA8fsggFWAmRiJetzCKVNiaxkwIs+Igni0ZaGM8EqpmvV5HHPjwks5tphLEOpFQ062xc+Milmp3MpEnl0WOWwGvW2YCVJjV+4I2Bh0R6SKKHpIGSc8Cw5eqizW4Djx/u+hP87Kuj76ZREdvkn5MQQogTrqEN7v+zufBIDAfKkWoQHpVMK0Yqgg/nIZeNTsCHlTDbKGUfk8lnD/H4cdNNA7nUMJn1nEECXqyE6SWeFsYxm/UUU27e0BcCIJNGuknBi5sS1pNNLT0kE8ZCBq3spBg/TqawlWlsp5aJtJKJRvN5lgJhdjONEjYCoSELp6TSQh15A4uquPCiCZs3CxozzFk04iFxYCVAMG40zKIxZm/0i7BZYcc+ePGdaI9EjDUSLAshhDih+gLGR+SBoBHQxDInPcykgmxdQwZNdJPEaawjg4aDts+kET9OaplIKeUEsNGHnWlspY1sPuB89jKJWVTgw02QOLYzmwYm4MXFOBpZz+mUsJHJeisTqKaddNx0k0UDbnooYjNenLSSwWd5iRIq6CMOCyHy2IeFMIXspp0MekjDhY91nE0WTeToGrLMhVN2MGugdF0hu8ikjjN5l63MGkjRcNFDC+OG3OiXSDcuemL2Rr8IpYw3Yi+9Z1RbEWKkSLAshBDihHr0r0aJr1gPlLN1PT6cOPCxiJX4cJHLXnpx4MJzQO5uod5BJo3sZRIpdLCWc5jMDsZTQxptuOkgn91MZzPx+NEoGsilFwe51NKHg31MAqw0kMsZvE0CPXyKf9BFCtuZRStZaDST2M1EKglhw44PNx56SCGZds7gbYLYqKOAEFY0iiaVh0ZRyE5aycaFlxlsQhNmGltRaIrZSD3jmcmmg1a+GDy73rpf1YxYZbEYn17c9YJRdUWIkSA5y0IIIU6Y1ZtgzWYjhzTW8pQj1SxcGBUoIjfXhbHSRzxzWYudACu5GBc+Mmkcsoy0Ew8pdNCCj53MZDqbsdNPFTOw0c80tpJOO22kU08enaTTSiafYgWgaSWbyWxnIrvZy2R8JDCbj9lDIZPYSS8JOPCxm+lk08gEatnEaeRQi50APbjIpg4/TqyE6COOEjawhym06CxyqMFCmFl8hB83mdRSSBU7mMlUthECsqljG7MZRx3dJOHCO3CN+9/o16OTRkXAbLca1VbuXAZ3XBf7b9JE7JOZZSGEECdEUzs8/CqgYy9Qhn9Vs8iggZlU4MKYinTiIY89ZNFg1kFOoplxuOkZmF0u1Dtw4WEjc3HTgwXMVA0LjeQST4AqphPEip0AYNRk1ljZxyQCxJFCO15cFLCbPCppZRz15DKfdSjCZNJAHEEUGjsBNrCQSeymhWy2UkYhe2gmh3om0oeDXGr4mLkUsJvFvEQl03DRRQkbyKaWVNpx0MMZvIOLTiayl06SGU8Nbjo4jXVEcqfduouZVOAlkQaVN5CSEeuVMSLsVqPqytOvR3skYiyQYFkIIcSIC4bg18/Hdp6yRyXjIZF0mkmlnUWsxE8CU9hGEt18xNloFHNYCzAQME7WW5nCVgC8JNFKNkVsJIF+PuAcrARx00E29bjoIZ1GxlODIkQ6Lfhw4sTPOOroIp3NlFJIJVPZTBYNNJLFBPbiIYkEupjFx1QxmTRaaSGTKewkj0payCKOfqwE2cZsqpmCxk4l05hANcVU4KAPgHx2E0e/+VhjJ4SHBKaznR4zYG9mHPlUka1rmM4mAJrNRVciOcyHutExlkTyl1//CD7YGu3RiNFOgmUhhBAjbulKqGuN3UA5ooVxKCCAjQDxzGM1WTTyFp/Fh5tKppNFIwXsxqOS8eFkNhvQKFrJ5AzeYhYf4aKHXuJYwHuk00wQO0FsOPAxnjoyqeczvMI0NjGHddQykS5SyaeSPtx8zHyms40U2smmmSaymcJ2UugghIXZlBOPD9B0kEImTbSQjR8Heewhk3ps9JNCGx6SaWA881kDaHpJIIkeJlJFACtuPIyjhhwaqWECJWxmByVs4Ewc+FjAGqyE2ErZAav7xWLZuOFEqq78/iVobI/uWMToJsGyEEKIEfVJJaxYF3v1lLN1PZP0jiGpBAXsJoNG0mgjlz2Mp46dzKSVHHMm1ccGFpJGG5P1NorZSC0TsRDmdN4lmQ5SaTcrYGwHQuRQx2ZK8eEmjJUQVpLpZCJ7mM16ukjGj8tcYMTHdD6hlA1sYRaptOOkh0nsIowFsFBDAQn4SaGNTFroIoV+HKTTjJdEailgJlvIop489lDITtz4aCSHMj4kAR9NZJNIN6l04cGNxkoQCzPYxhZKGEcjRWzEgZ8AVuLpG6iQka3ro/aaHS+b1fh0445l0B+M9mjEaCXBshBCiBHT6YG7l4MOx149ZS8uMmhkJhVmEFjD6awilVYgTJA4mhiHCw8z2QAYqRcaK34czGY9DeSyj0I6SScBDxOpIpUmLubP7GQ6fhKpZCrzWEcm9WY+cxAbAYLYCWCjhAoWsop8qnDgxU0XQSxMZQe1TCSePixoPLjxk8BUthHGSiodNJOJk158JJBDAzYCtJFFIzmMM1cFnM5mPmYh+5hME+PJoYY89lLJNBz4CGKnjgnYCdHIOAqpJIxmBpuYwSYK2UUCHor1+iOurRypTz1YrATaNis0tsEfVkR7JGK0kmBZCCHEiAiH4Z7l4O8zVlSLNR6VzFbKAJjLWhawhn1Mwksik9hFPbkowEaAOHqZwUYK2M0UtpFKO7uZTgptzKYcHwkoQKEZTx0dpDGdLWg0yXSSQSM51NNEFiGspNCJHR/KrLWRSQshFHnU4MdJIh76sJJFMz0kEsBBBi1k0UCCWatjA/NJpot8duHCRx25TKCGKWwjjj6ceHHTSSfpJNNBI7l0kUIYK1YC2OmnxZxhLqCSSqbgoB8IcwbvkkoLueyjHzsOejmDVWiMdzyHC3qPdInwaFDKqMayqsKozCLE0VJa62iPYcC8efN0eXl5tIchhBDiGLy6Gpa9GTtl4iKl4Qbn3bp1FwXsJpsGNLCXSUxmF0m0kUQXNoJUM5l4epnCNnpIopEJNJGLQtNKJjOpoJDdBLAwmSr2kUcWLSiCgAUvbhRhQJGAFzsBQmgSCODHgZ0QmhAu/FQyjXgCQIg8qgGNh2RayWAa21FoFBof8WjshFHYCNNGGr24sNNHOq1oLPQRTxA7PSThIRELYdJop4ksCqjCSQ8dpJFAL/H08glzSaWdVNroJoksmmgjAxshAsSzg5lspxQLmmayceLDR+KwecuRALmV4ZcIj6ZgCKxWuOtGGJ8e7dGIWKCUWq+1nne4djKzLIQQ4rjtaYDn3oqtPOWDzXbOpII0mnHiIY1WitjIbqbSQg7tZJBJPROpJJFuukgjjgD9xDGPtaTQRgYt5uy0poRP2MEMUummhQzceAihSKGDPUzDj5MwFqwESKEbZd72F8BCAr1AiHz2UE8OdgIEsdGLAzu9TGU7vTgIYSOEIoCDeHpJwM8+8nHSi8UsK2chSAJeuknmdT6Hj0QmUslUttFGGnZCBLGgsWIniIck3udc8thHN8l4cZJFEzaCJNNJAj7cdDKRKiaxk2ayyaeKTBpxDiqfFxFJt4j1RUwi+ct3LoP+QLRHI0YTCZaFEEIcl/6AsWJaKGysoHaiHWl+7OAlm0v0euawFgc+enHyIWfRTRJ5VLOIfxKPHx8uekhmGlvJop5yzqaJccxnLbXkkUMdKbRRwse48PARZ5FOGx4SSKGTMIp0WvETx2S2YyNAMl30E48FTTz9JNJFBm14cdJFOvH4OY0PCWCnhWzc+LASwkIYFx76sbOXyTjoBSCAlSzq2cdE0mgnAS+g8eEkjTbm8gHpNOKglxYyGUcDiXQSTx/9xNOHk2aySaaLlVxEDvXkUI8LLwHshLESRx8NTMBGmEJ2cjZvArCVMloYN2y6xf6LmMRiTWa71aj//X9/j/ZIxGgiwbIQQojj8swb0NoFcScpT/lo8mMjs51JdJJMJ21ksZUyvCShUXhxkk0j6bTQSwJ1TKQXB3ns5Vz+Ti41dJDOFHbiwU0WDRSyi50U4SGZIDZyqcVNFxpFN8kk0EcGzWapNkUGzXhw04/dHFUYFz68uAZu6Euig1TaCGAnjgAaRdAMXFNoJ4yVHpLoIB03PgrZjRcXcfQRwk4zuTSRwxS2MoEa+nDgx0UIC3nsJYkOmskiDj9FbMJHApk0E4cfB734SQAYmKHOZR915tgS8OLDPfB8/qve9DbmsI49TAUYWC47lhcxieQvv/OJsbqkEEdCgmUhhBDHbPMeeGP9yZlRjhgcsOXomoEgzaOSD5h1dusu8qiimxSaGI8LD4l0U8guPmEeHWTRQibJdJJFA5k0s45FNDDOLAWnCWBHE2IOH5BFA12kUMwnZFKHRtHIeOwECGMlSBz9xGMjaB4Xx14KiMeHGy8BbPQTj50A6bTQTzy7mEESXcTTSycp9BNHCDs9pBDGYgb5aQSxkogHP/E48eHEi48kvLgJYTWreih6SKSTFKawnVxqiMeHBYWdAPH0YyVEKeuZy3uk0kEnKVgJ0IudfhKMsnEkMoUt1JFHAn4K2cEZrMKtu8x60y5ms5468vCoZFx4h+Qox/IiJkqB0vDQq1DfGu3RiNFgRH69KaX+oJRqVkptHrQtTSn1T6XULvN76kicSwghRGzw+uHuP0WnTNxw+bGDZ50jOcoA1UxhK2Uk4Bu4Cc1LEl2koLHiwsNUtlHDRPLZQxIedjKDqWwni1oS6KWWibSRSSaNeHCTzx7ayGAHs9lOKe1kEo+PdFrw4sJBL1uYhdWsKNGHfeCPrpUQCXjJoJlMWugjHlC48WAhTCM5aCx0kUo/dvKoNW8W7KcfBz0k4cCPIkwNBbjpIolObATpJZ4CqsCsptyPnRbSmcRugijqmYCbbsbTQCcp5nORSCpdWOjHSoAMWughiW5S2E4xabThwMcZvMVkvZViKviEuUYFDt1Fkxp/QI5yLC9iYpX8ZXEURmou4Clg8X7bbgPe1FpPBd40HwshhBgjHvkL+HqjUyZuuPzYwbPOBewGGLISnR8n3SSTRxVzWEsvTrZwGvsowIuLKWwnj2r2kU88ffTgJp9q/DhoIpds6rERpI5CPmEu42hgGlvoJgUbIeLoI4AVC2HqyaOUchLppIck+nBiox87ATy4USiS6MZJDw56sdFPEl0EUSTSRRgIYkWj6MdCEt0EsJFIF2m0YDNv8EukmxTazdnoRDLMffH0E0Sh0KTSTb+5el8S7WbQbSWJThLwEsJGN0n04yCePjpJIYd60mkigX7e4wJ6cdJLArPZwBZKqVRFeEkcqFs9+LWJhfrKh2O3QlMHPCH1l8VhjEiwrLV+F9h/Mcn/B/zR/PmPwH+MxLmEEEJE35rN8OEOI//zZIvkKA/Oj53DOrJ1DTA4T7kLH+6BlegK2UUL46hmCmEzUGwlk3HUkYAHNx5SaKeFLAqpxImPXtzsYQpT2EUZ63DiJQEfQRT5VOKmm0wamMpmNJpWsrARwomfLOqwEcRJD/0kEMCKQhOPn0R6CANhNEl0YKcfCxo/DhLxkUg3yXSRQyMO+jFWDbeQRBd2+ghjw08cVgLksYcANjpIwYkXRQgLmhBgBewEseMjhB0FZNFMG1nUU4CDXsZRTw+J9JCMEx/9xJvhdzpT2YmbNiazgw7SSKKLT5iDEx9u3UUz4wDIpHHIaxML9ZUPJ5K//PZGeH9LtEcjYtmJ/DWXrbVuMH9uBLIP1kgpdb1SqlwpVd7S0nIChzO8+jb46R/A44/K6YUQYlRp74aHXwV0dMrE7Z8f68JrrrBXPpB+MZXN5LCP8dTg1l3kU0Uz2bQwjvP4B71mbvFCVhNHL+m0EI8fP4mk0UICXpJpJ4wihXbazfrExm13fZzH6zjoxU4fHlwk0o0TD258bKKMPuzEE8BGkH4cjKfGrLdspZN0rARJxIdL+7BohYsALvpJwUuC+bObXhwEcNKPk37iCBOPxkkIJ/1k6C7Swy04dAA/LtLpBELY0QSxYAMCWLCYW42c5V78uHDRg51+9jIZhbHsdxI91DERjYUCKkmjmXrGM5UdZNBIMR/TRSqVaubA7D0YM/dueg7IHx8NlAI0PPCyUSVDiIM5KR+eaa21Uuqgq59orR8DHgNjUZKTMZ79dXvhkyr45dPwi69DvP3wxwghxKkoHIZ7XjTyPKO1St/+ebBeXCg0fTiYw1oS6CWdJrpJZjfTKGQXzWSTRRPNQCM5nMNKwkAvLvqwkU0jWykhgV7GU42NMNUUkEMjCXgA6CKZiVQRwoafBBQaL4mk0UoYKwn4aCWTyezGj5tO0kmiy6gmoZ3EhXpwWEIkW3wABMKKbb0uNvsS2ex3U9OXQE/ISnfIRnfIRr9WhLRRuDqOMG5riFRbgDRbgFRrgIJ4P6WuHsqc3RTa9gEQ1NARtGOzhHFaIY4QAXMFP42dfuyEMf74j6OW9ZxBCm2k0ImFID0k4qYHBz6S6WYyO9jFDPLNmyQ7MVbz8Khk9mjjBr4mNZ5WbeSPN5I7agLliEj95TuWwW//OzZXnxTRdSL/STQppXK01g1KqRyg+QSe67i5HFDdCL9+Dn70ZeM/jxBCiKHeKIedtbH1O9Kjktmqy5hJBVPYhgMftRSwkflk0YRG4cRHM9ksZDVbKMWDm0nsoo94xqN5i8XM4QMyaAYU3SSSiMecSQ4RwjJQ2s2BHwsh4ugnhBUvLhLwA5o02gljwYkHa7CHQLifDLuXFKVp1nE83zaOjb4kukM2QDExvo8Ch5eLU9tItQdJsvTjtASIs1gIKytxBLASQgP9YUVb2E13KJ5AuI/mgJN1vbn8rTMLb8hKojVAXlwvZyd2cJqrB4Cavng6w3Zy7X7ctgAhlLnQSjxdpDGNrTjpxYubJDooZT115NJKNtnU4sJLDrUEcGAlRAtZQ553D8lD8senso3w/8/efUfZed/3nX89t87ce6dXYDDoHSQBFpEqpGRVx1LiWI4tr53E5STO2WInOWezm7IbbeK1fSIndlwSa13lJkuWIil2JEuWJVGFkghWkARAgqiDAQbT621z27N/3DsjgKRIyiIwoPS8z+EZAhjM74fnYnA/z/f5/D6fkKlgdP3zcuHSuqi+WUnEuTLHH3yGn/7bG72biJuN6ymW/wI/gf/Q+vjn13Gtb5s179KJ8/zGJ/hnP3hjo5AiIiIibnam5vmjzxK4eVr61sgHXebCAfsdt2CglQ7c6bxOBx3TZ1pJxgmHbXNOTGjKkN1OK0u7w4P6zIgJFbSJIa0opWJJpwHTVrW14uBIaohpSLbEdLPMo6xcj8nX2JEqiic4X273gekRl2tZmVTGmzun/djAM0raVaTV0WtRTaAqJa6xXoddbf1cXV1SVSoWGoyV9SZqYFf7ins7l5UlZRXF1aw2Ao+UhvzuTKek0K2ZFXe0hPOzpYwLlYz9mZL2ZEKIjIKSrDE77XBau2Xbnbcipy4lqdDyNHd60Bv1mzVldF0Ar6WPrFkvGiH3eMDR8F5Tweg1/vKbmTUN8PnHOLyLuw9s9I4ibiZeEbEcBMGH8D3oD4LgEv4fTZH8kSAI/hHG8J5XYq3rydo3y4Mn6cryU3/r5ntDiIiIiNgIGg1+9WPUajf2MfVQOKEge82j/ReaVA6F42531KRNVrUL8Tpf8KS7FOVkreg2Z5endZtXkdBt0VNud8Qjes2qSpnVL2NVvtWIV5GSVVBvJVy0qyjKKou32voyCC1V6uJhYFu6KBkmfGhus3wj6ZbMku8ZTGoEDazYZsqiDp1KLV9xMxc5oyCuLiFUE5dQBxfssMUlZe2yrTrtqpQVOZ2WBa3DhCEaYmKxmNdmZ9yTjQvUlRtxD+a7LNbTdqXz3tE1a6qa8rm5Lh2J0OHObotBv7SKBf3iatoV15M3QgmhUNqq2zzmKXdddYivQ9bKNR7lgk5n7bXXSbGQflOvGg9zEDRjEH/94/zK/8pgFHgb0eIV+ScvDMMf/Sa/9NZX4uvfSIKgeerxrx6mJ8e779voHUVERERsPJ95mPNXbrz9Yn1yGe65JtVibVLZjCiru80jpg17zOtlLbvNowKh1/iqZV2SKvY7rk3BvD6DZswasqxTQ4hAXSAudNlmm024YsSo89pUzOtZT5pIqkqpWA47TJcbBhOrdqaqzpQzPjC71c500ff15YVBIK4hMGNWvwEzJo2YNKLTnN3OKksKxBXkZOWFmofxCDTE7XDWii5TNtnhtIS6ioR2q+b02+yyJT1N24eGpIqGmLyMjJL2WM2+XENDUZuaB1e36WnM+tG+Cfl63Mdnh12sNby9b9VoalJVUk2XTktSaipiJjQtFZ0WvcZXjdl9TWufViLG1a/NvMFXpYc5EW/68X/pw/yHf3Jz2Y0iNo7IaPACxFqC+cNf4POPbvRuIiIiIjaWyflmpTU3/mnbi7X10RTTe51UknXKLWDQlCfdaV5fq9Wuma+cUFGWMeqCy7YYs9MbfV5DoCxtyoicFbs9i4ZRFxRlLeqWVm0djotLKrpcDgT1koPteafLWX8yt0U13uaH+mcd6chrDwpqUlal1aW0WzVtkxlDus3JWPWsvUIJgWZJSa0V7ZZQU9DZnBQLxTT0mPO0w+b0yioJNYy4ZEG3mIaaVGu6HAgF2q0itKJDSlla1ZgdhtKBTe11+UbMZC3rx/on/KvhZzyzVPSrV3aYr+c0WtnOgRAhYu73Tpdt1WVhvQQmq2Da0DWvzbQhAyZfMAP71UIizqVp/vRzG72TiJuFSCx/E2Kx5pvC73yKh57e6N1EREREbAz1Bv/5o9TrG5OpzDdv61v7tce9VkXafscddMx5exR02u1ZV2zWbcFmlzzg7SZtFtMw4qI3+7QlHQq6nXBEXVy7Quu/kqq0oqy6pLKkTivmKoG51aRDbSvGVtt9dHGbndm6d/dNa0/mLOgW17Aqo6ZphQg1VKTVxHWbN2hGSVqbmjE7tNLLlGQVZVSlpa2K4ZSDlnRriCM0b8gzDgkEitrlFC3qUkdKRdCq506oWdSjJKesXa0lypPKZg15Jna7znTSpWDEUj3pH/RP+OcDz/izK2l/NtVhpdGmICcu1GXRG3xeXs5Fu4w6JxcuKcgaNIXQfk8pytjmnAGT12RgrzUqvloIAoIYnzrKsTMbvZuIm4FILL8I8Rhh2IxJOnFho3cTERERceP59FHGpjb2cfQ3a+tbIx90GbdTVUp7q9Bjh9Me8gaDpo0YUxNz2EO2O6MoJ6NoWaeckou22mLcsHFVafP6lLSLq9lkQkKZWsn5UpvtqbIAfzq/3ea2hju7YyZiu1QkdVjSIW/OoKqEqqS8Hkt6JFV1WTJoyhm7tKkas11WwUpLlFakPOFucwaUpdXEDJoyY5MlPRrivuh7LRh0yVZTRozZYdiUQEyltWaIvAwCvaYVWzF2gyZbv2e3kqyahEEzgkSb88F2jSDmvVvOekfntH9zYaf/NjfssfBOhHosqGj3rObJt7Ua8YKM1/mSgqxDnlCUu6YxsZmY0WGwVVpy9Wt6M7f8xYLW+/9HWVjZ6N1EbDSRWH4JEvHmZOUXP9j060VERER8t3Bljg+2HkXfaPvFUDixXjCyZr1Y0amg43mTyjUxfWFF95oAACAASURBVN5eNH20s4ZMG3HJNkUZW4zrM4NAQU5JVkLDaXscdFy3GVllq5JKcuYNaAjEw6orxbqh+IqRZNlH5kfkgw5v710injZj0JwhqzJSqhZ0KemwoE+3JaFQQVZJuzYlC3qtypowose8soxFffI65XUYMmFevwmjlvQKsVmzmTClYrdnPeoeF+zVENdtwZJO04aM26Esa0WnmECfKQ0Ji3pa2dAZm110wFN2OC1tVVHGqnZ9ZgXxhJKELalVv73zuC3xRf/1XN1XKreZNWhRN+JOOgIOOOYWT/iaN6lKO+FIy7rxjdcPZgzLWjEUjq///A6nZa0878bnZhLRyTilVX75I00dEPHdSySWXwbJluH/3/1h07sXERER8Z1OvcGvfJTaDbBfXC2srtqBOxxdf6SPlid22HnNMgw8T0yXZPSZssdxAyY95vWu2KrLnDW9U5XyZW91xYgRl6WVxASmDckqiKlpiFupxsxW4o5klnx+qd9jlc3u7k3oS9UFaEjY5ryDnhRomNGvx5KqmJKcCZv1mm9VYk8pa5OXU5fwlDtVJZWkZZRdsNMFuy3pkVYxZcQJt1vQp02zXnZZp12e8UZ/LcSsYWmrUpoNfnVJX/YWSWErNaNdWdpml+SsuGSreMtU0m1BVVJBTllKu5J2JWVtJuNbzIXd3tw577e3P+bBKxM+vLBHXIC6AZOKcnLyztslEJg0ItPyMF8dKZcLl+SDrvWM65xvvF7Thq+58bkZq7ITcc5c5uNf3uidRGwkkVh+maQSFMv829+LHslERER85/Ppo4xPN4cF15urhRVN0TRoyikH5Kys2yrWDvblg6712Li16mu4w1FjdlrQZ8CUAZMOeMwRDylr12NRVcKSPj0WpFQkVBBz2l4ZZefsFhcKSxdtjc9qizV8dGGLg11xd2cm9ZgRSqiJ67IoUJdQdqGVADHXSr1IKctYtaSrVYF9uytGdVvQZcEdHtLWimi7YLtTbpVVsGDAtKFWPfaqWUOecoc2q3rNqgtsdV6fGT1mzRgyY5NA4KJdbnFMoGZZr2Jrgl7WJsRBx61qM2WzUKhdSVrRgGk1gbqYpFVpFZUgaSnWpaLNL2972n2+6FPjU17T+LxR52TkXbTDDmdNG1r3Jw+aWo/6u/pg5qApJxzRaWndd/5ShzdvBoKgmSv+sS/z9NhG7yZio4jE8rdAKsFSgfd+gEJpo3cTERERcX2YWrix9otvJpqmgtEXPNh39SR6KtgsH3QZMGlOn0FTJmwRCO12wjt9QlnaJTt83I9KqNninNd4QI85szY76TYDpi3oMli/yOq0O9tnfGmlzxPVbV7bU1cL0kKBpIpATawV4ZbQsKhfWllc3Vn7TBiRVFeV0GnZRdulVM0ZNGOTXjN6Teq2qF1RVsmSbjBoQq85q9oMmjZlxFe8XUHWqDHdFq3I2e2UhsCzDvmaN8nK2+a0QdMKOuR1qEq1ZsEJnRbF1LUr6jVrwYCqQJuKsJXHQVwooducnGaax9n4Qeca27yje9Z/Gf6kL4+fdrEUNH3Juh11r8GWj3ztdVyb+l99MLMoI6PwPN/5ix3evFmIxZo54//xw6wUN3o3ERtBJJa/RRLx5hvJz/0Rq9WN3k1ERETEK0sY8hsfvzH2i6t5IdH03IN9O8JTdoanULfDaTvCU4bCcYfCR40aM2a3hsARD2sI7HcCDd3mlLQJxZ21X7c5nRZptfUNmrSox3J5VX+wqCte8cdzWx3pKLkls2S6lahRlHHZFjl5WUUFnSZtUpPUZ1ZFSk5eSYdFvVIqrhjRofk4MmlVSUZRTp95dbHWdHnO3/ZxS3qs6FJr5SxPt67H9/qETouKslYlZOXFVWwxJlT3el8SqBoyqS6mImVRnzkDYhr6zChrV2+lPqdV1AVqUhJWhWKqkoqy6/aSuCpiUqpWYt2mgiFhLO392x61N//fjM2dNRVsNtWaKF8tkKeCzYbCCUPhuH5TlnU65AkFGQ3xaxIyXurw5s1CMkG+zK99rPk9EvHdRSSWv0WCgESMC5O870+bbygRERER3ync/3jTo3kj7BdX81zRNHTVhHntEf+ASVucs805ocDtvubv+rDDHnbKAVnLdnpWm5IBkxpiVrXpM+eIB32/DxtxXs6KurhAaLNxyzoVyyte23bew4Vuny8fdHdfm3SMtLJec2YMqWrTbdmKDqFG6yjdsm6zKpKKcnrNalOSUBFXkVB3zp5WtXRRh0UdVswYklE0Z1C/GXWBzS5pV1QTd8Vm5+2VVrbDGXF1p+3XoagqbcwuZWlv9Wm9Jg2YtaqtdWCw16gLpgxKK5sw6ou+V13Qymim14JOi0pyljXtFnGNlthOyuuSVtJl1mYXTRnx2fh7fK3+Gv+w/5JfzfyCyvRfCsPwGlvMN6i7xwOmDcnrdtxht3gC9fUJ9IDJ573GN3PMXCLG8fN8+qGN3knEjSYSy38D1mqxT1xoTmAa0SnZiIiI7wAWVvj9TyO8sekXVx/SWxNNe51sCq2rIshOOuKSnbosuNXDdnlGjxl5nfY64Qf9sZxFZWlZee3yOqzIy+k3L2fJYY+Z02/MbillqbCsa/W0+9pO+63ZA55q/wFduRErui3pUZfUa8aKLmUpaavKMi7YK6Wqy7xQIKUCJm0WV9WuaFWbpKopI2YNGTQhK2/KoFVtirK6zFuV1m/asEuGjVtqpTHv85Q+MxKtiu1Oyx53l4KcdmVzNqlLaFOx0DoY+IS71KVMG3KbYy7b6rg77fSsJb2K2lSkxdUU5Vo3Dc0XO6a2no7REKhKGDKpKOu0Q8bt9HD8bT4W/oihVN3v9PymrunfF77gqDW+btGIqcsqOupe/WbXLRtFHdc0MT7XxnGzsfY98cd/1RyYRXz3EInlvyFrgvnBk3zgM9FjmYiIiFc3Ycj7/4JKjfgNnipnFeR1rP94rWgkq7geI7b28Vywzzn7dFnSrqwhsMNpb/RZ/WZ0WwA1Cct6rOg0Z6iVOlFs1VaX9ZtSr1Xl6nOGEgX/ceZ2vb2H3J54RkbBJdutSlltJVjsdVJcw7RB7Uo6LFnQqy7QbclJt+g3bUGfRmvtgi5Pu8V2Z2WtiGtY0CunYE6fmHqrEbCiLi6jIKOoy6JRZ+xwRkmbK7YoyiprV5FxzGtk5Q2YVNGmLC2l6pi77HJaRUKXeWXtxm23qE9CQ1XaOfsVdCnICTSUtamKq2hTklm3aiRVtCt5xiEzho0Y02daQc4Tsdf7YOxnzDS6/ZeBjzoy9/Majdp67NtQOKEge43nvCiLuDE716fHa9PoqxMwXnhKffMQj1Fr8L4PUa5s9G4ibhSRWP42WBPMn304ipWJiIh4dfPQMzxxtvmo+UYzFWw285wYMchaWRdRa4kZQ+G4ERcklVUldVi2y9O6LKiKW5WyzTnDLqtIGjRp2EWdlq3Iarcqa0myOm1HfMJcLel3l+5y90C3e2Nf1mfaqpROc6pSahJqkkIx/abNGHLJNl0WpZQU5VwyYq/TLtphv5Mq0r7mLc7YLyevLmarMWfsVZX2dW9S1ea83SqSoCxjzoC6hAHTBk3J61DRJhBoiEuoWpF1pweFqIpJqkiqSVq129MWddrvhGVdPuPvqkkbdMWsQZdtlVD3ee80p9+qrECoJCfZ8i5XpGSUVaWcaQnrupSidp2WlOScD/Y5F+zzpeSP+Ep5n/+z76t+dPlnbK0/qSCrIOugY24JH215lrsccszVFoybOQHjpUglmF/htz+50TuJuFFEYvnbJAiaTT8f+VJTNEdERES82siX+M0/d8PtF9fs4Tki6g5H120Ya1Plgozv898NmHTBHjOGtLVSKBIqOi3qNWPUOW1Kui1a1GnAjLKkGVuM2aZQqdmazPvSco+T1SE/3HvJXieE4p51yKJ+Bz2p25y8nLwORW0a4vY6qdOiFR2SqmpSVvRY0e4Wj4mpuWCXdgXThvWYNWzCkm5tVo3Z7ayDPuPdLtprUb85wyZtdtR9xuzUptj6M9XkrDhrr2VdSjIOeEpMXVlaVZuSdrP6NVqT6ayCZxzUZ96iPtM2Saq29lv3WX9HQaej3mjakACBhnpLtDekLOp11n6TRvWYVxUXEzhvj3PBvvVov5PBEQ+2/wMfKrze93dd8HcqvymsNW922hTt96Q2BX2mr0nNgFBwUydgvBTxgK8+xQNPbfROIm4EiY3ewHcCsRhhg9/7NJ0ZXntoo3cUERER8fL5/U9TXt3YSmuadoyijGGXXTZqr5Oy4Qritjmty7zLtsgqCtDT8gvP6Zezok3BntZhu7qkZR02ueKSLToUtFvSXpmyJVX2BzMjbu2suSc9pS4QCHzF28SwybhAaEGvDvlWbXWnJT16zdnkkpiGc/YadkXdtIqMFd0mjJq0yWGPIlRtzX2b0+lAh2WBuoyitIKiHGIu26bPjJKsK7botmhZpyu2WDAgr0dCWVZeDCFO22lJjzt93YxBNSl5nRYNesZht3hcTGhRn80uOmOvXnMgJu6kw273sJSKtKK8ToTG7DBtk1scs6jXBXvE1PWatamVcLE2DY6FJLLv8J/zw366/c/9XOOf+mj1J40nD7hsm23Oyio46YjzOu33lIwVZRnjduo3pRHSb9aYndcI51y4JKtwU9oy1m4q3//n7BlhqHdj9xNxfYkmy68Q8RhByK9+jKfObfRuIiIiIl4eT57ja8dvbEzcN6fukCckrOozLdTwd31Iv4lWxNqiERd1mnWrR+R1uGyrFT0u2SatKtBAoKjdDudNGXbara4Y1lGZMJIs+vXJ7e7rrdiaXlUXSKoparPfk4ZcMmLcBbtNGlWV1KakoFNMTF1MrOX1DXDedn3mVSWccIfz9nizv3bFZgl15+2T1+WinYpypg15hz93h6/qtOySnT7hxyzr1mtWiHn95gxY1i2lYkWXlLIAZx2wpNuiPhUZO51RlHHFFvMGTNskrWxRr5qUi3Z60H1OOGzEuEOO6bKgJG2fk9JWJZUlNFC3qEfGirf7lLyMnBVxVV2WLer5ptF+q7k7/Fr57xM2/MPg96Rrs/rMqEtY0uWgYzosy1gxaNKYna4Eo+vNfiXpm77N77kk4lRrvO/DUTLWdzrBC59i3Rjuuuuu8JFHHrnh6z5zkZ//41fmkF6t3vwG+vc/xe6Rb//rRURERFwvVqv8zK+xlG/myF5v1g5+vdD0MGtFf0tEbXNOj3k7PY1Qp2VTLTtBVkFNYMIWBxw3bruUVXc4Ktkq2GiIi7UKQgLkwkW52pTOeNWvT233ziFGY1OSqhoCl4yqS9hiXEXKJdus6NJp2aq0YZc0WrOlfjMu26rbnLpEq1KkXZtVBVlZBU+6A3F5HRpiRozJ61SR1mfOhC0OedwjXudxrwevcz9C25xTF/eI1+sxp8tiy8JR0m/aik59ZrTLiwkFQnVxRVkLBnRYNmNQzopjXmPaiNs9aEGvAVO6zdpqTFXMqIvKUlJqHvUad3pYUkm3ZVMGFXQ54bAjHvVFb9Nj2QmHZRRNGzJ41YR5KBx3jwc8sRz3j1MfsilV8cnw3T4X/2Fwp6+pSlvWJURWfn2y3KzIbrZ9ZK2YNXTN9PpmJgyb1fDfdw8/+bc2ejcR3ypBEDwahuFdL/V5N8Us4TuJtTvNn/tDLs9u9G4iIiIivjl/9gWWizdGKNM8pHeHo4bCcXxjekhdjxld5kFRTkxNm6I+M7KW3epxQy5blZRUtcsZS7oNmXDAU+LqCrLm9Ao01CQNuWIovKSnfkU6qPuVyd1+ZKhgZ+ySuJqSlIJ2KTWdVjTE1AW2uGjYhLiaBb1mbNJnTo858/rkrAhbc+aMoop247baYlxa2W7PCtRbWRolV4xa0aWg07w+NcmWGF40ZMIOpz3pTjSj577sHbotOOUW93unog6XbXPJNkkVJ90mo6TTklVtFvSoSps15EFvcsYhl2xHXD7octmot/i0hpi40LRBg6aUpa1qd9lWbWqetV+XJcs6pdSctt+ICUe9Qae8o+6V1/28aL9cuGSfpx13WLnzXu8vv8fpcrsfiH3M6xp/DUoylnUJhGYNale0w2mzhhR0yloxbfimb/N7LkHQtGJ++qHmAdmI70yiybJXdrK8RqVGR4b3/RMGul+5rxsRERHxSjA2yb/8bQLNN/sbxdoE8oQjMgoaAll5Jx2Rtew+nxMKbXVeoKFdSbu8jJKkivN2q0oZcVFeh6wVOcsq2jTE9JozYZNlfTaHF2QaKwqNuA/MbPMjm4r6giUlKVmFVsawVite2Vm7DZizoFNK3YoOZTklbXZ4VkJdTENa2YxBeV2qkgZd0WnZZVvEhPJyBsx6xGtVtOk1Y96Akoz9TljQZ9qQUKDfrLP2aVPUZd6T7jIVjK7fSHSZt6DPrE0KsoZc9iafkVb2jNvkdRpyWaclR71JRmE9u3ibc2b1GzSl3Yq7fdWqlB4Lpg3psWBer3kD9jhpxLhlHRLq64L5AW8VSjjlgKlgdP11vNpP3DyAWTfYmhIPmnJu/qKfSH7E63KL/ip8l/8e+/H1CfRhjym3qrhpCumTjsC6gH61TJbXqNZpT/FrP0t3bqN3E/FyiSbLG0wqQb7Iez/A8s2Zrx4REfFdSr3Br3+8+fFGCmWYCkadcMRtHhUIZeXBgGbLw6q0TSZcsdmAae0K2pWVtAnU7fa0hIrTDug1p9+0UCCmLm3VhM1CSW2Ngs5w2VQ15Q/mdvnJTfOGghlFKRkldXGhmBVZOSV5GZtNOmOPS/ZYkdOuaF6fRQM+7Qc97YgJo67YYsxuZe3K2tWknLdbQ9KCft2WHHfYgGlpZfMGbDZul1Otw3ND2pQMueKyLXY5JRR40l3riRH5oKslaOcc8CSaptgDnpCVV5R10S6B0LJuT3iNvG8kisCYnfY6qSCjpMMVm+1wxqQhoZjPeZeqtCGXdVmQ12FVxowhfeZMG5JSccqBa5IsuDYPea32es1/XJSxs3er3yj/Q59Z7Pd9sU95u7+QCxdtc05ZyiU7PesWVSntirKW12PkGuKmDT3Pw7yWinIzkoxTqvCfPxoVlX0nEonl60gywdwy/+4PKK1u9G4iIiIimnz24aZN7EZXWtMUPRkFZ+2zyylzBpx0xIBJ9/m8DsvG7DRs0rRBCTU1cQ0JJRmhuB1Oy1iRtCqmIaUqpim0l/UIw5rtzhpbbfOJ5V1+dHhJe7AqLyutblVcXF1ep7xe0waRsKjLZhN6TalJW9Tvop0u2qEsoyLlrAPG7HbeXleMGjHujP1mbbKkS6dF04bsdMZKa+rbtCB0qkmY1JzODpswZru0VU+6wyaXDbjSqrduxucNmnK/d/qKt7nP57zFp3Ract4eX/F2GQUFOWUZswbRTBRpCAyalA+6POugOxw1bFyPRV/3JttdcN5uTwV3e9Idhk2otNI6KlL6TXvAm1VaFo/BdV/xS01+4k44rNOyWUPig+/yG5Uf96ezm/yQD/oH4W+ZMewxrzdtuDU93qskY4ux9UlyQfaaNV8Nh/1oZpQ/c5H/8fWN3knEK00klq8ziVjzTekX/qRpzYiIiIjYSOaW+eOmjfSGZyqviZ41C8KT7nDIE7KWzRkUV7OiU9KqirQuK+b0C8Vk5NUlLeoUCOx1ypIei3rF1VSkreiwObxoJLxkvNLmoyuH/ODgks7WobeGpFBNu6qCrJiGkjYJoXkDGpJiKgZMm7bZJ/2wNmX9rrjbV5120Be8y4Pe6HZHDbtk2rBpmz3hjpZ/OaXDistGETNlxHZn5XV50t12OaUk6zF3u92jLht1NjjonF3e4jPm9T7Pt9uc2m6Sk3fJdg+7V7Z1yG7WpqsmyNnWIcO8fpMtq0QRoX1OeNLtlgz4onc44lG3hA/Z5LKn3aqk00m3Kst6wl1WZX3F22SsmjaE+EtGuBVkZRRNGtHfmkT3Dr/D71fe44Ozm9wX3O9Wj8M19eYnHVHRtv511jK316qy1z53TTg/9+/UzTJxXutd+NDnOXtzbCniFSISy9eZtZa/05f45T+jHsXLREREbBBh2MyFrdU3Jiouq3BtioJuxx12m0cc8ZBzduszo8uycdtNGTZoSqlldZiwRShhRc6KDt3mZZQs6BFXlQuXdIRLJippH1na56cGx7WpecoR7UrSCtpVlCUk1NXEjRj3oNdb1C2upEPBGXt0WJJpWUQInLHfnCGsJWJsc9FOf+UHdJu33Tmf9MPO2C+ualW7rCUpq6Zsah32K3rSnTa5jLjPeadbPOG28GE7nfVJP4T4ehzbmuAcCsd1W3Dc7et13leLyUFTHvda+aBLPuha9//e6Wt2OyEr7yFvMGzSKQd8OXinT/p7XusBq9qtaveI1znpTscd8YzDzjqgoNtj7vFyhPLajdCaAF6zgwyF4966qd/v5N/iI3PDfsQfeJePtfzmy3aEp2RbPutBk+vCNx90Pe+mYa3F8WaOl4vFmvamX/pQ9ET5O4molAQadVy/55FrgvnYmWZL1s+8e+NasiIiIr57efgZjp/fmEprrB8GWz+4FbLNaavaTMkadQGUtRl2WbuCcdtl5K3o0m9WXk6vBTUNgVBZUlLdapjQF864Ukn7b4vb/fjwpIZAXdwez0qoSGqY1e+y7Tosy1kyZof9nmm11MWddEhRtzP2epdP+JR3u2CfAZNyVmxvCejHvc60YfmgS3tYstm4rIJuyz7j7xkwJcSyHmft1W+meQ1slpezz9MuuMcFBXucdNpB00auqX9eCTvd4WsGTfqKt5kKRk2Fw+7xgKPuXReTk0auOQiXD7qMhzvd7kF9pj3g7fK6jNltr5OEnAsOCkL2OKkq7ZKd6+18dzjqlMF1gZzX9ZIFIWuCd20f+aDLdDhkn6c9Ftxjz9bdfuX0slTwkB/o/Yh6q1plumXLaH6NZiIG1jOcq5JGnbMSdjYnzuEeBx1TDHMC4U15CDCVYDHPb/0P/vkPbfRuIl4JoslyacW2z/zv7g0/d12XWRPMDxznjz77yiZvRERERLwUhXLzZj3cwEprmoL5akE1Y1hZxpJu25w1Z8AZB2Qt67EgRFLdlE3m9egzb0mnFd1O2y+OIKzpC2dNVdI+urjVTw1PS6rqttTyNDcb/woyalIu2ONh95q2SUGXZV3qkr7o7S7ZqcOS/U447lZbnbfDaTOtWLNOS61ykeH1KeeJ4E7n7HPYI87Yi8C0Tcbt9KQ7tVt10pFW4kfBVDDqMffY5oztzjjtoO3O2ObM8wRnUYen3baeRDEVjDrqXqPGnjeBXiMXLhl1Trx13fpMK8iaCkY966B9njYUjssomjOgw5KCzPqapxyw18lvaYJ79ev6DeIec0/zzxHvcWDXe/xfE3f4y8VB7/Zh/aaVZXRcdbhvLYpu7ccX7AYHHVvfT7uiTks3dbxcPMbXT/DlJzZ6JxGvBNFkOZnWSLT56fBXrOhwLLjnui0VBM27k7882qzFfvd9122piIiIiGv4k882HwtvRKX1i5WRnA/2KYcZ+z3pq95ij1MyTokLXTai07IlXba6IGPFZZu0qbhot9s8ohSm9DRmzdSSPriww/88PKEiLamqLtBrXl1CqG7GsBUddjtp0qhF/TosCoRKsvY45bjDeiyIqxswI6nqGbeCUeckreo1rSjnvD1u96DFsMcOZz3hLjuccdxhBd3rtoFrBLDmx6xluzzrqHuvmRjPtiLp1ngkuPd517Og06q250ygjzoVHlDQ6aBj4CFvkFXUb9JBx5wMjzRFd2g9vg++4m0GTSm0prdTwahC2NmMcQufH+P2Yq/n1ZPn506hK8kB9+75Xj/7TE06dsxbO+93xaiq9DXT8ayCgo7m9Qq6nAyPOOiYA57QY8Gi7vVCk7WJ881GEDRjGX/rf7BvNKrDfrUTTZYTKZff/F5jdvmnftGe8OR1XS7WEswf/gKfu/GR0hEREd+FnL7E/cc2rtK6IOt2D75gGcmO8JR+U55xG2LaFWxySUOg14K8TgRCgVXthk0qyNnhWTUJuca85Xrc78/t9U+Hz4kHdW1K6mIWWwUlcVU1cQMm1MX0mNdnUgNpZaFAScaCHve630U7JFUs6jFps9f6sjf4gjZFswaVZfS3ou4W9XiDLzpvl2kjjjvsFk+gvn5Q7YVSJPrNrgtlvjEx7vfSbVYvZHlYmwYPmDRj2JidrUSJYScdMWv4qn3EnXBkfTo71fIYb3NufXq75hne4Vmh4BpB+jf1DufCJQfTU35s9w4/cfY2D+QH/HD4RwZNXjMdnwo2XzO5zwdd5gza6VmBhpOOXOOLfu6hv5uFeKuk7JeiOuxXPZFYRiOZ8Z+C/9e8fv/Ce42EF67rerFY867zd/6y+ZgmIiIi4npRq/PrH2seOtoo+0U+6DKv39/yCbeGD60nYrzGA+7wNXkdVnQadEVKWc6yDkvaFbUr6DZvWZc2JTUJW43pNy1TmxaEod+c2e0nNy2oBWnQriSu1qq+jlmVklJR1m7IFXN6DZuw1XkNcWccdNJhSXWPeIMeC/JysopWtVnSZdCEHgvrBSprcXfdFnzV99jhrJxm+sRR91o7B3N1HvHVnAhuv6bkg1YGdXD7S17PF7I8TAWjHvdaOSvKMtdUUeeDLueCfWgK1mZqRcGkEaPO2Rmekg+6jNm5Lj7XrBxJFRn552UsrwnVTeH486bnL0QuXFqfeE9n3+qe7fd6z6lbHC/3+tHw9yRUrxG+V6+xKzzpkGPO2WvBN0a0L3YzcrOQiHN5ppmQEfHqJRLLLZaDbu/zC6pS/pX/W184fV3Xi8cIQn7tYzx57rouFRER8V3MJ7/OzNKNzVQeCieeN+2bNagi5U0+KyNvm3ParEpbbf34jLSSipQ5gxpi2hXt9rR2BXs87ZJRnZZkLWlUi7piZb80ucdPb57RFlTE1cQ0FGSlVPRYMGVYVZuytLSqhpghU9qVFHSYMiIj76CnTBjRYcmAVENTlQAAIABJREFUSXMGfd0b5Szb3JpI95oyZ2BdFOaseNxrPRXcvV60Umx5g18qPeJ68EIJEldTkHXQMQcdc94eKzphPWZuTXy+zv2+18e1KXrU653UtEEcCh990bSKFyOrYLY15c4HXbb1bHPryJ2+/5lbTdRy/hf/yar0NcK36dnOuM1jTjjs4eCNTjryPFG9Edf65RIEBDE++WDzcG3Eq5NILF/FTDDsfX5eWsm/8m+u+6OdeLx52OY/fLD5mDQiIiLilWRqgT+7v/n/N3Kq/EKP6bc557Jtpmz2evfb6pyLdvi8d8nK2+m0pFUpNdOGVLSJqSnKyVlW0m6302riytWGwUTRL13Z4X/bdFl7UJeVV5FQkhZXU5NQR6dlRVkVbfJy+sxKKynIyFkxYkzWijZ5d3jQgAlfd5+UVff6a0MmLOmQVXDCEXf7iqFw/BorRC5cstlFZ+wzYvy6ts690I3I2jprCRIvdOiPbxyoxPqhuqsPHq59zpJeGUXtyuu/t03RiPF1q8VLrfVcpoLNzgX71kX1VLBZ3/Bb5Xpu93eePqjUiPtZ79Nt/prrt9m4M/ba3Lqur4Zp8nOJBYQNfvkjUaPvq5VILD+H8WCnX/bv9Zv2f3ivdFi6rusl4s3HpD/3R1ycuq5LRUREfBexkZnKz31Mv/b4fc6gJd0mjBp1QVrz39e01fVpcEPDnb6ux4wl3dqUVcV1WhRXVqnWDSXLfvnKdv9kaExHvCrQ0BAiLqdkVVpaWVpFVkFVwmkHxNXFhLKKUi1P8pIeW1zUbU4gVJHWa05aqRmzJmxlOfcj5qj71gtArk5ueNZBBE45sJ4vfD0ygL+ZX9hV5R0v5uc9H+wzbuc1E+Grp7O5cElJxte8RYdFb/B5d/qasoyvefPz0iq+He9wEAQObXubfGqXv3fqFumw4B/5Vfs9uX79mtc15lkHr/Ew38zT5BcimWgm0vz6x6M0rFcjkVh+AU4Ft/gN/9oOp/2sXxSE19eZn0ywWuG9H2Bq/rouFRER8V3C0aeb1bsbUWlNUzCHAjucVpQzZqc+0zYbV5cwaZPbPeQH/bFus+oSapJGjOuwJKVi0JRZ/ULJpge5tmo0ueT9U1v9UP+UXCIQaEipCMXF1MwakFIXikuqOme3Lktu85g2JWN2etYBCXW7nJJSsqRLu6KYhjarbvGYLkvOOCClJq+j1WLHtBGPe+36ZHNtwrx2SG7QlKKsfZ6+LhnA38wvTPx5h/5eaAL7YhPhq0Xw2eCAx91j0BVZeeN2XpNW8XLWeimGwgldQcE7dt3jdGXAT5y701B4xQ/4sNs9pE1x3Xu9dn1fbI0Xm7rfDCRiTSvGXz280TuJ+FaJxPI34bHgdT7gZ9zuYX/f71739ZIJimX+7e+zsHLdl4uIiPgOplDi/X9x/TOVX8oSkJGXbHmSB0xrU5JQtazTcXfItopB+szosOCA4xIq629MZW3SyvKyirWEoUTZh+eG3ds5ZyhV1ZDQTMqISagKBNoU0UDgik06rLRmzlWTNjvhdvMGTRvWEDfqvE5LQnFjdpkzIKMgpajPrBmDrRi7bet2hasnm8/NjV7LYj7twHWLNHshv/ALHfp77gT2pSbCayI4q2AoHNdnxrRNYmr2OO7O8AG5cOmatdZe77/JtHdtSp5Jprxn935fXMz61xN32uGsN7hfyuo1fuir17yatT3c7A1/a9+Lf/hX0ZPkVxuRWH4R7g/e6dPe7ft8wlvDT1339ZIJFgvNCXP++ro/IiIivoP5o89SvgGZyt9MnPS70sz1dcSjrXa2fZ7Ua8YXvNOqdh1WnHKLVRkZBYc9asImSXWz+s0btKJTh2VtjWV98YIvLvfYli7Y115SktYQU9Iurgaq4lLKMkqWdbTEc16HZc+4VUbJEQ+bNWBZl9P2iyGp4lGv02XBFmNmDBowa06vQOCk2xzyhKzlFxWE36qP92/CUDhhKBy/Zp2hcPxlTU9faiL8DRFcd5/PaVP0VW/1sHsNmtRn+ppykG9XjK6tP2hKZ3bIT27v9LtXOr1//nY7nbHfieddxxcTxH+TlI4bTTzWtEa970NUqhu9m4iXSySWX4IP+sced7ef8F8dCh+77uslYs1DOT/3h5Qr1325iIiI7zCevcSXnrgxPuU1cXKHo3aFT6+Lk5Jc6xH6ZCsjd0BC3VkHTBtRkpFUEWiaN4ddsixn1EUrchLqitol1FXDpK5wyflyu8VGyu25siraVFSlLem1rMuquIyStIpJA7IKes3KKpszoCHhou1Cof2Ou2S7mpQ5/aqS7vR1BVkPu1dRh5qYlLoZg/I6HXXvNa12z+WV8vG+NHX3eMC0IVeCUdOG3OMBvLRd8KWmz994UhD3tNuUZQyZsM/TvuJtzjhktpV//EqJ0W9M45cN9N3mjcND/s25Pp8u3uotPmPQlfWM7vUiG83K61vCR59f+vItpnRsBMk4s0v8wWc2eicRL5dILL8EYRD3X/1LE7b6Z37Bplao/vUiCJqCeWyKX/yTZqB5RERExMthIzKV80GXy0bXY9PyQZfpVoV1v0m7wqcd8oRHvF4g9Dpf0G9SSbu6hF6zVuQcdEKbFV2WLeoyZFJDoFKrqYV8aaXHO7ub096KnLiahFXzes0YFheoC0wYkdIQiilrU5AxbpeCDgutKu1VbW5xTI9Zf+Yf+Qs/5qJt+s0YNCGl6pRbPe4epx2Ss6Kg8xqv8nN5pXy8L03cUfcaNGVTOG7Q1DW5zt8Oa1PbgqwTwZ3mDLrNoy4bNRWMOhfscy7Y9y2L0ZeT4JGwaq/jvmdkq71dXX7i6UGnayN+3P9nVdphjzro2PoU+5tVXt+I6f63SxA0b2Y//xiPPrvRu4l4OURi+WVQCrL+k3+nJulfeK9cuHxd11v7Rjo13oyaqUfNPxERES+DP/9qc2J1Iw/1Nb3JBU+60yHH7ApPrkeShQJ3+aorRkwZMWNYILTXcd/vT2132qxeW421psVVK7J2OmtFlsqCwXjBB2a3+J8GZqzISKpb1K3Smk5vclmbgmmbTBsxYZuYuppEK18564LdHvU6ocC8/5+9+w6P67zPvP85U9AGhQBRSYIFrAIpkRYlUbYkW+7dsZOsE6/Xcds42dhO8jp5s3k3ccqm7LspjkscO05cYsfrLvdYtiRbtmhblSIpsZMASbCgER2DMpg5+8cAEEmRlEQRheT5XhcugBwMngeDc87c5/f8nvuuccJSPaonHS7o1uC7fkW7RmUG3e8FfuANRpXoUj8tei/Ul/t0eoYvBR3BIh1B4xmC9VL5Op8rCGSnzUoMn9H28EzF6FM5eHSqE6BTvVjAjU0vVlFY7A171hgIS73dP5mYvBkoM6DZdiNKtFp9xhxmr7r/7Jm6mf3QV6N9SpcDkVh+mnQH9T7gT1Tp9jv+Qjyc2WajKcH86IG8/VNkNRMREXEhOnr46o8JzF5V+Wz3hF02TrpODEsZUKlHryqr7PVaX7BQuwLjBlUoNGaJViu0ShqTUaJdnSqndKsWG++xsqDPxzuXemPtoGNBk0FVQpQbctIinRbLTbZf9KrWqcEae8TlpJXaa70+C2ywzWq77HeNap3GFLrHa/WocZu7kZWSdtA6d/pFJZPV4KcjkueCmayenh0Ecii4Zlp01p3WevFMxOhTOXgQt9sm2yb72xfHe/3qqlU6M4XefOhmheGol/u2doutsF+x9Dkjr2evun9pSMTz7Zb/8BVyubmeTcSFiMTyM+Bg0OxfvE+zx7zdP864gp0SzPc9nu9tigRzRETEuQhDPvL1/CpUbBav6mcHc5RI2+l6dU64zd3SSvSoljRqkwe9xLcUSKvSpV+lYiOKDZmQ1GOhaqcQE2T6rSvo8vnuxV5ZPWQklvdbPmqpPlXGJVTrNKpQ0rgCYxbqUqHXsJS0lFarpKR1WKRDvUIZyx2aTBIs1GyHLnWT1clOKYNPEmCYVyKZma+eTgWB7HS9EukzgkCqdV+0GL2Qg8fU56GgQpsmSRkjRevd1PQi9/dl/feOF1ocHvV2/2hAhRElZ/zcqTnMVnX/UpKI5/cZfOfncz2TiAuRmOsJXG78LHihxeERr/dFLdb4oVfP6HhBkL+jufMhykv4pRfM6HARERGXIVsf4+DxmXe/wLRF15kbw9qstcc2WwwFFXJhXKMWdU6o0iUp44Ql6p1wqx8JhQKEAnFkhcr1G5YyPBGzKnHMjwcqrSvNKEoU6FCpX7lmj+tSIysuFKjWrV+lbrUW6jIhYUiFFqst1WpAmR51BlQ4pdYK+yWNW6DPCUscsMGgcsu0aD3NR3goqNAaTlaVza8NYuesnl6iuU4J8UfdfGb4SJgfb5fnPOk5Q0HF0xr37Gr4YFj+JGF7+vc0atG4gN6G6/3bsW1uTN3kzWUPWm+H7/rlM+b1dOcwHwnyJ4Iv3MO1TaxomOsZRZyLqLJ8EXzVW+xwg7f6mFXhnhkfLzYpmL/8Y+58cMaHi4iIuIwYTPMv35l5T+UpztV/usZu+07zFU4rs88GbZpkJZQakFGQt4GTVpzfCmhMkX3WKTKmSpd4OKZeuyNjxcaCYg1Fcfut16NGyoh+5ap161VtVImshFFFWqzSavWk48Ya293suGUKTNjtOm2apAwpMmKxI7rV2Wujanmz213Bcy6biuRMVk9nqo3h6VTDz/6e7slY7vWLrtdYsch795f7YeYmr/MV6zw2r9srninxWH5T7t98MXLBmq9EYvkimHLI6FHtd/yV8rB3xseMxfK9iJ++k/t2zvhwERERlwmf+h6jmdmpKnPu/tNH3awjaJz+nmEpyyYry6NKEGpyQE5gVIkQMROyAku0GVQuJ5AZH1YQZN2frrWyrNhhK2UldauREzimyVFNyvUbVazTIiXS1tltWLlPe6/ttrjJfQ5bKaNAsx2TFmjHLXFEjxq9qgwqn9cbwOaCmRLiFxLhU44YZ7f0DCuz2yalQdq6pl9UXFDprbtr7M+t9ps+oNTgvLyZuViSCXoG+NeZj3SIuAgisXyRDAdlPuj9Sg14r/8lNsOR2OTvPgN89Btsi+xmIiKueh5v5ee78naTs8mFvGzrwhNSBlToUalL0oh6xxUblhUTkzWuyCk1Co1JyAgltI0WWl444gs9jV5QNS6t2KAK5fpc7wHF0jrVW6hTysBkG0eoU51iaZVOSRm0wQ7HLLXAgB96lQr9bnOnNXY7YJ2jVjqiabon+UqqUM5XLiTCT7erO7314/RWnyXxHreterGRbM7bDl0rG8b8vj/VGLZO/7z5FGt9scRj+ZaqB2d+wTriGRKJ5WfBkWClT/ptzXb6VZ+alTHjsfxy699+iV2HZ2XIiIiIecj4BB+5I7+LfrbcLzh/gtyt4V3qwjbDUtbYrc9CFXps9JCYnF5VQnGhUIdFOi0yIiUnpm9szDVFg77S0+CWhXEnLJVWps4xixwWl1FmwGY/U2RY/2QPc4m0AhmDyhG6zT1arJoW0sPKDCjX6IgBFR52q902qdWhU90lcbq4kIdwxFPzdFL3hqXcXrzP81fcZE//gP/R+QL1jnuLj6kLj59hRXc5v+5B8MRm3Z6ZdaiNeIZEYvlZsjV4ie97nVf7mpvDH8/KmIl4vr/pr/+dQ5fvdSEiIuJZ8LUf0zecX76dXc6dINenwhZbpQx41M1W2W25AwJ0qzWi1KAKnRabkJSVcNA1OidKLEsOeHio3MqyhKFYlREpnWotdMqgCjlxISr1OKVOuyXGFelVJW5Cl3ot1uqzUK12AQ5Z4zZ3KzTucZvts8EyLTBtV3YplvEvFL8c8fR4qtS9oaDCfs1+pfKw6+ubfK5tzFeGb7LeTq9wx7RXc62Oy/51T8QZy/CByE5uXhGJ5UvA5/26/Zr9un+wJDw8K2Mm4/l0vz//DMe6ZmXIiIiIeUJbZz6AZG4u4OdOkOuyxANutcVW6z1qkWOOWmm3jeJCC/ROB090atCryoKw04Jct4FswmBQJpUslDKs1nHr7XBYkxJpoUBGoXZ5cXvCUvtcp1eNVmuMKVSlW6UuVU5NWsl1G1DhhKV2usE+G1TomY7gvlT9rk+nMhpxYc7nG3161b4jaLTLRu9ZfMrKspT37K2wK9vkJb5nsaNqdVwxr3sixoHjfDuyk5s3RGL5EpANkj7kj4wo9rv+QlGYnpVxkwlGxnn/p+iY+T2GERER84Bsjg/fkf88057K52oxyFfu4k9KkMs/Vu6wVTbY5qgmj9pijT1K9EtLyYhb4ghCCRmxkWPqEmPuG65XnaoUl9NvgSqnlBlQrdOIYlV6ZMXETRhVYpGj1tlpn/UKjAswoMIRK3Wpc8gazXYgX0Vu1GKZFjvdYFjZJX+dnqoyGnF+LuSUcXrVvjTst1CX8SDld5viChNJb9q7Sn9Y7pf8O8Ir5nWfsoz94j20npzr2UQQieVLRl+w0Ef8kTonvdOHZy1BpCDB8Ajv/2QUmRkRcTVw18P5yvJsRFpfKKZ4ld0GlE9XApdo8XJfc5Mf61avxKAtfiInh7gRhWJC1dpd52Gp4cdsLOn1jb5Frl2QFArkxK3zuCGlJiQVSys1rF29Ymm9akxIyEqYkLDZ/QaVG1NkVLG9NgqxyDGtViF+1u9TPiMOCjOZqHelcyGnjKmvm22f7FdPG1XiVHKN968cd2I053fbNikIx/1XH1YfHlEXtlkfPjrHv9WzJxbZyc0rIrF8CdkXbPBVb/E893qB78/auMkEfUP5CvPg7BS1IyIi5oBTA3z2B/mvZ2NTXz7soUyz7dMtBp3qLNOiR7USaZ3qXO8By+z3AncrMuSEJSp1WeqQUSVOWqRARrGh/M8dG3ZDSaefDFS6ecGIMsNOWiQhY0JcmUF9KpVIy05WsffYqNdCQ8oNK5GQNaBMgTEDFjilVvGkmCo2bJ8NHnO9ese1abLbphlxvZjpRL0rnaeyq8vHb5eKywqww2aFxqRLN3tHI9/qTPiXvutV6/J2H3Wbu3WrnoPf5NKTTNAzyKe/N9cziYjE8iXmW97oMc/xVh+btf5l8psCOvv4s88wMjZrw0ZERMwSYcjHvslENu+KM1Oc3XrRpV6lUzZ6QLc6jY4oknZkMgikVocRBTbY4ahGqxx0i7s1OCkjqdSQo1YYUaLEqIFskdJgwsnxAiuKhpTFxg0rtc4u5QaMSInLKTXolGpDypTrd9BaGYVarRaXMy6h2yJjihQZUa1TtXa7bfJzL1IifUa1l5mJrp6pII+IPKVhv0CoU4MRJYaVe9TNioyrrLnNTQuL/dGhcj8bb7beTunJNqErxaEkHvDjHTyyb65ncnUTieVLTBjEfcz/a0SJ3/bXCsPRWRk3CPKbAtq6+MvPMZ6ZlWEjIiJmiQf25H2VZ9pT+ezWi5QBZfqFYtZ4XIlBRcalDExW/Uosccy9Xm5IhazAejsUGhHDsFLNdoib0B1WOTU6rjqRcTxTpLYgp9CIau1qdOlQZ6/rDChVrl/KoK1e5IhVbnafhHGr7RYT+IHX61WlX6VlWsVltZ0WWV1qcFaqvTOZqHe1c3rV/vFgs902TftjH9QsGYSuWfoq1cUpb9tT61Su0qt8QyBrhQPqwrbpm78VDkgZvOxE9JSd3Ie+FrVaziWRWJ4B+oMq/+QPNGjza/5p1sadEswHj+f7nCZmPiclIiJiFhga4WPfmp1I69PdHVaGe2yx1X1eYqcbZRQq1+eEBlts9Zrwi17ta4YVW+GgkckI6pxQhf58Kp+kat1qdGgbStuc6vfjwSrPKR3Up0JcqFgaOUVG1DopLmdM0qAym93vqGXGFKt3QqlB3aqF4k6ptcgxHRp0apjuF46qvVcG5/s71mifXjW4Jr7X+1YmDeYK/XbrGqXhgLf4hC41ttiq1BOCu1P9ZWnzl4jn+5Y/+NXITm6uiMTyDLEreI5veJPb/cCt4d2zNm4Q5JdoH2vJn1jZ6MSKiLjs+fT38u1VlyLS+umEaEy5OyzVapdNhic38rVabcACi5zUrsEqexQZssVWY5JW2S9hXELOuKQKA2q0Sxp1cmTCbal2Dw9XuKE8LSOp0LgxhQKhmKzF2ixzCDzkNoet06vKq3xd3Lj9Nmi1WpkB13rEFj/WZ6F2ix2ebAs5Pf3tdKJq7+XHuar2PLFqkCPvq1202OblL/K93jKf61lpk4e8yjfsskm5/mmHkqey+ZvPATOJOPva+N6Dcz2Tq5MZF8tBEBwOguCxIAi2B0Hw8EyPN5/4ujfb41pv948awrZZG3dKMD+0j098e9aMOSIiImaAXYfZ+viZ7RfP5k396YRoTLk77HWthTo12z7d0rDN8xQacZ2H7XGdjGKBjM3ul9Kn2IgTGoQC2clq8eBEoDI2oi+bVFXIYLDAcY0KjRkXl1ZqVJEAhUYm2z4CbZZP2smVqdCrXK8yAxLGVOjTqc5PveiM5fmognxlc3q1uVq3+7zENs+zprLGivob/F7rEo+NL3K777vRfQZUTK84lIb9arULBee0+ZvPATNTK0r/fhdHO+Z2Llcjs1VZfmEYhpvCMLxhlsabF+SCuI/67zIKvNdfS4az5/8SBPmNAfdu53M/iARzRMTlyHiGD3+N8KxI62fzpn52de16D+g8TTSUhv2abTekzMmgUZf6J/2MfhWGlVqg1y4b5SSUSEvK2GedAdXGFJpQJB5mtKaTGgtGHZ5YqDhRJGlCmUH9KiTlZMSNKTGgzLhicVnP9RM3+5FSQ4qNCTCi2LgCFfod1qRD4xm/06WIr46Y35xebd4VPMeUPWBHsMjmRRstKV3gl/asNZIrcLu7NGjTqU6z7a73M0u0KDF0Tpu/+R4wE4/l2yv/7kv5uPuI2SNqw5hheoNqH/P7lmn1Kz41q2MHQd6r8bv3c8d9szp0RETEJeCLP8zbQp4daf1s39RPD9E4rlHtpGioC09Y7iBMi+Qu9brUSxlWF55Qo90xy2QUmhB3vZ+q0mVMgZy4Jdos1WJEibSUH/bXeH55r58O11lanDOmUIExSRk9aqSVKjAhYdSwcgMqDKlQYFSjIyqcUjptJTdkqVY/8gr7XXfGxr1IJF+dTN041oVtVsYOuaXpBUbCQm8/fKNUOOQlvmOdxyxwSrk+o0rstklOXKe6J910pgzP64CZZDwfQvb5u+Z6JlcXsyGWQ/wgCIJHgiB419kPBkHwriAIHg6C4OGuriszt3lHcJPve51X+oZrw0dmdexYkP/48r3cGfU6RURcNhw6wX88kD9/z8WzSY07PUSjxPATokGfJvsdmXSVWBHu02y7LvU6gkWGpTRq8RwP2es6g8rVOanQuN02arfYAn0KDSs2pHU48PyyHntGSm1K9RlRqEhaXE5WXIU+PaoMKkdcTM5JjYaUOqVGiAIZAxYYUmGJNj/wWoHYdF9y1HZxdTN1DKy1R1rK8oIBm5te5u6eQh/tvcFq+63zuKwCh62x2yZDQYVhKbU6dKqTMnxG4M58DpiZKoLd+VDeHSdidpgNsXxrGIbX45V4dxAEzz/9wTAMPxGG4Q1hGN5QU1MzC9OZG77gnY5Z6jf83ayffLEYAT59Jz/ePqtDR0REXAQTWT701QtHWl9saty5QjRqdUgrUW7ALhvV6tAQtllltyJPJB3VTroQjClAzo1+ap9mhzVpsl+Dk0YUCcWNTWSVGJFDIlkiHlCrU7FRvSomRXqtnIRTahyzXE5MgVF7XadflUEVSgypddJK++yz3mFrzxDIUUU5Yiio0GOhOid1q5OqaLZm8S3+rKXc3vFaz3WfEoNKJkNxpp4zdezHJq3mOtWpndzIOp8DZmJBvjXr778cBZHNFjMulsMwPD75uRNfx00zPeZ8JBMU+qg/VGrIr/vgrDcRxycF88e+xYN7ZnXoiIiIZ8gdP6Gz9/yR1s8mNe5cdlyd6izSNllpTktLqXdci7VGlUwn+DXbpsioDg1W2+c+LxETGFFsgT7DivSq1hdW+dlAhU2pAbsyi5Uk4ibEJGQFskoNa7FasXGd6owpMaIYMeX6LXFYmQHHLXXQWjE5hEKBZvk7/kggR0xRGvYrMSRpTKMWK8J9Xlpfbn15gTfuXWssTLjZfRbo1mz79Hly9uoM8cvGcjCZYHiUf/pmtCdpNphRsRwEQSoIgrKpr/EyPD6TY85njgZNvuRtbvBzL3TnrI8fj+VPqg98hZ0tsz58RETE06CtM7/HIAjO76n8bHyEpzZITTlq5B0COjzqZoPKhQLrbTegQom0I5oUS7vGDhlFutV6ke+pctIKB4RockAORdIqdfthf4U3VJ60c6RcbVFcwjji+iwwImVMobQyGQk1OkxImFDgfrfpUidl0AmLka9Gf88b7LRZdnIzV432S/BKR8w3LsblZerGcbdNHvE8sNouzw9+6OVNG5xS5Q+Orrdcizoduif776eee/rqzOVmOZiI8eiBfMJfxMwy05XlOmwNgmAHHsR3wzCcfZU4j7jTGzzmOf6Lj6sPj836+Il4XjD///8n79kYERExf8jmnvBHP1/7BZcmNW5qY1SNdq1Wg2bblRjygFsNqTCkzFqPq9ahRocCI+CUamvsssE2K+0VyAkFCkzYOVLt1qIjuicKDBatV6ZfTkJGQlLGMUvFheq1KTWo1KAiaUct16vGEau1uEanBpV6bbPFScv81Eu0WemIJmllz/zFjZj3XIzLy+k3jkNBRT7FUYXdNoonKry46WZf6q70ncGVXuo7yJ8/Z6/ODCk7o+o8Nf588Fg+H0GAkH/5Tn7TX8TMMaNiOQzDljAMN05+rA/D8K9mcrzLgTCI+We/J6PAb/nf4uHs+78k4kxM8BefpfXkrA8fERFxHv7jfo53n7/94lIyVY0uNajMgBUOyIo7oklHkLdkC2Q1e9QCp/SqtNwBaz1uWKkYKpxSJK3ImGFl+nMl+kfSlheOaLfIULDAgEojChHTq9JSR3WotUC/UFapQSHzRf8IAAAgAElEQVQ2e0ijg0oNGFFoo0ds9UKHrZnuJe2cXCqfr5W+iGfHxbi8nH7jWBr2W2W3Dg1GJ91Yrisd87zF67z74BJd2TK/5W8UhqNPWp2Zcn+p1a4uPKFucvwpoT5fhXM8TmaCD3yZbJTaO2NE1nFzQG9Q7ZN+x0oH/KJ/n5M5JBOMZfizz+TfnCMiIuaWjh7uueeEMv1ntF/M5Jv02T2b+1w7bSM3LKXZDkkZBcaMKJKUsVCntfboVSmjSLERoUChEfecKvALVR32jVVIJVnuoCwqDDmmUZ9qPRaoccqIQgsmLeGWOmJYsWaPSxq1XKtv+2WjSuUEkVC+irhYl5epSvF+zUqkDSux3nYZce+qa7OwbLFfP7haXXjCm33CsJRlWs7oX95tk2rtljloi63T/uPzKZzkXCTiHOngGz+d65lcuURieY54KLjVvV7mdb5kTTg3bdwFCdJjvP+T+c1EERERc0Mux4e+xmA2ZWUwewliU5W4gck4a/IJeM22W+6gMUX2udaASq/1VePikjLGJfSqkRMiVGzYzv7ALyzocGy8UHVRTq1OpQZUGPRzt8ooUGTEiFId6o0psccGHZYYUmaBXjFZ1brd5XX2uB6MKJ1sE4mE8tXAxbq8TFWKO4JGnepssEOrVar0ejB4vvcsj9s+tsjHu1Z5sf/wEt/WrdoKB6wI902PUywtYUKLVdbYPS/DSc4mCPIb+L9yLy3zr/h9RRCJ5Tnks/6bbnV+098rDEfmZA4FCYZG+ONP0jM4J1OIiLjquesRWk4yEp+9BLGzK3G5SaeJZQ5q1KLWSS3W6VUtZdCwEtfaKRSq1GutHZJCY4p0ZAolglAqnlWWmFBq1KhChTJarVCv04gSA8plJPVa6LAm9U4okjaoXLcaY4qMKtGgTbPtdtukJVg7rzdZRVw6LtblpS48cdbmvLhWq1TrcsA1WoJmjyee79eaGvzFsWX2j1V4RfhNI8q0Wq1Gu1vc43b/YUSJDg2aHNSnct6Gk5xNLJa/6f7bL+VXjSMuLZFYnkPGgmL/7PfUaPcmn5yzeSQT+ZSw938y8myMiJhtOnr5t8ltz0Hw7MJGngmnV+LyThpDGrW4zsMqnVKl0+t83nP9UFxGuQGnVE73GpcZNqxYPMz6bk+t28t7nZpICGKFQqFSacctscZ+C3Qq16fMwGQaX5UC4ybEETqlWoVBB60zLqlCr2LRxehq42JdXs7eGEjWCgcdtWK6Ot0RNBorvcFti1d424FrFEr7HX8pf/zVqHVSzeRN3WJtHrfRCoemV13mm9fyuUgm8kWvz1zVNgozQySW55i9wbXu9AYv9R0bwm1zNo9kgq5+/uTTee/GiIiImSc36X4xkc1bO3Lxy9DPlNM3Rk25CMTlLHfAUcst0qZSz2TYyAlDyowrMS6hTNoxS6QMu6OnxpurT2gbK7KggCIjEnLGJCxzWIc6BcbVO6FSj6yEBm2KjXjEcyc3YlW4w5scsdKwMqG4UH6zVcTVw8W6vJy+MXBluNsWWz3gVoeCa6ZdLurCNtU6bKpdJlbU4M+PrbTO497i47b4iZMW6Vaj2Q49KqWkJ11hFszbcJJzEQ/40aM8enCuZ3JlEYnlecCXvdVxjd7lA0rCoad+wgyRiOU3+/3FZxkdn7NpRERcNXz/oXz7RWLS/eLZhI08G6YEeqtV+lVa7zHdao0qlpFUpVO7RQqNScjoVK3BSftGU1YWDIkLlRbEMW5cwrBiSTnj4hY5ISYjo1C/BU5aosKA/ZoNqvYTL/dtv+KwtQZUucerbfNcbZqkDF4WAiVi7plakVmq1S4bpx1dutQrkrbRNq1W6w7q/LflCV/qbfLAUJWbwq3K9OmwWKExvao0OK5TnY6gcVrAz9dwkrMJAnJh/iZ8YP5P97IhEsvzgExQ6ON+3wI93uLjczaPIMgL5taT/K/P5+1oIiIiZoaOHj77g/zGnCn3i2cTNnKxnC7Qu9U76Bo5ges8okjaqGLjiix1UJk+/RYoMao/LPLzvpRbyvoMhknJYMK4UjCmyITAmCIJY8oNO2iNPtUaHbVPs6Sc4xrtCjYbCirOaAtpCdZqDdYaVvakAJL5auEVMbdM3fDtdZ0S6TNcLo5p0meBMgNqdXgk8TJvWrnUu1vXyYah1eG+yej29X7mxQ65Rq0OdWHb9LF2OfXNJ+OMjPGRr0fpfpeKSCzPE1qCtb7lVzzf3TaHP5+zeQRBfjl471H+9ov55eGIiIhLSzaXT9LMntZ+waUJG3mmpAwbViZlYFqYZiSNKlTllKRx5FTqk0VcTsyEr3dWeWfNMW3jJQoScWmlMpJGlCo1aESpcgNGlDpqmWqdk+EjS62xxylV1k8uj5/vd+9Unw8umSV3kIjLk6dakRlW5pTa6X0Aw8qtSrGpdon3t63SEJxUrt9au6QMaAnW6lRnrT2X7bGWiPFYS5Tud6mIxDIe2X9UJjs219Pwdf/ZYSu904fmdOlxSjDvOMSHv5Z/Y4+IiLh0fO8BDnc80X4xl3QEi4TYaJtuNQqNKzQiK+mUKhX6xYQ6NAglVTnl4DA3pnrkxChY4KjVHrPZhEIB0spUTPYnd2gwISkr6YBrtFrrJ15shUN6LLDWnvNe7y4mpCLi6uOpV2SybvITGXHVOqyzQ7l+G2pX2JFZ7icDVTaEjzqh0RZbrQz3qNXhmGVPGutyWdmYSvf7RJTud0m46sVyZ9+w3/v4HR7Z/w3Z3Nz2HWSDpI/7fSlD3uEjc7p+MiWYH9zLP38rWsqJiLhUnDjF5+8+s/1itqkLT5whULvUG1Vgi63IyUo6bpkdbnbEcmkphcblxAxlkx4ZTLmptN+AUv2TzhbLHJKRMKxUypABlQaVO2QN6FPlpEZtmmz3PK1WGVVmmy0XbDOZLXeQiMuXC63IlIb9anV4wG2aHFRs0PUetNd6RcG4Tctf6A+PbzSRy3pB+H27XWepVt3qdKp/xvHb84n4ZFrvB74cFb2eLVe9WK5dkPKHb3qZU4Nttrd8VxjO7RHVFqzwVW+xxVbPde+cziUIiAX5ZZzP3BkJ5oiIZ0s2xz+co/1itjndaqsuPCFlQJFxJQY0ajEhoU2TAF0axOSU6pcy5F87F/nN2qNOZook4jFFhtRqV6vdhKRyvQaVC4R6Val2Sos1utUqNmJUiRUO2OZ5Hg5ufco2k9lyB5lrwjB/fExk8x+ZCcYnGM/kfXPHM/n/y0w+ns3l3VSi6/KFmao6twTNdtlojb32aVap16NudiK5yaLGN/jjttU2BI+5Jfyhva49I6TnXCsbZ99wMj+rzlPpft+M0v2eFVe9WIZX3NiseekLdfQe8PiRu4VzfPX5rl920Fpv9THlYd+cziUI8mbndz7Il++d06lERFz2fPtntHXOffvF6e0NpfpssdWIAoXGVOpRpQsZTfZY4rCcQIEx9w1UeE35ceNhXCoZUyitTqdBKYeslpLWrd6QMu0WG1WiU62kCcct16vKOo897QrxXLmDzCS5XF70jo4zMVmbyYV5EZwqorqCxdWsXMyGFdx4Dbddxw3ruGY5y+uoraSshEQi/7xQXjSPTQrriWwkoqeYqjqXhv1KpO10gyo9Tlg6fQwWlq2xvej17upf6DY/kBOfPtZwzpWNs72d52vVeSrd78s/4nDkxHjRJOZ6AvOFFfWbjWXSDp18QEGi2Nolt83ZXHJB3CfC9/kr7/FWH/URfzRncyFfXRZwx08oKuAXbpnT6UREXJYcaeeLP5yd9osnJ5rl38xThqeruENBhe4wLwJ6LbDBoyr0GVQOXu3rxhQIkZBzIrvQ3uFCr2zoMJhNGFSqQr8xCROSTlqixRrLtTphiR41FuqUlHW/Fwhk3WyrB9ymWofBsPwpBfM5e1HDfC/qkMujHSMMJ8WrvJ99ELB2Kcvraayhvoq6yrxIjl/ETdToOO09nDzFsW4On+RoZ75PNREnk8kXPOKxuWv7mWumhGynOrU67LTZetsNhaXTFnPX163yV60v9s3UHd4V/JW/jH9Yq9XWekzKoB6108ctTxybKxzQHdZNWi/Oz376WCy/SvG3X+Qf3k1Bcq5ndPkRieXTWLP4VuMTI5OCucSK+s1zNpfjwTJ3hG/2Kz7j/nCrh4Jb52wu5E82Of7PPRQX8LIbn8aTek5QlKLktItHup/RYaouDwueiIhLwfhEPoY2m8tHzF9KziWMybreA7aFW6aralMV2ilOb294gZ1KDRhQLhQ3qlBMVoVeaSWGlft0e4U/bdipc6JQWSKrVpce1fqUq9KnXJ86HR7xXBX69aqyQJ8RRaq1a3DCPV5pWLla7fn5hBcWF+dqzxgKKua9UA7D/N+8IJGvHi+p5eZr2LiKlYsu7cpCUUFeeC+vP/P/R8bY28Zjh3h4H+2T4nk8kxftsatIOKcMTwvlIWW61BtSmne7mBS/QRCoWfqr3n/igA8vfdSrcl/w49hrpQyq1W6fDYaVa7Yd7LbpjBvOdovnpVCeIhmnu5/P3cU7XzXXs7n8iMTyaQRBYMOylxifGLGn7UcKEsUWVzfP2Xy+65fdZKu3+0d7wmvn/ESMxQhzfPI/KEzygk1P8YSiFCcP0LA6L5jT/U/8OyLiKuLzd+UTMpMz0H4xtRw8JTynNjTtc815q15PLBmXGVTuoHWW269cvxKDSqRlxWUUSkl7cKDY6ysOmwhjChNxSWOyYhLGDanUpcFae21zg1DCSfVe5PsedYNrPK5I2jbPM6z8NNFef1lViJ8OU33EQYxrm3j5jVy7glTx7M+luJDnrMp//NrLGRph9xHufZRtB8iG+bkm4ld+xbkjWKQuPDF9szh1DG6zRa12KYNarVaQLHGg6rfc1f+H3lD2Bb1hrdGgxH1eolaH7smf161++lw7vZ/+6ayWzBVTLZU/eIib1uWPz4inT9SzfBZBELOp6dWqyhrtPHynzr6WOZtLNkj4Z++TMuTX5jCs5HSmlvI+9i3u3/UU31xSkRfGJw/Q3XamcI6IuEp4vJU7H8pX8p6NKDnfhqLTl4NP34TUETSe10UiL1LLDCvRbLtKp/zUC5XpU6tTwoRRRTLiurKldg8VuKm032hQqNiYMQUyEjIKLNBrXLEH3GKx48p1e45H/NxtygzZ41oFJqy0V7Pt06L9cgp5uBBhmO9BzoX5NopX3cyH38OfvpWbm+dGKJ+L0uK8SPqDN/Evv89bX57vfc6F+Wpz7gp3S5jqXT69X7/MwLRQnjo/qsoafXj0LTIht2e+pM2KM86lNk1agrWXZT99LMgfr//wFYZH5no2lxeRWD4H8VjC5tWvV1Zcbduhb+kdPD5nc2kLmnzTr7rFj1w/h2ElpxOPIeSDX2Pb/qf45pIKKuroOZ7/HAnliKuI4dH8G1OYe/bL3hfaUHQue7ULuUh0BIt0qVerw7BSC3Vab7ukCYPKhGLK9QsF/vnkIu+tO6JnIqE4NiYj7pRqY0qMSImZkDTmuOUOW2mxY/ZqNqFIt1o73Gi/ZnE5xdLP7kWYZ0yJ5PoqfuO1fOoPeNsrqKua65ldmLISXrmFj/w2/+vXeclmBPnNgrmrYGPgU9kR1tdu8aGujdYXHLdl/OvqwrYnnUtzkbZ5KUgmGBrl49+e65lcXkRi+Twk44VuXPNLipKlHjpwh8F015zN5Zt+xRErvMNHlISDczaP04nH83eof/ulfOXsvKT76e+ganH+c3r+3nVHRFxqPvFtBkfyb1DPlgsFdJwtjOtOe/x8Va+hoMKwMus8rsCodfYYU6BTgxwSMh7oL/LaiqMEgcJETEIoJ5AyrM0yrVY5bJVSQ9Z7VCjmhCVWOCgjIcRajwuEtttiRMmT4qsvR7K5/MeCMn7vjXzovdy+Kd+edjkRBKxo4Ddexz/9LrdvfKLf+kp20zj9fFltz3SK5NRjG4KdwqoXu29woZfH73JL7k6d6hRLywnOuEk93S7uclktScR4cA8/f6rV4YhpIrF8AQqTKTet/U/isYQH939NemxuhF42SPqE9ynX57/4xJzM4Vwk4vmlu7/+PPvazvENp/coVzc+0ZIRCeaIq4D7d3P/nvwb06XifBXks4XxGruFnihlT21wqtE+/cZeGvbL66GstXYZVqxEWpUuSRM6JkrtGCp2S1mfkckq8pBiWXFDyqZ/dmbSMWOpVoes1mGxVqvVO65Cr1rtjmiSE9etxhKHz6iOzzdf2guRm3S2SMT5Ly/NC8wb110ZPb+VZfzW6/nAb3H96nxP85Uoms8+X/a5xhZbpwXz1M1cX8Ea3wtfJy5n0ej9qnWo1i5laPpcWhHum5d2cU/F1PH6T9+kZ37U3+Y9kVh+CkoKK9y05pdlcxkP7vuqsczcLLEcDlb7tjd6gbtsDB+akzmci8RkQtBffJaWs9/zRofP7FGe6mEend/LVBERz5aeQT76DYSXVkidq7XiXMvBj7rZsNLpavKwlGVa1ExuZpqqPAeyAoF2ixVJK5ZWYcApNf6hfbX31bfqnigSxGLGFRhSrk2TtFKhQK12q+wXF/qZ2y3Q74gmB2wwrEypIdtsQRxZG+xwXKOU4XnrS3supvqSwzDvBPSx/4fXPHfu/bJngkXV/H9v5i/fkXfuyIVXVvrb2edLR9DoAbdaY7eGsE2pQbtt0hE0OlX+Cp8duMFzS45bM/Q13WrstskyLZZq0ajFkLJ5u6nvQiTijI3z4a9deTdEM0Eklp8GZSU1blz9i0Yzgx7af4dMdmxO5vF1/9kxS73DhxWF86f3L5nIbxD508/kk4KmqVr05B7lkorINi7iiiaX44Nfyb8RXUoxdb4NRafbxk1tAhwKKrQGa7Vardl2yx0E6zzmJvd6se8aVmKJYzrUKjQiKSMuq9cC9/cX+6Xy/RJBaDxRYUAFYnrUGVApJyEQKDFsQsx2N/mR1+hXqUanah322OiQtap1iclORg7fKiUtJntGG8l8JpvLV1lXLuYD787bbpWVzPWsZp7VS/L9zL/+mny//ZVSZT5XNHZH0Oig5if1MA8FFQ5WvN2j6SovKnrc8rGt6pxQLC1uQoV+aWceDJfTakkizt6jeYeMiAsTieWnSWXZYtevfJ3BkS7bDnxDNjcx63OYCAr8i99VpdsbfWbWx79QvGcykRcHf/Ipjs1de3dExJzz7Z+x/9ilrzo+1Yai/Bt09oze5JQBdU4q16dNk5MWa/aYhdo126Fct1f4lgbHZBQZVSie7bdvYMwLy3uklRhVLCc2ncRXoceoIgkTiqUd0KzBUbe5U7calbqnBf0RTVba5xo7dKubdhVYYb9QMK+F8lTvboA3v5i/fCeLFs71rGaXIODF1/O3/y3/u2fDK3MD4Pk2w5aG/Wpip3w98S4lsazFY/fblNuqQq+shH4VrvPwdAvH1A0t2ctCME+ten3m+/lQm4jzE4nlZ0DtgibXrXiFU4Nttrd8VxjO/trUwaDZXV7rpb5tVbh7VscelvIc95/3wpBMkB7j/Z+io2dWpxYRMS84dIIvzFBK37kqYqdvKBqWUqtDpzorHLAy3OM2dwuFOjR4rh8qkrbT9ZY64mb3erlvqtEurcQRTfZr9smT9X6voUXvRJIYhcaMKLXbRoPKxWWtske1dn0W6FIno1Ctds222695upd6mRanVEsZ0qhFXdimUYukcSWG5q3NVm5yA19DFf/7N3jdLZMuQFcpi6vzgvmlm59IJLxSON+KzembZA8V3u4ro7d7RfkJh3sOKzbimGW2eZ4xRW5zt5Xh7jNSAi+H9iLyx/VElr//Mtkr6O96qbmKT/+LY/HCZtc0vlBH7wGPH7lbOAfrUl/2Nj1qvMsHJcLxWRt3KKiwX7Mttp73wlCQyPs3/tEn6eqbtalFRMw5I2P8zRfyQis2B1fWqUpzrQ6B0A1+akCFh9xqoS4ZCY2OOGKFEcUanFBo2LAiSRnlevUNtdtY0q8snlWcyIkJndDouCVu8HMZMcNKDagQiglwm3vsdL37vNSIUrU6NIRt00lnP/NiP/JKRdJe4ruKpD3ieXbbNC99aTMT+Wjq1zyXv/8tltbN9YzmBwUJ/uur+YNfzbt+ZLJXRlvG+VZsqidXSKZu/E6UvMCBsUpvKn/M9/qXWG+HlAHbPM8RK11nm0Codh7HXp+PZJy2Tu64b65nMn+JxPJFsKJ+s5UNN2vr2mn/8a2zPv5oUOJT3muxo17nS7M6dkfQaJeNF7wwJBMMDPPHn4x22kZcPXziO/QNXRqbuItlKKiQVuI6D+u1UKlBKYO61OtX5aBrvMZXVOk2IS4QE0ooM6Aud8Q9p4q8vqrTUFiAmFCg10LLHBSXU2Rc0oSdbjQipUKfdg0W6JOS9oAXSCuxzk5ppdORwENBhR61TliiR+0Z4RDzxZd2ahNfaQl/9jbe8rK5/VvOV65fwwffy7K6fPX9chfM51ux2RU8Z/r/U4Z1WOTe5BvVJsc9N3OHH2U2W2O3lAGjShyy1kr7pJ8UPT//CYJ8X/rXfkLrybmezfwkEssXyZrFt2is2ejQyQe0tj886+PvCG601Qv9gi9ZHB6etXFLw34l0k95YUgm6B3kj/81LyAiIq5kfvoYP9s190v1dWGb9XbY4QZFRrVZ6jW+apXdarRbrFWddjEZj9nkhMXKDCoy6hPti7yvoVVfNqkoljUgJRT3HPcrMeag1UaVGFKm0KhB5U5YosEJSxyaFL4D1tthSKkST5z4+evGkC4NAuF0NXm++NKGk44Py+vz1mnrls71jOY3VWX8xTtYv+LKEMxPRf4YjXs49iLfzL7Kr1UfMdB+p33hNdbYrVOdUGCnzdbbfoZv8+VCLJb/W/7dl/Ib9iPOJBLLF0kQBDYse7H6yjX2tN3rWPfsu3t/zm9KS3mXDwrCmW82murteroXhmSC7v58hXlgfhSPIiIuOR29eb/SS20TN8WFNtae/j3rw0dc52GHrNFqjcdttNn9ulS73Z3W22ajR4yLO6XGKvsVGjUmaW+6SF1yTH1yTGGcLtViGFOg1JAxCUlZffLRdAt12+s6d/kFezVb6qhmj9piqwfcao9NoHny+jDVknHYqnkXCzzVn3zLtfzVf2VB6VzP6PKgqID/8Waet+HK3fh3OlMV6G8n3uV4tsr/rLnX3vbd9mueXmE9FFzjAbdaa8+8Ob6fCcl4/j3783fP9UzmH5FYfhYEQczGpldZWL7UY6136ug7NKvjDwUVPuc3rbLXy8x8duVUsMEzuTAk4nT28cefYnD+uN1FRFwSJrL5SkxmYuY8dy8Ucz1FyqAmB4xNRkw3226VvUy2SmXFFRgXNyGjSExWIKNWh3g46lOdS7295rjhXFy/cqWGJIwrN6BT7WRYSacy/UYV+YmXygmstcv9XmSPazXbadekP+1QUGH3pGBeYw+c0ZIxX9ovJrL5/uRfeznvfUPUdvFMScT57V/k1VvyNx25K8iP+XyMB0X+Lf77VhWlvcQ3dQ31Psm3eZst8+L4fqYEQb7CfOdD7D4817OZX0Ri+VkSjyVsXvV65ak6jx78tp7BY7M6/s/c7lE3eqPPqA47nvoJz4KppahncmEIgnyCWXsPf/JphkdndIoREbPKl37E0Y6ZDae4UMz1FJ3qdWgA6zyu3nEbPaRfpWJppQYkjQsFEiYUGlNiVEbMZzsWe0/dEUPZuOF4pSJjYrKKjRmwQJFxYwoFQsXS7vVKBAYs0KlekZHp1L6FOs9osWjTNB1kcvp850P7xfhEXhz/jzfz6puvjBS+uSAI8jcbb3nZlRdgcj52Bdf7Ue5Ffrv+sJMn7tSbLTrj8flwfF8ssYAwxwe+kne3isgTieVLQCJe4MbVv6i4sNzDB75uIN05e4MHgU97r1DgHT4y481jT2VfdZ4pSsQ43s2ffSY6ASOuDHYe4ls/y7+5XCqhdb6Wi5ThJ8Vcn85UJTeQj51u0Oa4paqckpbSqU6pAQkZRUYs0Ccn5vBYykQYWFOcNhIr02mRUKjAhKOWa7Nchwbl+lXqEopZ4ohu9U6plVZisTbd6j3iedJKXe8BpWH/eb1r55qpjXxVZfztb3Ldyrme0ZXBa57Le96Q//pKspY7H1+M/aYhZf5m8cN2H7lzTpyxZopkIr8S/K/fneuZzB8isXyJKEiWuGnNL0vECjy476uGR2fPN+1UUOvL3majhz3XvbM27jNhSjAf6eDP/43R2XO8i4i45PQM8HdfzguvS2kTd76WC7JPS3gWGZU0ptSQpHEnLZYypMSIUcXiJgRCMTmZMOFjJ5d4d/1RvdlCRcGYGu0CgR6VKvWImZBRYFC5Qhm9Kq21C1kpQ+odN6pQp3oQCO1zjVrt5/SunWvBHIZM5GiozvsnN1xlISMzzW3X8b7/lL/eX+kV5qGg3L8H73Z9asDrkncb6Nr6lHsLLifiMX72OI/sm+uZzA8isXwJKS4sd9PaXxYKPbj/K0bHZ88G4i6vcdBab/FxqXB++rVNCebDJ/mfn40Ec8TlSTbL33yR0bH8hphLyblaLk7fJ3Au4Tm1ue957lGmz4Nu1a1auT5FxkyIi8vqVwlCoWElvtrT4G3VbTJhzFi83Igi5Qa0W2REqUFllmlVYMSQckPK1erQq8pt7nFKjQGVCo0qMzAtjjuCRsPKLpg2OBdMOV40NfDX0Ua+GeOma/itX8j3gl/pgvl+z7fNTf54casTHfcpG9l+wb0FlxNBkD9nPnwH/Zdf+/UlJxLLl5jS4oVuXP2LxjNpD+3/qszE7DTphkHcv/odKUP+s3+ZlTEvhiDI37EeOs5ffo6xyKIm4jLj/9yT9yKdqT7loaDijJaLs/cJnC0889Xo/ZZqsc0WaeVOahQIVDthSIVH3aRWu4wCo0r0TSQcG+HG0gHDQakudUaVGFCmRqcC44aU61FjgT69FjpqJQIxWRlJy7QI0G6xdXae0R5yMe1aM8mUUF6/nD9/O6mip3xKxGvdvjcAACAASURBVLPg+Rt55yvzr/vluOnvqRxoph6vc9KXvVUQJPzd0j2+0bLX6tw2G8JHzrm34HIjEWdknI9+48q3B3wqIrE8AywobbB51esNj/Z6+MDXZbOzowjbgib/4Zfc7geawx2zMub5uNDFZkowHzgWCeaIy4tHD/Cdn+dbL2ZqQ9iKcJ9GLf+XvfOOb6u89//7keQlee89YztxlrNDCGFD2DMthLIpXUB3oeP2/npne2/vbUtbymUVCpQ9WhJWoIEkQHac5XiPeMTylm3JQ+P8/jiWIm/Z1rTP+/WCJMfWOY9sSefzfJ/P8/k6LBf2ypTzcq6z8OwTUZxkJXrSyUd+bDCDNJGOln6GCCKDeprIYogQbAgea07lB8OZykYRjhU1VSzEhFxhVmMlmMHhTn2QQCtHWUXlcL56FJ3E0E4I/RRyktPk+JUv2RlpONZszUL4yVfk7nMKnueyNbD1EvlnH2iCeaoEGvvXwUo0XbwvrueiyDbOD63kk8ZaIuked29BIKJRyfszdh/z9Uh8iyKWPUR8VBbLc6+iq6+Zw9V/x2bzzo6HN7mNFlK4h0cJ8kArbFcyX2HqDxu7YK5okAWzEoKu4O+0G+Qd4iBv6nMHo99P4ZKBDGpIpw4bUEs+RZQM5xRbJ/Q/1opCSllODpUk08gQIQRjoZ5cEtGjwUw7SVSwkM96ojk/oo1QlY0BdRQhmAnDRAhDnCGVXmKQkIigFysqBtFiRMeFvI+OPk6wkj6iEEjE0zqcxJHmN75kZ2zDQvnCFfDdLZ5NLVEYy3Xnwg3ngY3AymGeKoHGubW8CS1mgmgkk19nV3GyQ8+n3Tq/nTxOF7sd44lt0NHj69H4DkUse5CU2AKWZF9Km6GWY7Xe2S1rFiE8w4Ok0MR1vOT287uS+QquxV2NEMwvKIJZwX+xWOFXL8k+e3cKrtHvp0RaGEBLCWtYxx6SkMWxiXASnarMowmXDMTRShPpZFFDJN10EI8OI13EEDwc/2ayhfBpl5ZrYtrokqI5TS4DhCEQRNFNP+EcZi160hkglCT0fMwVnCGDAUIIpw8DMRxlLREYaCCbw2xAh9EvfMnO2IXylevg/qt9311xvvLlC+HyNXJ1OZCW8p3tUBLjz44lBJH0UEsBn3EhUapB/jO7gU/qDlE6lOp3k8eZolHL9+ffvh54qwTuQvn48DCZCcsoSDuP5s5TlJ7+h1cE80mxkt1czDW8SrqbW2G7IoKdv3eyuCs4K5jLT8O/K4JZwU95YYecp+zpDX06eimlmBpRxEmKWcYhBtAikCZ8n4VLBkeHvJ1cxXvcSDLNRNFNN7GEMkQXseRRzkctvfwwpYpWawQdqkRSaEJChZkgouiilwhOU0AlRXSQhIFIMjiNAEo4h25iMaFFQrCLy4ihCx09Iywh/pAva7deXL5Gzv9VMpR9hxBw92Y4b2lgCWbn6EMtfRQxcvNeESVo6aOHSLKpooU0Dou13BJTwzqtns9rd1Mt5fnN5HG2aNSydfLDg74eiW9QxLIXyEtZS07Saupbj1DV/IVXrvkiX6UfHffyO4Tk3qmgKyIYRn7YTLYkZRfMp07Df7woNwtQUPAX9p2C9/Z5zqc83vspXDKgxUj1sEfYhHbc91mS1EwiLbSRTCnFJNBCDO1UsJhEmsmkjmoKiKaTE/0RFGiaSQkaRK1WYUTHECGOqLk+dKzgAIUcJYRB3uHLlLGcJM4MNxbJ4TDrSKWZVpKoFkXsYyMFlPpV9UyS5PbLl66URZoilH2PEPD166AgQ47u83fBbF8xtSfQlDq1b18iHWIlnwNQTy5aTJxgOaEM8Dq30000j+XW0NtXz7GWcr+YPLoD+/vouQ/gTIdvx+ILFLHsBYQQLMw4n/T4JVQ2f06d/rDHr9kronmB+yngFBfxrlvP7YoIHv1hM5Wf0R4rd6oe/kOpMCv4CU3t8Ls35L+7y6c8mtHvpySnyDgJwTFWspijJEkNYx6ro5d4WhCAjh4yqCGXCpJppI9I1Ayyls85Kq3gvRa4N6GRNlsUXcRSSBm9RNBHFB3EEoyZPsLJoZLDrENPGgOEUUWhYxnaSDT72AjIJXa9yOAI6/2memZPvbiwGO69ShHK/oRGDQ9vhcRo/29aosM4xqNcSjEmwonEQCTd1JMLqGklCR0mylnEEFr+wjfI0LTz89xeKps+o6svMHOWx0Otkn93//uaHKE5n1DEspcQQrAk+zKSohdQevofNHWUevyae7iYExRzC88QLblnKuiqCB7vw2YqP6OjwlyvpGQo+B7ToPw6NFs8tzFsvPdTAaUY0ZKInj4i0JM2ooLrvKHW3gwknRrW8hlRdKLBAtgIZpBBtFRSQEVbHQ8lVWGyaTitzsdMCN1Ekk01NtQEY6YfLYfYwF4uREJNDpV8wUXs5CpOspJwejGiQy8yRlTL/Ml6YbXBpmWyR1kRyv6HLhT++U7Qhvr3CuJ40YeAww7VSipZ1KDC6shAt78v9onz+ZwLuD/6CEsiJEqqt2G2zJ22tUFqaGiFv33u65F4F0UsexGVUFGcdzVxEZkcq3mP1u5qz15QCJ7hITSYuZ3H3XJKV0XwTHNWHR7mBvhXpXGJgo+QJPjd6/Lu72CN564z3vvpCOsJY5Ba8mkjeXgDbSRHWO/ojGff6Ofc5tqKmmRaOMYqrIQQjJlmMigbSiHY3MxibR+tqnSCsKAnlVAGCWKINOqwoeYdvkQCehI4QxxtBDOAjh76RBStJNNHBNlUsVg64rkfyAyxWy82LIFvXOferooK7iUhGv7pDll0+XuF2c54towwTORQMa4V8Xm+xpAI5bEFpxkc6uFE/Y450w5bCBDAqzvljrzzBeUjxcuoVRpW5V9PpDaRw1Xv0Nnb6NHr6UUqb7OV9eymWNrnlvN5utmAcw6zIpgVZkxnM5hG2X5MBvn4FLy9B0qqZGuQJ5no/XRSrKBPRI3YABhBDzp6J9zoN0AYraQQTi/tJHGabBZxnLIzx/hOSh311kRiRBch9LOYo/QSgQ0NFjSk0sA6PiGaLlTYUGGli1jWsYdcqZQcKhFYyaWCduI9+0OZJvaK8tqF8MANilAOBPJS4XtfAkRgpCuMntQC9KOlh+hxrYg9Ioa/ci9L1BV8b0EYZzrLaOo46e1hewyVSn7P/c8r8srbfED5WPEBGnUwawpuIiwkkoOVb2IwenZ6to2baSKTu/gjIZJ3OgrOFrtgrmqCXzwL/XNnFUvBW4Tq4EzlWcFsMsj/Dp28/ezxGnhlp+xR9oel/Mk21OZK5VzAe0jIm4109JBHGUk0MkAYH3THclN0LSogSK2inmxSaKKHcGLpppp8mshCYGUte+kimg+4kXaSiaeNWhZwCe8SRh8r2UcNBehFhs9+FqOxC+VFWfDtm5R4uEBidSHcfqmcwezvRVfnSa29ylxKMSfEqgmtiJ9yOWUs4dvRO8mPjuNk/ccYB7p8MXyPEKQGfZdcYZ4PKB8tPiI4SMvagpvRqEM4UPE6fQOdHruWVQTxNA+RQCs38rzHruNu7IK55gz8v+dkD6mCgstooyAlXxbI7Q3ynyn58vEJaOuG/35Zjh3zlwrlZBtq06gnDj2h9BNHG3qS0TBEIs2stn5MraGHS6I6GCSYIYLRYWQALQm0YSSMTuIZREsfkQwQjBYTOoy0kkwYJiLopYIiFlDBECHUscCHP4mxWGyQkQiPbFUajgQiV62Hi1fIEx5/F8x2XLUiSkLFMzxIKAP8V04zKqHmSPU2rzUo8zRCyAWFd76QV4HnOn5yO5ifhIVEsrZgCwD7y1+jf6jXY9cqF0vYyWau4C2yJA97pd2IXTDXnYF//jMYA6MwruAvaKMgKgk6m+Q/JxHKQ2b4zxdl24+785RnylQbahvJopYCghlE/uopYuiiizh+eyaXH6eW020Npl8VThztaOnFhppeIjASwQLKiecMEiq6iSGdOnR0A/Iycwp1rGU3Q2gIZhAd/tPCy2yBuEh5w1hosK9HozAThIB7roT8dHniEwhMx4rYJLJ4hy1coN7NnflZ9Jj0VDTt8dZQPY7DjvHq3N+Qr4hlHxMeFsuagpuxWAfZX/4aQ2aTx671EvfSRyT38ChCCpzZrV0w1+vhp09Br+d+RApzDZMBDHqITZP/HO1hHkaS4NE35ag4f6pQTlXFqhWFNJBLMANo6SOaLjQMUmYK5dzgkyRohrCqQ9Fgw4iWMAapJ5MWMghiiAgMxNFGJ/EcYzW9RLGWXazkc0LoJ50GKiiijRQOs07uKjhOhJ23MVsgPAz+5W6I0Pp6NAqzQaOGh2+FaJ1/J2TYGd2iHhiRUDOav3ELLaTy/fC3WJBYRE3LAdoMdV4YqXcI1kBXLzz/oa9H4lkUsewHROmSWJ1/A/2DPRyoeAOL1TM72owighf4Ggso5xK2e+Qa7mL0B5IQEKMyYG1v5idPQXefDwenEBjYPcop+RCfcdaSMY5gfnM3HCiXJ2X+4FO2M14VS4dxRNtrE1qSaSaPMgxEYZPgRGstdyc20SOFYiUIsDBIKE2kkU01aszDEXMCPSm0kkovMXzItWgxkkALadRziqXs4wL60SKhZh8biafduz+EUZgtEBIEv7hbTlZQCHwitMMJGRr/T8gY3aLevvozUSt6swjhGR4gmWZ+nKEnPDSWY7XvMejBwpi3UalgxyE4WefrkXgORSz7CbERGaxYcA09plYOVb6F1eaZKfbnXMBxVvJlniVG8u1NbzIm+kAaUuvQd8KPn4RO/1kRVvBHBowjPcp2D/PASG/hoXJ49RP5w9CfhPJEOL83cqRyruZlwoe9xXG08V6bmgcS6zBa1QSrbOgwEMYgZjSk0YiRCMIwOrzJwVjQk0wkBmLopI1UTIRjJJLPudgRlSXnLEdyUqzw2XO3WEGthp/eLnuVFeYOGYnw/S34fULG6Bb1dpvURJ1sAU6KlezhIq4Vb3DNghWYLQMcq31/zsTJqQRINvjNa3N3b5Eilv2IpOg8luVeQUdvAyXV27C5uU01MJy9/ABqLNzBn9x/fjcx2QdSkAbaDfDIk/KGLAWFcYlNHetR1kbJx4c5rZe7UeFHG/qcGW/JF6CPCHKoJJ1aEtHTSRw9xNI8FMqgeZAirXE4GcJKMFYsqIihmwGCCcJMGs0YiMZIJDXksoq99BDBcg4STD8arBg4W7Z1pamQp7HZAAHf2wILM302DAUPsqoQtpwvb7D1Zx05WULNRLzI/QwQykOhL7Ao4zzaDDXUt/pfZvlMCdLIFsln3Nsw2G/ww9vD/CYtroiizIvQd1dx3EMzz1aRyltsZS2fsULa6/bzu4vJPpCCNdDdKwvmFs8FiSjMlllkHXuaHqOc4z3kwQ59s2WiFZY2kmknCQ02jrGaLuJYy6e8c2aI76TU02UNxiI0qAEzamxoUGPBRhDxtHOGFI5wDkdZiY5+2khgLZ/RSRwxdFJDPg3kUkSJ49p9Igojugm9mZ5EkmQBddvFsGah1y+v4EVu2iTHyvlzQsbohJocqXxKH3OPiOav3MdCTnJHYjsJUTmUNXxKr6nN28P3GGoV7D4ORyp9PRL3o4hlPyQ7aSX5aefS1FHKqdM7PSKYt3MTjWRyF4/5bfbyZJFZMDyTNcIjT8gVQgU/ZIZZx57GYpWTLwwmz3boc2a6G4Ng4hUWgHj0lLGUUAZYyhE+7dZydbQeFRCmtqDBzCBBqBCokI2g4RjQk8oJViGARFppJxE1UMpyWsiggTx09GFC3jmXSItjrJN5Mz2FPUv5gmK4ZoNXL63gA4SAB2+E5Dj/9C+Pl1CTQMuIieVE75VdXEYZS9jKU2zMOQeNOoQjNdux2uZGlIQQw91P35h7G/EVseynLEhZT3bSKupaD1PV/IXbz2/PXo730+zlqSKz7ARpwDQAP31abmCi4GfMIOvY00gSPPGOnN/t6Q59zkx3Y5Cd0SssgOO9YUONniQs1kFKDRYuiepAQkIgYUGDGhsmNARhQY0FM2GEYCSBZgQWJMCGmjOkE8YAQZjpIpZ6cgE1pRSjo9dlb6YnsNigMAO+enVgeMoVZk9oMPzsK/Kf/tYhbryEmlKKaR9uTT/Ze8U5e/kezQssz72Cvv52yhp2+eKpeIQgtexbfmKbr0fiXjx+qxBCbBZClAshqoQQj3j6enMFIQSLMi4gLX4xlc2fU9tyyO3XqHDKXs6Uatx+fjszqai5GvwOsmAeHIKf/3lu78YNWKaRdewNtn0Bnx7zfvLFTDYGwdgVlkRaHO+FDXzEMg7z++YMfphaS69Vg0olr0TZ/x+MFYHEICF0EE0vkeRShZY+YuhEwoaWPppJZ4BQ2kmgkFMY0c3Im+lOzBaIj4KHlaYj846EaPjRrfJeAn/a8DdRznKNKHTpvWLPXt7IP7ggspvspFXUtx6htTtw+h9MhUYF+8tg3ylfj8R9eFQsCyHUwB+BK4Ai4FYhRJEnrzmXEEKwNPtykqLzOdWwk8b2E26/hpy9HMG9HsxedrWi5iyq7R9IzqJ6ouB3OBs59G/Pw+EKjzwNhZniYtaxN9h3Cl7Y4b3ki9ETxT4RhQktCznmkvgcb4VFR++wNcJKBN10GdtYE1JHgmYIjVpCBQwRjAYJCbASRD1ZDKIlkh50DFDGInT0YkNiMcexoKaM5UhAHhWUswgdximtUJ7EbIGwELnpiC7Ua5dV8COW5MBtlwRGS+zpvFfk7OUU7uYPLElfR0RYAsdq32dgaG5kogoBSPDHt8Hguz3BbsXTleW1QJUkSTWSJA0BLwPXefiacwqVUFGcdxVxkZkcr/2Ali73OueNIoIXuZ8FlHExntnG6mpFbabL1HaC1HIF4r9ehs+Ou/1pKMyEaWQde5rKRvjt6/LfvZV8Mfo1nSQ1sJijnCbHJfE50QqLBCSiZ5d0EW+1hnJnQhMmKQgrGozoUANWBCYiaSOJeDrQYKaNZMxoyKSBaAxYCOYAGzAQB8AAWgzEYCTSMfaprFCewDocEfeTr0BSjMcvp+DHXH0OrF3o/xv+pvNeMYsQ/syDpNDEDeINivOuwmIzz6k4OY1aXvF97G3//b1NB0/fMtIA53ZPjcPHHAgh7hdCHBRCHGxrmzu7Qt2JWqVh1YLridIlU1K9jfaeeree/zMu4gTFfJk/Ey11uPXcdlxZzp3pMrUzGjUgwaNvwYcH3PgEFGaGi1nHnkbfCf/6vCzCvLmc7/yazpNOsY497GMj1aLIJfE50ZJvrSiklnwa9If5XlIVAzYVNlUQ/WgxE0QQg6iwMYSGCAyosGFDjZZ+QBBDOwOEUsFSdnI1J1hFMk00kDvsUzZOywrlTmySbCH55nWyV1lhfiMEPHADJMX654Y/mJ5t0M4JsZLPuJBreYWC0H4WZVxAe08dtXr3Wy59hVoFR6vhM/cvinsdn2/wkyTpCUmSVkuStDohIcHXw/FbNOpgVhfciDY0hkOVb9Pdd8Z9JxeCZ3gQDWZu5//cd14nXF2icodHUq0GATz9Hrz0sYdmtX4cieZXuJB17Gl6TfDPz8LAoGzX8Tb213QmtZykGL3IcByfjfi0DepZYD3AYm0fQ6owBKClDx19dJCAlSBi6SScPgYJpokMQjCho4deolBjpoATJNI04r0JskifSKhPZIVyB5Ikrw5duR7OW+axyygEGCFB8NOvQEgwmP1QMM/0vfIC9zNIKPfwKJkJy0iKXkBF4256TK2eHK7XsKdjPP53uSV2IONpsdwEONcG0oePKcyAYE0YawtuJiRIy4GKN9yaz6gXafyNW1jPLpZL7i3JTmeJyl0eSbVKfnG/vQd+/5YHKhJ+GommMJIhC/zbC9DZ6xuhDGdf02UsRTvsA7YzU/EpSRL65nf5YUo1HVYdjSKXBjLQYMOKmgGC6SAeIxF0E0Mn8WRQRzg99KOjiUwayaGPcDbzNka0XrdajIfFBoWZ8JVLfHJ5BT8mKQZ+eIvcLc6fNvzNhh4Rw0vcSxHHOZ+PWJp9GUGaUEqqt2G1zo04OY0ahszyfTiQ7RieFssHgHwhRI4QIhi4Bfi7h685pwkNDmdt4RZUKg37K17HOOC+Fnbb2EITGdzFHwh2Y/ayq0tUk4nqmSRqqFSyaP7sOPz7CzAw5Lan5JeRaAojsdnkvM86L0fEOTNdL6OrdHce5oGYA6gAvTqTOnKIo5Ma8hgkjHD60GGilRTMhKDGggYLbaTwN26lmzgEUE0R+9lIGHKPWl926huyQLQOfnSLvDqkoDCaZblwy0WyTSeQhZczn3A55RSxlaeI1ZhZlnMFfQOdnGr81NdDcxsatZxU9UmJr0cyczx6C5EkyQI8AHwAnAJelSTppCevOR/QhkSztvBmbJKN/eWvMjDknvUNiwjmGR4kET038Fe3nBNcX6KaTFTPdPOfELJgLq2Dnz7l5p25fhaJpnAWSYJn34eDZd6PiLOTJDWTMBzz5vz6NxIxKzFqtgyQZniDy6I7+EhcSwfxrGEvDWQwhI4GsgjCQjtxNJJJP2Gk0UgXMRxhPRps7ON8jrIGExEcFJs4KVY4zu9pq8V4WKzyBt2f3Q7hYV69tEKAcd25sDxP3vA3F5Czlx8iDCNbeYqEqGxyklZxurUE/RyJkxMChARPbYc299X3vIrH6y2SJL0rSVKBJEl5kiT9u6evN1+ICItnTcFNmC0D7C9/nSGze9rllIllfMJlXMkbZEi1bjmnq0wmqmez+c8umBva4EePy5u93IIfRaIpjOTNXfDBAXl1wVeNLIzoCOfsRNY+wWsleVZitLHxQ/4l7QTVtiyOiZVE0EsX0YRg4TBrMROCgSgGCCOHalRINJFJNwkk0Uw43cTRSj0LRohkX2EbrhA+dCNkJvl2LAr+jxDw0E0QGymvRswFGkU273IT57ODRdJRCtLPIyIsgeO17zNonhvZa2q1/Pt69M3AXBXw+QY/hZkTrUtmVf4NmAYNHKh4A7N10C3nfYn7MBHOPTyKkPxn+j6bzX9CyJWrzl744eNQdnqWg/GjSDSFkXx4AF79VPY2qnzY8c0d6S6j6eg5zd1hfycxyMwrqq+RTRVtpFDPAmyoKOIoKmyUsJYQBlFjZYgQqllIF3F0EkcTWY5uY77yJtuRJFksX7sB1i/26VAUAghdqLzhz56vPxd4i620ksw9/J4QYZPj5KxmjtW+N2fi5ILUcoTnjgAM/FDEcoATF5nBygXX0NPfxqHKt9zSY75PRPIiX6WAU1zIe24YpetM5k12x+a/YI3sXf7Fc7P0T/lJJJrCSD4/AU+/K6eheCtLeTLc2QHPajOj0b/MvQmNfMjVw7kWMdRQQBnL2ccmEtHTj5YuEjERQQ9RHGYdsbQhASWso50Uaoaj53zhTXbGYoOiLLjlYp8OQyEASU+Ab10PiLOrE4HMkAjlzzxAKo1cw2tEhMWzKPMC2gx11Lce8fXw3IJ9le/Z96G1y7djmS5+cDtRmC2J0Xksz7mSzt5GDle9g802+6n2Hi7mJMu5hWeIktzlW5iaibzJYHXbRqkgzdk4m+c/nOHOaj+IRFMYydFqeYlPINtuJmMmG0ZnwkQTvJlcv7b5M36Zup8OKZo3xF2kcRoTOg6zgSi6KWY/lRSipZ8IeuglEitqFnGc0+RRSwESaocFxBfeZGfMwxv6fvClqX9fCgrjce4SuHSV/Hk+F4qvx8RqPud8ruNlkqVGMhOWkxiVS1nDp/S4Mf3Kl6hV8nv/d28EVqqJ8hE1R0iNW8iSrEtpM9RwtPY9pNnaJ4azl4MZ4iseyl4ej4mWrkHt1gYJ9k1f2/fCL19yc1JGoDCHsqIrGuFXL8k3TFeSFGbbLdIVJkvCmO71e0xtXC69yRJtHy+oHqRf6KhkIak0kU05CZwhmH5WcJBassmljAi6CcJMC2lE0EsjWZiIcNvzmw1Wm/we/PFtoFM29CnMgrs2Q1aSvEoxF3iBrzFECPfwewSwNOdyNOoQSmq2YbXNDZN2kBqqmuHDg74eiesoYnkOkZm4nIXpmzjTWcaJ+o9m7XNqEen8jVvYwKcsk7z3qh5v6doTDRLsntajVfDIE9DZM9uRBxhzJCv6tB7+9S9gsbjenc8TfuLRTJTukkUNIKdiFFFCitRAESUYh4Xs6OqyJNnoanqDR1KqOSCt4SAbANCLDE6wnIt4n3YSGERLNQtYzAnUmImnnVMsYxebaSCLPCrcOhmYKdJwh757r4ScFF+PRiHQ0ajhka2gDZErloGOQcTyEvewmKOcx0eEBOlYnnsFff0dlDfu8vXw3IIQ8grgcx+4ccO9h1HE8hwjN2UteSnraGg7RnnjrlkL5nfYQjPp3O3m7OXJcFdjElewJ2U0tcP3HpMrlPOGOZAV3dAK//QMDA5Nv+mIO/3E4zHRBK+e3OEqspYwTCzkKGGYMKIdt7pcpz/Mz+N3I1RqnhcPjoj3MBLNPjaRSxVHWcOnXEU3MWiQqGQR/ejoJZLDbMBADIm0eMRu4iqSJFeV1y+Ci1f5ZAgKc5CYCHj4VnmfQiAt7U/EJ2ymgiJu40nCJQMJUTlkJa6gTn+YNkOdr4fnFtQqsFrhf18LjBhARSzPQQrSNpKVWExNywGqz+yb1bksIpineYhEWibMXnan/3OqJg6e8JoKIW/8Mw3Az5+R0xTmgv/NJQI4K7qhFX72NPTPsI21NydlzjhXmEPpJ5VGQhkgi5ox1e3+QQOFxte5LLqD18RddIjEUWezksQZDrOetezifLYzSBgmtMTRjoFIVrAXgFKKkcDtdpPpYLFCQjR84zrfRfopzE0WZcGtc6RhiSRUPO2UvQywMGMT4aFxHKt9z21Rsb5Go4Y6Pbw3O5niFRSxPAcRQlCUeTGpcUVUNO2hTn94VuebKnvZnf7Pqbr9zeRargpsu+B6+l3449tzJ8NzUgI0K7qxDX72zOyEsic6602HMEz0EsVxVtFLJGGMvAFKkkRdw7v8Z/opprXbwwAAIABJREFUqm057OC6EV9PkhpYxx72sZF6chkglDyqqCOHg5yLgSjOYRddxJBDJRH0EE6v2+0mrmKxgkYj+5RDg71+eYV5wDUbYGnO3PAvN4pstrGF89lBkXQUtSqI4ryrGLL0c7xux5yIk7PbMV78CJo7fD2ayVHE8hxFCMGynM0kRS+g9PQ/aGyfXeNEe/byvfxuTPayO/2fU3mTZ3Kt6Qhs9XCL7N3H4CdPznEfc4BmRTe2wU+fllcCZiKUwfUW7KNx18pGAi30o0VPCtlUoSeVfrQk0OL4nuaOUr4Z8TEJQUM8o/oeNjHSkB1PO/vYiF5kEE87R9jAu1xPNrV0E08FS4aryUEetZu4giQBAh64HtLivX55hXmCSgXfuVlOWZkL/uW3uRU9KdzNowRJQ0RqEylMOw99dyWN7Sd8PTy3oFbBkBn2lfp6JJOjiOU5jEqoKM67mrjITI7Vvk9LV+WMz2XPXs6njIvZPs7XPev/nM21piuw7T7m03r47mNwqn74C3MoPQIIyKzoxjbZemEakK0zM2WmG0bdsYoSLhkIp5d6ctFiYh8b0WKknlzC6SVcMjBoNqJtf5N7EhrZIa6lTuSPOc9JsQK9yHD8vYR1nCGbvVxAHuU0kc1H4jrqyfWJ3cSO3ad88UrYsMSrl1aYh+jC5NULtSowvLCTYRYhw9nLTVzLKwDkJK8mLiKT0tP/wDgQYGHFAYwiluc4apWGVQuuJ1qXQkn1tlltDtjDxZygmC/zZ2Kk9hFf86b/cybXmq7AFkKuWvYPyA1M3twN1uC5kR7hIMCyopvaZaFsnKVQng3uWEWxV7XtcYj6YRuI/d86jJTXf8ivM4/SSSyvceeU5zzbSjsJCcExVrGYEnKlUp/bTSxWSI2Huzd77ZIK85ycFLjnSvnvge5WOC5W8RkXcg2vkiqdlleNc69ACBUlNdvd0ldBYWoUsTwP0KiDWVNwI7rQWA5XvU1nb9PMTiQEz/AQGizcwZ8ch73p/5zptWYq5oM0sqfq1Z3wz69E0R0R2OkRgUp1M/z4Sd8KZTuzXUWxV7Wdq9vO/z7a1ceWkI8oCuvjWfEQA0I75Tl1GGkliUT01JJPtVjEPjZSxHFancY423zy6WId9ik/fOvMLTMKCjPhklWwbpFcXQ50wfwCX2OQEO7lUYRkIyw4gqXZl2IwtlB1Zq+vhzcvUMTyPCFIE8rawpsJDY7gYOWbGIz6GZ1HL1J5i62s5TNWSl8AM/d/zoSZXGu2Yl6lkvOYKxrhoaeiONkVmOkRgcrxGjkebmDQ90IZPLuKMmTpp+/M2/wotZZ90rkcEetdepxsHxnZuEcvMviEzcBIr7O3OvdJEkgCvnYNJMd6/HIKCiMQQk5dSYiWVzcCmR4RzYvcz0JOcAEfAJASu5C0uCKqmvfSNdMCmILLKGJ5HhESpGNtwRY06mAOVLxOX//Mtp9u52YayOYu/kioZPJIw5CJmMm13CHmhZC7DgWbDfxtu55XjqVh7gyc9IhA5fMT8O8vyBXK8SqT3mpb7XxuT66inGrYya/SS7CKEP4ivjnl9zs/f/t7w/n5+7KltT1P+fzlPrm8ggKhwfCT2+TVDWuAC+ZdXEopy7iVp4iW5Ht3UdbFhAVHcLT2XSzW+diG1nsoYnmeERYSybrCLwGC/eWvYRqc/k3eKjQ8xUPE0MEWnnPpMd4WNc64S8yHSwYWqCqpV+Xz5skMfv5uPvqT/p8eEai8tw9+9wYgTdyZzxttq53x5CpKm6GWjdJHXBDZySviPrpF3JSP8fbzdxWzBaLD4evX+nQYCgqkxsM3r5NXOQLajiEET/MQQQxxO/8HQJA6hOW5V2Ia7KH09E4fD3Buo4jleYguNIa1hVuw2izsL3+NgaG+aZ+jShTxMVdxGX8nVyqf8vv99aY+HZyFkloFVd1R/Oy9fN7+2MiQ2dejmztIErz0MTz7wXAyySQtrL3RttoZT62iWKxDNDW8w39kVFEuLeIfXOHS47z9/F3BapOtSw/fCmEhPhuGgoKDjUvh/GWB719uEem8zVbWs4sVktzJIzYinbyUtTS2H59V4pXC5ChieZ4SqU1gTcFNDJqN7C9/bUYdgV7hbrqJ5T5+h1qaPNTSH2/q08VZKNm7/vURxUuHU3nw904Rc/OdWUTsmS3w2Nvw9mfyh5PahU8ob8YW2nH3Skl54y5+lnSECLWVp8W3kYTrH82+eP4TIUlyB7WtF0Ouf4aqKMxT7rtK9s4Hun95GzfTQBZ38QdCpH4A8lM3EKlN4njdhzMqfilMjSKW5zHR4Smszr8B06CB/RVvYLYOTuvx/ULHc3yDLGq4grem/H5/uqm7C5VKtgh09sgRc3/6m5zYMK8JnVnEXlcv/PQp2HUc1EL+2bqCL9pWT7ZSMl0h3dFzmuz+j7k1/gzbxRaaRPa0xuKrtt3jYbHBoky4+hyfDUFBYVyCg+CRrbJ/OZAFs1UE8TTfJp42tvAXAFQqNcW5V2K1mTle9/6c6O7nbyhieZ4TF5nJygXX0NvfxsGKt7Bap+cnOMi5HGADN/G8QwxMJBZypXK/uam7m2CNnJjxSQl867fwxcnAXu6bFfbmJtOI2KtohO/+Eer0slAWwrVL+apttfNKyRLpEEWUOFZKjOgoooScYXvSZJYji3WIirrt/Da7ghYpmbfZOuK5TVWp9oe23XbMVggLljuouTrRUVDwJilxchdJAty/XCmK2MHVXM7fyJEqAAgPi2Nh+vm0Geqoby3x8QjnHspHmgKJ0XkU515JV18Th6r+htU2jT6hQvAc38SChnt4FCQJIzpWsJckqQGQb+hFlJBODX1E+Pym7imEkKvM/YPyxrSH/w+q5muijzZKjtabImJPkmDHQfj5M8Ptq9WuC2XwbmzhaOwrJZEYCGOsjSmBliktR2UNn/Lt+BKyQ4zsFFcQgrys6qqn35fP3xlJkn9v375J3tinoOCvbFgCFxYHvn/5Fe7GQPQIG2RWYjEJUdmUNXw647QrhfFRxLICIGc2Ls2+jPaeOrkrkOR6n9AuEc9L3MsSStjEDvpEFBUUsY495A13EDMSzgBa2kgGfHdT9wYatVxlrm2RO8799nXZpjGvMBnAoIfYNPnPcRJD7P7kp96V/z2TphXejC0cjd3+UEs+/WgposQhjksppoHcSS1H7YZ6oo27+VbyafZwIZ+w2eHpL6KEPiKmtCrpRSo6jCMmnfbqtjeSZuxYbXDBclhZ4LVLKijMmHuuhOS4wLZj9Asdz/JNsqnmCt4EQAjB0uzNqNVBlNS8q3T3cyOKWFZwkJGwlEUZF6LvquR47fR8Tzu5gjKWcBtPECV1ohcZnGQ5yziMQEKFRCnFI27+vsyA9TT2DYAqAZ+fhG/9Tu4CODAfojDtHuWUfIjPOGvJcBLMjW3wyBNn/cmubOTzJ0bbH0opJgwTOVTQThLApJYjs3WQk3Xv8oecCvqI4gAbAGgniRwqCMPkmFhOha+TZoaGY+Ludi3AQ0HB5wRr4CdbISgosAXzQbGR/ZzLTbxAkiQvY4YGh7M0+zJ6THoqmz/38QjnDgF2i1LwNDnJq8hPO5emjlJO1n/ksmCWhIqn+DYhDHIHjxMuGdBioppC8ijHhG5ObOibLvZmJkjw5m742v/A9i9gcC5HzQ0YR3qU7R7mASMWqzxp+OGf4HTr9PzJvszqHs1o+wNAP1p6iCaDGoeHeSLLUVnDp9wbW8rSsG6eFQ9QxjKKKKGAEwQxRD9Tt7i248ukGZtNnuj84MtyAwgFhUAhKXZu+Jef45uYCeI+fosYXhFOjsknPX4J1Wf206l093MLilhWGMOClPXkJq/hdNtRyht3uSyYz4gM3hrOgLyUv9NKEhKCY6xiMSUOD/N8RKWSRcXgEDy/A+7/9RwWzbGpYz3K2igqTal85w/ypAHk6s50/MmerKBOV4g72z/CJQMr2Es9uZwQq2gfrgjr6CFJah5jOWoz1KLp2cuP02o5wAYOcC4AYZgwE0IFSyileMRznWp8vkiascfEXXcu5Kd7/HIKCm7nnMWyfSiQ/cvdIo6/ch9FHHe0wgYoyryIsJBIjind/dyCIpYVxiCEoDB9E5kJy6lpOUD1mb1jvmeim/cBzqWZdC5hO+nUU0s+1WIR+9hIIafGPMafqoXeQK2eR6J5mIEheGo7/NMzoO+SrSkzSUvwZAV1NkJch5EKikgctlvUiELqyaWQU47H2y1HZssAx2vf5/c5VdgI5lm+BUKQSAv9aKkln3j0ACME9lTj80V8nNkKqXGw5QKPX0pBwWPce6VcZTYHsB3jEzZzkuUjWmFr1MEsz7lC6e7nJhSxDGhDZN+SzfU9bXMeIQSLsy4hLa6IiqbPqG05NOLrE928e4jiT/yQSAysZL9DyOhFBodZN2ZDn6/9ltPFXeJ+tGi+77/hrx9BZ687R+tbzBb4+LAcpbfj4Fkf93SqyaOZbgXV1d/XbIS4XqSid7JbpEgNJKLnMOscj7eP41TDJ2yJquTc8FbeFLcRwiDhkgEdvZRSPMK2YT/3VOPzRXyc1SZvZP3BlyduRa6gEAjY85eDNGANVMEsBE/zbYIwcxd/dBx27u6n76ry4QADH0UsA5lJcnXEBtgCdCnGEwghWJqzmeSYfE417KSh7Zjja30iij4iRiQA1JIPgJEIPuB6NrGDAunkiMeM3tAXaJ393C3u7aLZbJG71n3zN/DfL0NlY+AuCw4MydXyr/4antwOff1nE0Jmy3QrqNP5fc3WyjDZ443osHZ/gdlwiH/LrKGCRTSSgREdWdTQ6vT9fSKKVpIoZv+YlAsTOhZyfMT5vR0fZ39d3nk5pMZ75BIKCl4lNQ6+cS1IAexf1otUXud21vA5a6Q9juNyd79Ejtd9wKB57qVPeQtFLA9z43lw+Wq5uhyobxZPoBIqinOvJiEqm+N1H9LcccrxtTaSxyQA2IXIa9xBBwl8ld8QJE3ulwqkzn6eEvdqlbwRUCVgf5lsWfj+Y7DrKJim11jRZxgH4I1dskh+foecN60W7qs8zqSCOp3fl7MQz+fUGI/9VCsIkwn5DouGbXXV/Da7ijBhYSeXU0shfSKKenIdFg77eRLRU8nCUb7lBtaxi3YSRpzfiG6MMPZk0ozFCgUZcNlqj5xeQcEnnLcMzl0CVilwNcB73EgtC7iTP6KV5GVKlUrN8twrsViHOF73odLdb4YoYnkYIeCuzbB+cWCb/T2BSqVmZd51xEakc7TmXVq6Kh1f60dLEEMUcGJEF7NBEcbTfJtUGrmRFxzfP96yeJLUQD6nAqaznyfFvXPkXEMb/OnvcPev4N9ekCPoZh0919k8NvPYZJCPzwCLFY5Vw+/flEXyq5/IVXK1yv3L8zOtoLry+xotxMtZxDr2jGisM9kKwmRCXpIkTtTt4PKIBjZHnWGv2EQli8c8j9GC3tnakSeVso497OU8QNBKEjlUkjT8/d6yLVmt8nL1QzcqXfoU5h73Xw3xUYHrX7YJNU/yXSIxsJWnHMcjwuIpTN9Ea3c1De3HfTjCwEX5uHNCpYIHb4DFOYpgHo1aHcTq/BuJ0iVTUr2Nvu4TjuYLFSzBTMiYLmbHxSo+4TKu4nWyJVlgj14Wl6tleyhnUcB09vPGZipn0awSUFIpC9K7fgn/+aLcTru7bwYnDtWNzDy2ZyKHui62HAL5LXk8v3wJPj0Kkg00Ks9lJs+0AYkrv6/RQlwvMtjHRgoodWkFYTIh39h+gqHeUn6TXUkLKbzDljHjmEjQ249nUstJllMjiqgln0T0mNBRyCmv2ZYkSV6mvvdKWVAoKMw1QoPhx1vlVT5rgO5hqhd5bOdmLuQDFkuHHcezk1YSF5nJqdM7MQ50+XCEgYnwp5L86tWrpYMHD/p6GAya5fa7dS3yjX82G5LmGmbLAPvKX8XY38F5BVeQGJFCDpW0k0QGNbSTTI0odHy/Vurjv7ifHqL4Jx7FKoIcVbh2klhAKRUUoRcZjsfIG56MftmwxLmCOHpzlVdybSW5chusAYsNYiNgWS4sXwALMyEu0oWT2AVyVJLcXc85E3kcjANQewaqm+BEHZyql8cxZB62jvjxlHu2v68UqYFkmmghjTNOr1FXMQ10s/vkczyVV841kXX8h/hPysRycqRyEmhxNOqxt4Q3EY5AGjPedpIc3QL7RNSsxzUTzFZYnAU/v1P5TFSY2/zjMPzftunlwPsTQdIg/8G30GDmER5nUIQB0D/Uy+4TzxIeGsf6RbegEv7x4T0wBF+5FG44z/vXFkIckiRpSlOZIpYnoK9f7jDW2jWzNrxzmUGziX1lLzMw1MutBUsZDF81qRBZKX3B9/kFr3M7b4nbANdFSJLUjHFUQxNfiml/Go8kydUPq1Xe0W2VQBcib7rKSISMBEiMgcRo+c8RTSPaG6CzCWLTsMVm0NsP3b3Q1SdXrLv7oLoZyhvk40EaWaRL0vBmPf/4jJ2S2fy+JhKqriJJNvaWvcL6oJP8Ne8g27iJl8RXHecuooR2kmklmSJKACilGJC9/60kkeh0Xft47MdnOq6ZYLWCRgOPPgixrkzIFBQCGEmC/30N9p8K3LSXfKmUn/N9PuJqnhPfchxv6jjF0ZrtFKRtZEHqeh+O8CyBIJYVGTgB4WHwL/fAw4+DwagIZmdCgrSsLdzCgbIXebnyBOsWLiFSO7z0LMlLz32cvXk3kcV+zuV6XuKAdC7dxJBBDSbCiUdPrxQ54c3ebtuolcZWBn3BeAJLTgbx/rq0GN48Z/8wVyNvBqxogLJ6UKnlyq+EXAWWJFnkRmIgT+hpV6WRiJ4KayRGEUWqqhmT0NEjRWG2yOeMURlIUxtpJTUg3wMz/X2Nnvj1SpEjXoeuUH3mANb+en5XUEkDWbzGnSPGUCrJjUeykf00zu3ga6V8sqgZY+1olZIo5JQjlm4m45oukgQIuO8qRSgrzA+EgG9cJ3+WdvUG5v2/UhTxgXQ9V/AW+6TzKBPLAEiNXUhrVxWVzZ+TEJVDlC7JxyMNDAKkPuQbYiNkwRwWAkMWX4/GvwgNjmBV4a2o1SHsL3+Nvn45CH08D6kRHV+wCRNavs5/sxjZR1XHgik9yoEWLedLhBhO1dBASPBwm21AACFB8n+xagP56krqVfm0kEEN+RSoK4lWGTChI0eqJBIDIUEQpzGQp6rE5KeZ155ktAdZh5FWkkZsJpwsHcNg1FPZ/Bm/zmslTtXLE3wPixjZD9ruRw7CTAO5I17TfSKKk2LFOK9z9Yj8Zk/HxIHsUS/KhvOXe+wSCgp+hzZEzl9WB7B/+VXupIUUvspvCJYGgOEeCtmXEKwJ42jNu1htirhxBUUsT0FKHPy/u2SPaKDukPUU2pAo1hZuAYTsY55g00CfiKKUYv7BFeRQzVo+c1TR7JmyWdRMeJ1AipbzZ4QYKQKFAKOT2FImJmcZvZnQiI5E9CM65k2UQmG1mTla8y6XRPeyJbKU7dw0wsdvZyYbRWe6yXGmWIYtPg/cEJjeTQWF2ZCTItsDIDA3/A+JUJ7kuyRzhi/xnON4sCaMZTmb6RvooKJxtw9HGDgoYtkFclLgJ1+Rq3YWRTCPIDw0lnWFW7BJNvaVv0r/4MQV4j1cTA0LWM0XJCJX5OyZsvXkTnwNH7TynatMJbaUicn4TDaRGB2HWNawC4b0/CHnFM2k8QZfGXM+X3Tdmy52+8VXr5ZX2RQU5iNXroOlOYFbXS4Ty9jB1VzO2+RLpY7jCVE5ZCYWU6s/REfPaR+OMDBQxLKLLM6G794sV1cC9U3jKSK0CawtuBmLdYh95a8yMDS2Z7MseFt5nq9hIYhv8D+kSvVTVi8DQVTMJebjxGQ6LbHHm0g4xyHqu6upbz3CH/JbiFcZeJLvYRYhY65jr/Dbj9s7YibSMuU4vIXFCkuyYdMyn1xeQcEvEAIeuknex2QOUMfCS9xLBwncz/8SJJ3tcrUwfRPakBiO1r6H2RIg3a98hCKWp8HaRfImF0mSO/0pnCVKl8SagpvkpIzy10a01XQWvBViKS9xD6k0ch0vT1m99HYr3/nMfJ2YuNoSe6KJhP01GT90ghO127kqboDrIsr4gOuoEIvHvY69ku98nTaS0dHrtlbqs8Fqk73v37pesV8oKERo4Ue3yhukA/HePyjCeJLvkEojNzk1CdOogynOvZLBoT5KT3/swxH6P4pYniaXrIIvXQg25KxZBZkkqZkMnY41BTfSP9TD/vLXCDLrSZKaxwjevWyimnzWs5sCTkwqxrzt0ZzPzNWJyVSVY1e82lNNJHqJ4K3aasIY4DdZpbSQwmvcNeKaU13HXzzjdm/mXZuV9AsFBTuFGXDz+fJ9PxD9yyfFSv7BFVzFG+RJZY7j0eEp5KWuo6mjlJbOCh+O0L9RxPIMuPE8uHy1PMMMxDeNJ7BXzTLDI1m94AaMA13sq3iLLkvQCMEri44qHucH9BPGpWxnFV842grb8eXy83xlrk5MXKkcO1ssJMaWUhNpoY+ICScSjWd2c6a3lccKu4hXdfEXvs6gCB1znqk84f7gGbdYITcFLl7p9UsrKPg1N5wH+elyQ6hA5K/cRydxfJ1fj7BjLEg5h0htEsfrd4xYFVY4iyKWZ4AQctXlnMVKW2w7zlWxpZEqbswrorXfxCeVO7BYhxzfZ69eNossnuUBcqgijXoKKPWL5Wdv4KpHVsE9uFo5tlsstPRRRMmI16OOXtpIHnNeAFVvCSebD/KlVA1XhB3hEy4lCsO4KyZTecJ97Rm32uSorIduCpzGMwoK3kKtgu9/SW7wFIib/fuFjif4Lqk08iWedRxXqdQU516J1TrE8boP8admdf6C8nE4Q1QqOU5pSY4imO04V8Wioosozr0ag/EMByredAhm5+rlXjaxj41czjvoSXWImZXso3VUVW0uiUlXPbLzEU9NJCar2I62WNi76BVRMqG4to+z2xrE57W7SArR8KuUL2gngYOcQzmL0GEcMfaprBy+9oxLktzA5paLIDnWK5dUUAg4YiLkzf6IwLRinhQr+ZBr2MzbLJSOOY6Hh8VRmL6J1u5qGttP+HCE/okilmeBRi2b/nNS5GWZ+S6Yc6RyMqhxVMUWxCSxLvdCuvuaOFT5FlareeQDhODPPIARHXfwOJ3EkUwTTWSQ6FRVs4sIrdPmJzvTEVL+UtH1F2+qP+KpicRkFdvxvNqlFBPCoKPdtbONyN5CO4dKDtd/RtegmecKa4kUPRxnOWdIR+6naB0x9gRaME5i5fC1Z9xshdQ4uNo/OuAqKPgtK/ID24r5MvfSSgpf438IlUyO49lJK4mNyKD09D8wDXb7cIT+hyKWZ0lIEPzTHZAcE7g+JncQLhlIGI696iWSWvIpooTNsb2szTmfjt4GDlX9bUy3oF4RzTM8RA7VXMNrw8vgcre00WKyjWSXhdR4whisrGCvX1R0/cGb6o94YiIxVcV2PK82wCAhBDFIBjWESwZypXKKKMGIjj4Rxc4OqO+s4js5sCaojEOsZydXyhM9DKxjj2OFJFwyEE4vreNYOeyecF96xm02eYn5OzfLNgwFBYXJuf0ySI0PTDvGoAjlcX5APG1s5UnHcSEEy3M2IxAcq30fSZrHomYUilh2A7pQ+MXdEK0L3BzG2aLDSCnFlFJMDpVE0ANAO8nExa9mafbltPfUcXgcwVzGEk6wnA18SjCD1JJPInpMaEeIyekIqfEqlInoqaDILyq6vvam+jPunkhMt2JrF9elFHOIDQCs4nPSnbpM9va3c6h+D8WRGn4Qu4d24nmdO9BiwoSOSAycpJhE9D5/rbmCTYJrNkBWkq9HoqAQGARp4OFbQaMBawAK5kpRxHZu4mLeY5l00HE8LCSKoqyL6OxtpFZ/yIcj9C8UsewmYiLgX+8Bbej8FMz2qpiz0Gkg19HmNyNhKUuyLqXNUEtJ9TZstrOfLjqMPM1D9BDFN/g1g4TRShKpNIybaeuKkJpIWOtFhs8rur72pvo77p5ITLdi6yyu+0QUDeRiJphOEimlmDRrGcer3iREBY/lVREiBvmAa+kmllaSWEwJPUShxThmwuePDFnkiLgtF/h6JAoKgUVyLHz9GpBEYNox3uB2Gsjiq/wGrXS2mVha3GKSohdQ0biHXlObD0foPyhi2Y0kxcoV5uCg+SmYYXKhk5m4nKLMi9B3V1FSs90hmPUilVaRxpN8lwzq2MoTJKLnCOvHiMnpCKnxhPVkj/eWp9nX3lR/xh8mEqOjDuPRU0sBAvluuO10A4aBHn5ZMMgidRXvsIVdXE4RJWRRwz420kfUsHA+Sg+Rfrt6IEnyZuVv3wTBGl+PRkEh8Ni0HM4pCszOvmYRzOP8gEi6uZPHHMeFECzJvhSNOpijte+NKG7NVxSx7GaykuBnt8u+v0D0Ms0GV4ROdtJKFmZcQEtXhSyYnTxRR8UadnA1l7GNYAbHiMlEWsY9f65UPq7IzZXKRwjjJKcK83jj81ZKxVzNM3YHzhMJ+yTFeSJhn7zMZmLj6mPHez0Ptn9EZUcdV6XFs0X7BbUs4A3uoE9E0UYy7SSjFxkY0ZGIflg4R/vt6oHVBhcsh4WZvh6JgkLg8rVrIDo8MItkdSKft9nKRnayVtrtOB4SpGNJ9mX0mFqpbP7ChyP0DxSx7AEWZsIPvyznMQfibHOmuFoxzU1ezcKM82npquDoKMH8V+6jmXTu5E8jloX6RBRGIsY9vwRjRG4RJcTTMkLoFHJqRCTd6PEpKRW+x3kiYZ+82I87T15mM7Fx9bGjX8+G/k62n64nPSKWh1NOARIfcA1a+gCoFYUO25H9sXqR4XhO/rZ6YLFCWAjccbmvR6KgENiEhcAjW+VVmkC85/+dL1NNPvfwKDFSu+N4ckw+aXGLqT6zj+6+Mz4coe9RxLKHWFkA37xOXuYMxF7yM0EvUh3ZsnZkkasbU7XLTV7DwvRNnOmrnGZ5AAAgAElEQVQs52jNuw7BPCRCeYwfEUUXd/OHMecfryJbKwrHiNw2kimleIQwPsw65EivkY93rugqKRX+Q5+Ioo+IMXnHcFaMzmRi4+qkyPn1ZrEOsbd6BxpVCD9YEMYSjvIXvsER1o8rgP199UCS5Mn816+VNygrKCjMjpwUuO0SOas80PzLVqHhMR4miCG+zq8RTgWsosyLCA0O52jtu2PjX+cRilj2IJuWy1UbmxSY4eUzYToVv9yUtRSmn8eZzjKO1bzniKmpFQW8yVfYwKdskHa6dN3RIrdWFM5IrCgpFf5FG8mEYSKHCtqRoxrsr6fZTGym81hJkjhR/xGGgR6uzy/mNvWLHGENn3K54zUVaE1zLFZYnA3rFvl6JAoKc4er1sOizMCMkW0R6bzA11lCCZt5y3E8SBPCspzNGAe6KG/cPckZ5jaKWPYwV62H686VxXKgzTZnwnStDHkp6yhMP4/mzlMcdcp1fIcvUUERd/EH4qTWKa/rDpHrqc1l/tIMJVAJZpAIDBRwgiJKHNXlnFGedPvP2JWf93ReLw3tx2nuKGVx6lp+ovsLRsLZxSXkUuHYdGoX8IHwe7Xa5Lirr18rV5cVFBTcg2o4qzwsJDD9yzvZzEHO4cs8S6Z0NiozPjKLrMQV1LUepr3ntA9H+P/ZO8/wuKpzbd9LXTNqliWNbFm2JVmSLeNeMQaM6b2aFkowNaETQgiBFMjJSf2ScEiDnCQn5YSUkwRCQglpQAgG29gGy5aLZFsuai5qY6vMrO/H1h7PjEaj6UV+7+vyJWtm9t5rb2k0z3r3s543fkRNLCulPq+U2qeU2jD074JoHSvRue5MOGMuOE4gwRxMxa9qwhJqypaz/2C9KwjdqVL5Lp8kBeew20LeRErkRiulIhnaWyeioDev0yYWcIxsUnCQjR0rXdSxgWIvT7p5jUe73sH8vhzpOUD97r8yPm8Kn5m4mXJ28z0epp65FNHCAt72FPA+fq6JdG3Nvz8fOQuKC2J+eEEY8xTkwCdWgUpJwjvKSvEcD9BDDh/nK6TrPtdT0yedhjVrHJuaXmZgsM/PTsYm0a4sf1NrPXfo35+jfKyERSm4/SJYWGtUdca6YA6lyjtt4lJqypaz72A9GxtfxqmdtKsJ/JSPUccmzud3Prez6f2UDIkmd1HeQ27QIjdaPtNkWDiYiILenLz0ksdRLDhJpZhWFvMWHW6e9Bzd6Xqtld5Rr3egk6K+ATvrd75IRrqFm6vKOJ8XeIVL+UAtdMtfziQbO7l0jfhzTaRra7a0Pm9xzA8tCCcMs6vggiXJeUe5R+XzAz5BObu5jv92PZ6ams7sivM51t9DffPf4jjC+CA2jBiRmgIPXgUzpoxtwRxOldcQzEOWjKFFf29wNu+xjGv4CVP19mHb9GLFyvHUDPP47ZRGZDFVuFVBc3v3arsdS0KlIkBiCnrz52d209vGSRyiiDw66cXiEsruHmZzG393NwKZFDm1kw2NL9E/YGfFtDO5J/UZ9jKZ51kNuOcvmxXlbSPeRUmUa+vUxt+h+640vgqCED0+chaUjU/OCNkP1EJe5jLO5UWP7n7jciZSNWEx+zo203p4RxxHGHui/SfzHqXUJqXUj5RS43y9QCl1h1JqrVJqbXv72O4Uk5ZqxMtMsRkLAMaiYA7XyjBt4hJqJ53GgUNb2bjTiJX7IQ/QSQH38GWytN3j9eb+57OGKr3FQ4hE4lZ3uFVBc3ubbqaIVrrIYyYbgcT7C5qISSDm7xNAEa1sYQ7NTGE2a4cJT/eJjSlmu8hjGvUBTdbct9+2900Odu1hwZRlPGb5b3Lp4rt8igGV6TEh7B6qeqfTTzmNIx4nEa6tUxsV5amlMT+0IJxwpKXCI0ncDvtXrKaZqdzJN8jVR1yPV09cRm52MR/seo2+AbufPYwtwhLLSqnXlVIf+vh3KfA9oAqYCxwAvuFrH1rrZ7XWC7XWC4uLi8MZTlKQlQGfvRls45JzxexoRMLKUDVhMdPLT+fA4QY2NL5El7byXT6FjQN8lO8Me32Pymcf5cxmHXasWOl1NSBx96kGWw02991ENXVs4CS9LuiqYI8yOrkt4S3sWLFgZw3LKYlC0ka4VfB4JoGMNHYT97sV61lGP1nDqrnuE5MKttOGDQt2tlEX0N0Nc/sjhzbQ2PIeVcUz+GTRu8zifX7JanarKsBTwJtV73Uso53SEY8T75SVgUHIzYZrV8b0sIJwQlNaCHdelJztsAdUBt/hEaz0cCf/z3UCKSmpzKm8gEFHHx/u/gs62U4sRMISy1rrs7TWJ/n494LWulVr7dBGvMFzgLjkhsjJhidvgQJrcq6YjfaCJZvez2xbDTPKV9ByeDvv73yJ3c4yXuMSTuWvLNeve4wjR3dioZdNLGAe71DDRpbwlqsBia9qsL9z8K4mA2RjJ4/OUauCvvZrwU4LZa7tW4fsKZG2YoRTBY93m2l/Y/e+WwFwFAtdFHgIT3NiU8sW7EMd9MzGIIFc7x6Vz8ajRaxt+jvF1kLuKh9gBa+yniW8wuWu15kTQvdxued9ex8n3tfWbGl99+XGZF0QhNhx2hxYPD05m5U0q0r+l9uYx7se64byLMVUly2j9fB29h/aGscRxo5opmFMcPv2cuDDaB0rGRmXC0+tBktW8gnmaC9YMvc/y1ZN3eSVtB7ZzsbGF/g/51XUM4tbeIYJuplerNSxwZVG0MpEuslnIvtooooSWkf0iPo7B2+PaR0bOIqFJqpHrQr62m8xLYD2qCpGo0FFON7YaCWBBIr32OfxjmuyY4rTHN1JhW5wVXM/VAuGCc8elc92Zgyb2ARyvQccfby582+kpKRxU9UkLk35Hd0U8AMe8pmxFuhdlEhd21AnqYNOWFAD86YFdThBECKA2fwnzwr9SfZZD/Aal/Aey7iWH1GpG1yPV5YuosA6kc27X+dYf7efPYwNoulZ/qpS6gOl1CbgDODBKB4rKbEVGhXmzPTkEszRXrDkvv+TS4o5e3I1O44c5J87/8Ez+iEGyOAevkwf2XRgGDBzh+LEDjOetSyjgMPYsY7oER3tHEyPaQXbyMZOPXMDqgr6EtpAwNtH4tqF4o1NhI5z7mPfT7mHVcWczCgY9nPqJXdoQuLuVc6nmi0BX2etNZsaX8F+7DCXV03n/Ix/MZ52/pt7wv69jtS1DWWS6nBCeircdmHw4xYEITJYs+CRa42FtUnX0VcpnuVBDjOee/kSFt0z9HAKcyrPx6kdfLDr1TFvx4iaWNZa36i1nqW1nq21vkRrfWI3Fh+ByTZ44mZjMUAyrZrtUflo1DDfaKh2DO+qWY/Kx46F6Wxicsl8Zk09h/bOXby27U2+67yfqezkOn5Io6qlmUoq2O4StTtVHduoYyYb6CJ/xGqwP2F5XHQVcBSLxzajVQU9ky9yhrXdjmbFNt7e2HBwH7sFO23Yhk1mGn10ZmyjlBy6vbzKvTQwI+CJyfb9/6L1yHbOKK9kSW4vC1jDH1mFg7SgrmE0LUrBTlLNz66bzzXuZAmCED+qJ8GqFcnZDtuucnmGT1NIB7fzLdcJWLPGMX3SabR37qK544M4jzK6SIBQAlAzyUjJUCp5Vs0aPuEejxSAcOwY3lUzm25mJhvZQwVFtDKjaApzKi7gYHczP9i2hz/pizmXFzlFv+6qJJqiNkd3UkIra1hOD/kjVnNHEpbuHtMP1QLqmTvsVr+/qqD7fhXD/ypGq2Ibb29sOPgaewmtfu8OmJgisoZ67FiC9irvP7iVHfvfobqoipNKqrmGH/Mhc/kNNwc9sYm2RSmYOwcDDigvhrMWROTQgiCEyWXLoWpichXGTHaoGfyKW1jMW5zFS67Hp5TMY3zuZLbs+Tv2viN+9pDciFhOEGZXwf1XGqtmE30hgCkAzBQAwKOTWSi3rd2rZlV6C0t4izUsZ6eqcz1eO76MeVUXcaT3AA825LBLT+EWvkMnBR6i1uzs1qrKXbfAvUWPP2EZjsc0noI13r7jYHGvwronTMzU7wPQho0ymmmhjHIaPfxy3vSofHZQRx5dQXmVO3tb2NT0CuNyypg+5VxuU8/QRxbf45NolRr0xCbaFqVA7xw4ncYt33uvMBb3CYIQf1JT4BNXQ2ZGcgrml7mC91nEDTzLFL0TAKUUsyvOQ6GGOvAmWdk8QOTPaAJx8ky4/QLjDkci+5q8UwDMTmZ2coaJgmBuS5tVs8k0sZm5tKpy1+Om6JtQWMv8aZdysPcQt+6YjtZwG0+Tpvtdr7OTO6pH1J+wDMdjGgnBGuqt/ETwHQeDexXWvQFJB0XUsYEpNLKeJXSTB0ARLSOKw1DsJ8f6e1i3/Q9kpGczf9olfFQ9Rzm7+BWrGSRt2P4DtVJEK1M5mImYE7hwqWHzEgQhcSjMMwpjKgnj5LRK4fs8TDf53MuXXH0PsjPzmDH5DA5172VX6/o4jzI6iFhOMM5aCNeeaTQQSNS+8u6irFI3UE4jTVSj0C47hiks/N2W9haFObqTchppH/KcenuYTUFlK6hiQfVlbOhS3L9nPlVs4waeHfa6QM/B1zFCJdj9+hLG4GAe7yREe+RoMlIVtlWV0+62cNO8i1HPXJ+TDm8R2UsudWwY9rvlLnYdzkHW73iBAUcfC6sv5+y0f7GSl3mRq1nH0rCsFNHyjQc6ERsYhDwLXH1GRA4rCEKEWVgLK+Ym/l1kX/SofJ7hUWwc4Fa+7VL8k4pOoiS/koa9b9Jz9GCcRxl5RCwnIJcvN6pCid5X3hAFRgpBN3mu5h11bHAJC3+3pd2FdI7udCVH7GLaqPaF4vwKFtVcwe8P5vHd9hrO5iVX/nKkieaiLV+TiRJaXY00EqX1dLQYqQrbNLRw0/3xkSYd3iKybUhouydkuItdrTUf7nqNI70HmFN5AbOzO7mF/3L5lMOxUkTThhPIRMyVqXyZkbIjCEJicsv5UJSfnHFyDeokfsNNLOOfnMsLgGHHmFVxLqkpaWxsehmnTsKZgB9ELCcoN54Dp88GRwILZiu9ropfBdvJpQuAdko9PtRHEkTuomQqRp95MzkiEPtCXW4aK2ou4Km903i7Zzyr9dPU6k1+RWwowjeai7b8VVfj3R45FphV2AHSPdpFm3cZBkgftTrrLSJ7VD71zCWHbp9it7HlPfYdrKe67BSqCkq5ny/STT7f4VGcKtW1j1Cuf7x94w6nUbWaK5nKgpDQZKYbcXJpKclZYf4jV7OWk7me55iujSSMzHQrJ009i87eFhoPvBvnEUYWEcsJilJw5yWwsMZ4IyWiYDZFiruwaKaSJlXr8Tp/t6XNbdMZoJnKYaLHVyXRFLy9WFmY08lptRdz1675HB5UfMz5nzgY3kDCJBThG4tc6Q5sTOcD7ENNUULNC04m3KuwuzDUXR0bsLnlUwdyl8EXI4ndA4e20bD3DSaMq6V6wmI+zlcp5CDf5nG6VIHH2HyJePO5kSZX8fSNOxyQniaZyoKQLEwphRvOMf6fiJ/x/jD9y22Uci9fokAb1osJhdOZMK6W7fvfpsveFudRRg4RywlMago8uApmTElcwQz+xfBot6VD8XeagheMBhXLLHu4dloVd++eR4E6wjWDT494sUIVvtFatAXHr8EeKpjJBip1vSsveCJ72MukYdcsXAtItFuWB4L3QtF65gJQwxYguLsM3vj6vTrcs5+NjX+mwDqR2ZXncQW/ZC7v8VM+xk413WNbXyI+3HjEaKI1oOCW86AgJ96jEQQhUM5fDNMnG502k42jysq3eIIsjnI/XyRVDwAwc8qZpKdmsbHxZZzOJIz98IGI5QQnLdXIYJ5aaryZEk0wjyaG/d2Wdt/WSaqrCYW3KPTVsKQNG/NZQy5dZGMnPyuX4snX8Z8ts1iW9j4rjj3rMUZ3ERiK8I3Woi33a7BTzWANy1nCm4DT5V22DjXocL9m4Yq1aOcBB4Iv+0QzlfSQF/BdBl/4+p0sOLaR9dt/R1ZGDgurL2O+ep/L+QVvcBZ/5QKP7UcS8VPZkbD+8UGH8TfijHnxHokgCMGQkgIPXAXZSRont09N5Qc8RA1buJEfAJCRbmHW1HPoPtrOjgP/ju8AI4SI5SQgKwM+ezNMKEy8N9NoHk1/t6Xdt+3FSgmtPkXhSIvg9lHuVmGuYWpGNweKbuPPnWWszvw9pZ0v+hSBwQrfaC7a8r5+raqcdzmVItrpwOZqrFFCKyk4IibWwrGWRKsqHakJifc1PeTI4H+3bwU0i2qupCyti4/zVZqp4MfcY3ie3BhJxBcPNUnx7vQYy2q8L5xO4wNXMpUFITkpyIEHVgEqcVOw/PGuOo2XuJKzeYlT9V8AsI2bRtn4OnbuX8OR3pY4jzB85E9rkmDNgi/cAuPyjGioRCEcj6b7tqZ48yUKfQm7NmyMp410+jiKxZXGMSW9i9etD9HYn8fjlmdJa/+9h3AKRfhGatGWL5HZixUrva7ncnQnFuxsZTblNFKhG6JmAQl1v9GoSkdyQuL+e+VwDrJu+x+w9/cyb9oVFGZm8wBPoYBv8Tj9KiugsbnbZGy62WPM8bZkaODyU6GsKK7DEAQhDOZNg7MXGJPfRLuDHAi/YjWbmcNq/osp2liwXzd5JZnpVjY1/hmHM4GESwiIWE4iCnLgi6shx5KccTOj4U+8uT9ntjTuoJR1LHOlcYDhYSZtHM+nfxKlUrgv50W27P23q6tQKMI3Uou2/InMXqyu2L0mql2NOIppwaabo2YBCWW/0VjwGI0UCa01m5pe5nDPPuZUXkBdjuYevsRkmvgOn6JNTRy1MuzbJvMWVUO+8mDPO9JV+f5B4+/C5aeGtLkgCAnETeeCbZzRqj7ZcKpUnuHTdJPHgzxJnj5CeloWsyrOpefYIbbv+1e8hxgWIpaTjOICeGo1WDLHnmAebaGg+dxEmmnDRqOqHbYAzLR0pKcofpFyL1VZR3ki92dsavwjDudgXNMK/IlMYzIwvBHHbiqpZUvELSDhVnIjXe2Oxs+lYe+bHDjUwPRJpzGhsJYz+RPzeZffcgMb1SIqdQPL+Dtw/JMpR3dSoRtc4tWXTWYzc5hMU0jnHcmqvJmpfN8VkJE2+usFQUhsMtLgk9caa5WSMU6uSxXwLZ4gnyM8yJOk636K8ysoL55NY8t7HO7eF+8hhoyI5SSkrAg+/1HISE8sS0Y4+BNv3s+9z1JKfETQtQ5VCs3Xvp1yNr/kVs7OP8idlpd4b9v/MTDYF8ez9C8yG3004oBU1rMk4rm97iLQFIbu+w2k4hqNanekaGpZR2PLu0wunkNF6SKW6b9xAb/nTVbSSDUTdDNFtHCMTKYMRcOZjXGKaXGJV28R726TCeW8I1mVdzjhlJOgbmrQmwqCkKCUl8BN5xj2qmS0YzSqWr7Hw9RQz218C7RmRvkKsjPy2Nj0Mg7HQLyHGBIilpOUignw+A2Qmpp4i/4Cxf2WtCnezMfdRWEwt+i9X/tKylX8jfO4t3QP52e+yztbf8nR/u6on4+Jt+gMtHpuPheLttzuUXzuE46Rqp3RXPAYCfZ2bGZL898pHVfNzClnUs1Wbueb1DOL53iQDkpdmeDrWQbAAt5mAW8DxyPrvInUeUeiKj/ogMwMIypOEISxxXmLoW5KcsbJgbHg7zfcxHL+xiX8irTUDGZXnIe97wgN+96M9/BCQsRyEjNjCjxynbGY35GEgtn9lrQp/txFmikKgxGMvl77Y+7lA+bxzSlbmZW2i7frfx6V1bmj3WIPpnoeSwEabLUzll3qgvX4th7ewQdNrzA+bzJzKi+kiA4e5EkOU8S3eYJs7B4TEoBmKknDQSqOYZF17oRy3r7Gb9PNTKM+5Kq81kNNiy6GXEtQmwqCkAQoBfdfmbxxcgB/4Dre4gyu4Scs1m8yPm8yU0rmsat1PQe7muM9vKARsZzkzJtmvKm0Sj6PU7Q745k4VSpP8xgdqpSf19RTntHHO1uf58ChbRE9zmjn409sxbtNcjDVzlj6voPx+B7saub9nX8kz2pjwbTLsKgBPsHnyaCPb/B5QA+bkNSxgWo+ZJBUHKQO69bnTijn7T1+m25mCW+xjbqQJ0WDDmOivGxmwJsIgpBkFOQY+cuQnHYMlOKHPMg2ZnAXX6dCb6N20qlYMgvYtOsVBh398R5hUIhYHgOcPBNuv8B4QzmTUDBHqzOeO3aVyzf4PBnKwe+mf0i5NZ/3d77Ijv3voLUOKaXA1zYAGuXzfPyJrXguPITwPMjR7AYY6ISqs7eVddt/jyUzn0U1V5KeksrH+Brl7OK/eIx9asqwCQlAFnYyOcY6lrFuyJJhduuLxLl5j7+WLaxhOa2q3OP5QCdFDqex+Ofjlw6LhxYEYYwxrxrOXJDYHXz9MaAy+Cafo4t8HuILFKd0MbviPI72dbJ17xvxHl5QiFgeI5y1EK4/0wg0j0eoeTCiwv21pkjrIp9qtvgUaZESYwdUOd/ks5SqVp6v+YCK8dVs2/cW9U0v0OXM8rBEVOqGUVMKfFU969iAhZ6EXfjmi3AtINHuBjjahKrn2CHe2/Zb0tIyWVS7iozULG7i+yzibX7OHWxSC4HhkxUrveylkn+z0qNbXzulLvEaiXNzH/92ZriEsvvzgUyKzA/Lj5xtpOIIgjD2+ei5UJSfnHFyYCRkfJ0nyeYon+BzTMwpZKptAXvaNtDRtTvewwsYEctjiEuXwyWnGGI51rPQYESF+VqbW4MRC700MMOnSIukGNui5vA9PkmN2sL3KzYye+I8dh/cwT8a/sSWgUnUsYEFvE0RLaNaQryrhnVsAIwFYom48G0kwrWARNtO46/qfbSvi/cafgvA4tpVZGfkcinPcw5/5CWu5FV12Yj7bVUTXfGDHueial3iNRLnFqnkkAEHlBUbi38EQTgxyEg31ialpSSf1dJkr5rKf/FpJtPEAzxF3aQlWLPGsanpFQYc8U2oChQRy2OM68+Es+aDI8aCORhRYb62hnpXg5Emql2tnb1FWqTF2Bp1Gj/nThbzNo9P3MLJlSvptLfz1y2/42DvQQbI9LvQy3tsx5ul5HgkKcTadxwqoVpA3Cv+5nWoYBsaFVGhPFLV+2hfF+80/IoBRx+Laq4iJ6uQ0/UrXM3/8BZn8Dy3RmQM4ViFIrVw0+mE1BS4/wrjqyAIJw5TbHD9WckbJwewUS3iOR5kFu9zj/o2cyrO5Vh/D1ub/xnvoQWE/NkdYygFt14AS+ti73MKRlT0qHx2UEceXR6vHUmkRdrb/Kq6jJe4irN5iZsLt3Hh9DNJY4DvbW3itY60gCuA7lVDxfCLHUvfsS+i6Sd2r/jn6E7KaSSdfiz0RKyaPlLVW/e3sabhVwwMHmNxzVXkW23M0+9wG0+zifk8y0NoFZk/b+FUhiO1cNMJXHwyTLYFtZkgCGOEC5dCzaTkTccAeFOdzf9yKyfzT+6zvkhl6QKa2zdxsKsp3kMbFRHLY5CUFLjvcphTFVvBHIyoCFaARKMJxvOsdkXbXG99g/tmVDIpJ4c3dr3L/+1pZ7KzYdRzSOS8YYiun9gUfqZ1BfBoPx6J6+Cr6t3er/hTwz/oHzzK4pqrKMiZwDRdz738J01U8S2ewKHS/e430ElEuD/jSCzcHBhqab1qRcCbCIIwxkhJgQdXGfnqySyY/6RW8RJXci4v8kjZXnKyCtm691Xsx47Fe2h+EbE8RklNhYevhZry2AjmYERFsAIkkNeHUkHVKoX/5TZ2UcmZvExaei4La65mkW0SO9o285Nt20gZ6Bhx+3jHvQVCtP3EPSofOzke1pVoXoej/d2safj1kFBeRUHOBCbqPTzM5zjMeL7OU/Sp7FH3E+gkIt4/Y61BDdkvMvzrf0EQxjiFuXDv5YBKXjsGwPPcyhucxTXq5zxSnY3DOUhze3u8h+UXEctjmIw0+MwNht9pMMqCOZwue6MJkEBeH2oFNYs+vskT7KGCu/h/TFW7qSg/n9MqlnHI3sEf6v/CkZ4DwV+QBCKa8Xw5uhOFpolqj4p/NOwnR/u7WbP1V/QP2l1Cebxu41N8BgdpfJn/oEsFFhMR6CQi3pF+g044dZa0tBYEwWDxDKPNfbIu9gOjUPVDHuB9FnN35s94aOZJ1JaXj75hHBGxPMbJyoDP3QylhdG9dRNulz1/AiSQ14dSQbXp/fRipUNN4Mt8iVYm8jCfYxbrySlaxrIZ16NUCv/e+kt2HngX7TXbCESgR8ozHM5+grWwxMqiEAxH+7oMoTxgZ9GQ9aJWf8gTPEw2dr7KU7SrCUFnIMci4ztUBhxgzYJbzo/3SARBSCRuv9CwZvUPxnskoeNQaTzNY+xgOg+nf4PCzs3xHpJfRCyfAFiz4clboDDP8D8mC8EKxGDFj7vY7VH5fJtP000et/EtqnU9eZYSls+8CVvBNBr2vsG7237Lsf4ej+ONJtAj5RkOdj/mtXMXtN3k0UPuqILW37HcfyZmxd88XjAWhWB+tj1HD/LvLb+kf9DOotqrGJczkULdzl18jVw6+TaPsVtN83tNRmo7Xc2WhMzE1hpSlHHL1ZoV79EIgpBIZGfCw9cYyTjJ1ojMnX6Vxdf5Am/qFXRbJsd7OH4RsXyCUJADX7wV8qzJI5iDFYjBVlC9xW4R7XyFpzhMEY/wOJW6gfS0LOZVXcysqedwuGcfb23+H9qO7PTYh9+GGSFWvH2N3RS6gezHvHYlQ3nRABVsp53SUQWtvzG7/0zMyr77zyRQi4KFbo9OeccbunR7vO5wz37+veWXOLWDpdOvZVzORAr0QR7jUXLp5ps8QQp6xGtiXkvv5I6Zeh1LeIsGZiTk4sxBJyyqhfk18R6JIAiJSPUkuPzU+PRViCS9KpfvOD7BQHpuvIfiFxHLJxBF+fDUarBkxUcwh1IpDlRohmoJ8Ba7+9VUvsSX6SafR/kMU/V2lFKUF89med2NZKbnsHb776nf8zcczsGABHo4FW/3c2unNA4MOt8AACAASURBVKhoPkMUd5NLl8e1C0TQjjTmSC0YbKcUMFpLuzd0MR8HaO9s4t2GX5OelsWyGdeTZymhQB/kMzxCAYf4Cl/kQ7XQ7zUxryXgkdwxkT1htZ2OJoMOyEqH2y+K90gEQUhkrjrNiJNM5nSMZEHE8gnGhPGGJSMzI/aCORRLQqBCM9TUAl9i95Aq5kt8GTsWHuUxynWj8drs8Syr+whTS+azq3U979T/lKzedaMK9EAEtXeDD1PYnaTXuQQpEHTlPJxmGiMdKxJeX7O1dDZ2ZrCRbOweDV32Haxn7fbfY80q5OQZ12HJKiBfH+IxHqWQg3yVL7Jd1Y16bd3FfS5dZGNngAw+ZGHIbaejidZGVvpdlxh3gQRBEEYiNRUevhrS0pJ7wV8yIGL5BGSyDT57E6SnxbbffChVyUCtFf4WAY5U0a7UDSNWozuUjf/gK/STyWf4FFV6KwCpKWnUTVnJwuorGBg8ys+2vM97ze/jcAz4FOiBVry9JxIA2djJo5MOjE4U/vYTSU/uaGOOdOa18vq+qWUdGxv/zLicMpbUXkNmupV8fYjP8CjjaeerfJFtambA1/Z4d0GzwlyTcB5lk0EHnFQBJ8+M90gEQUgGbIXGgj9IbjtGoiNi+QSlehJ8+iPGAoFY3sIJpioZrLViJFFsodtnRVuD32p0u5rAU3yNXnJ4jEeZpde59ltSUMkpJ93GpOLZNLWu5c3NP6Gja/ew6mSgFW/viUQdGziKxRXJZnqPR9qPt9i26eaQPbn+xhypBAzTo3wUC/XM4SgWavX7bN/9Clua/45tXDWLaq4kPS0Tm97P5/gE42nlazxJgzopqGt7vLtgH0ex0E1ewnmUARwOSE+Hj19mVJcFQRACYcVcmF1lrHUQooPyjsOKJwsXLtRr166N9zBOKNZvg68+D2jjlk60McVWBzaKaPVbWTaj3dyfz9GdWOn1ebvcXcj1qHyP74GAjuvrmBP1bh7gi9g4wHd5hDXqNI9tDnY188Gu17D3HWZS0UlMLz+djLTRG2P4wqi4byOdftaxbNh5BDK56MDGNOrZRp2H1cDftQuUkX4mU2hk91BTkkCOV6kbKKLFZb1I629hU+ML7OruZmrJfGZMXoFSKUzV23mEJ0jBydd4kp1qelDjPW71yaVtyA/t/jsR7vWIFFobC3XuuAhWzo/3aARBSDa67XDv02Dvg/QYfJZHkmP9cMPZxoLFWKOUWqe1Xjja66SyfIIzvwbuuwK0ir7nKdiqZLB5zP5sHoFWtH35qsfTztf4AjuYzj38J2fqlzy2GZ9Xzqkn3URl6WL2dWzmjQ9+THP7JrQO7oKa9oYuCjiKZdh5jea/dj/HHV5C2Xw+EGHobyHmSD+T3VQG5Ec/nk6R6xLK/T07+OuW37Gnx86pU5dyxuTp5NLNTP0+j/MIA2TwNb5AD3lBj9esPjeq2mHdBRPBo2wy4IBpZXDGvHiPRBCEZCTXAg9cZdyVSqAa6JhBxLLAspOMipbW0c1sjEXr4JFEsT+frffiul5ymc/bHovrjmLlx9zDBhazmme4TP+vx1+k1JR0ppefxrK6G7BmFfDBrtd4a/PPONi1J6Bxu08kPlQLqGeuh/gMRNiZ5zhAOuU0epxjMM06Ql2I6WuiYlo33PdtRsT1qHw62t/j71tfQKM4ecZ15BYvpxcr5/M7HuFxOrDxNb6Ahd4Rj+9vvPHuwBcIDofRbfP+K8V+IQhC6MydBmfOl8V+0UDEsgAYb7AbzzFuBUdLMMdCuPgSxaNVtL3FVi8WytlNMQc8FtcdYRzf4gne5ExW8VNu4nukaE/Dd77VxtLp1zG38iIGHMdY0/Br1m3/A73HDvsdd7gTCfdz3MU0AFeOcTCNUExB7e2f7iV31NQLXxMVXwsXAQqd+9m1+wXe3fVPCnNKObnuZvKthk3iZP7JJfyaA0ziWR5gHAf9WlACXTgaqW6KkURrQBld+ooD69QtCIIwIjefC+OTrAFZMiCeZcGDX/0dfvcGpKQYHcSSiZE8y6Zf1Z+f1t3vW04jWdhdKQ3GIrTjsWZKO7meH3IBv2MT8/kvPk0u3cO8vFmOg+xqWcfGli04tYOpJfOpmrgkZD+zP7y9xOYCOjs5KHTAWcju19DMZ06nz+WfDmRb0xfu7RM2r+1Wu4XXd31Ah/0QM201lJdfRIpKIUU7uJYfcSH/xzqW8htupIh2WijjgJelxBcTdDOl7Bvx9f487fFqdd0/CHVT4PMflaqyIAiRoekAfPo5I2koJQlKosngWU6LxWCE5OHqFWA/Bq+8CyoluT7AfVZn9XF/qjs9Kp8e8j2+79A2j8V1hljcRjZ2j221SuEX3ME+Xc4tPMN/cA/f5ZOUsJ8mbSwcK6EFa0o3aROXUFC8jG373qKpdS172jcy1TafitKFERXN3tX5HpVPs650icdAxaB5zerY4Dpv0z/tb8GlWUE2r3+3zqOODa5FfB3YmORs4I0De/l7y0GyUtM4o/JkFhdm0kQ3aMW9fImT2MBrXMzvuY4pNLruEHTrvKAiBrO1fdgECaB3qAtihx59gWm0Me0X94n9QhCECFIxAVatgN/843h2uxAeUlkWhqE1fO8F+OcmSFUnxhvteJycwkIPveRgpYdmKimnkXZKaad0WHrCbP0ud/NV0hjkR9zDAOlkYyeDPjaxwGORncPeRMP+99h1eA9pKRlMsc2nonRB2KLZl4i16WZq2cJ2ZgQtCnN0Jwt4mwEyaKKGbvKoYDtt2Chx25d7ZdYUzOYxDGuDAwt2immhpbud3+3eR9uxAeaMH8/USRcwkGEjR3eyhDe4hF+TzxF+zD2sY2lQFWBfFWOzI6B5R8C7Yu6vAh0LzPSLuy4xYp8EQRAiicMJjz1nVJnTE7wsmgyV5SQo0AuxRim48xJYMt14wyXQfCoqeC+u200lM9hEFna6yaOeuRTTMuTd9fT9blKLeYqvcpjxfJyvcwp/Z4AMGqmlxG0hYY7uZG72QRZXncupM2+mKH8qOw+8wz82Psu2vW/RN2B3vS5YD20kM5YBimkZyng2mncAQ1FrqSN6g7396L1YKaGVI450Xt29g+837GLACauqZ3N5RSWZ6VkAzGY9N/AcaQzyJF/nn+rcoP3bvl5fz1zaKR02VgiuC2K0GHRA3VQ4fU5cDi8IwhgnNQUeku5+EUMqy8KIDDrgq7+EjTuNN95YrTB7V2bNqqgVO1a6XV7bDkppVLU+91Gud/JRvsN06tnEfP7K+TQzlRJaR8x2HuxtYveBN2g43E6KSmXK+CpWlOTRa5nnMZZAsqYjlbEciK93NG8wwMBgHwfa/k1T63rsg05OKSnk1LKp7ExdAEAuXazkz1zA79nCLJ7mMbrUOL9jCwX3sZoV8nh7lgcdRqXn6fugMDdmhxUE4QTkb+vh2ZeMNUiJ+hmeDJXlBC/OC/EkLRU+eS188WewdU9yC+bRRKdN7wftmc6RozuZSg+l7KOZyhGFYY7uZAJ7eYOzaGMCp/APJrGbtzmDD5nt4Rt2P2aatYI5VYUsP7qBf7UdYufBHfy4w0lhbgtTbQuwFVQd9wJr341WTEzPta+MZfPcvcW1L/Hs1/dN/jBvsLeXuG/Azq7Wdexue59BRz+1eTmcUTaRAes8dg6J1W5yuYkfUEs9r3IJv+AOHCryf4q8x5qF3e+5xQLTP3jnxSKUBUGIPmfMg39vhk2Nxme6EBoilgW/pKcZbbE//xNo3G+82SIhmIPtzhcuo4lOX8+bvtdmKkdcZGbux/Q0r+MUGqnmPF7kIn5LHe/zc+6giFacGpfn1/38c7MruXJKJm1lVbzf0c7mtp2s3/EC2Rl5TCo6ia5xZczJ9r8ozZ+IDVRww/CFgnB8MaR3JbZb57n22z6QQlPLWprbN+JwDlI6robTSm3UWY8dv37kUk4TV/EzBknnOzzC22plRH6+JuZ1Bc9OfVnYyaGb9qF0Du9zixWDTphdCctnxeyQgiCcwCgF91wB9z1tVHBFMIeG2DCEgOg9Bk/8N+ztgLQIVJjjEeM1Wqtt7/g48L1AzHMhnW/RX8YeLuS3LGAN7ZTwG25iPO2sYTmtqty1P3PRnB0rM9nAGpZzgDLaDu9gd9v7HOxuBmBcdj6zxxVQXDgTe3adx/HB4bHwzlzct54lHlFygbYZHwnvc+0b6OXwoU3sP7Sdlp42FIqq8VOZVrqAvOxxHmK1iq1cxc+oZAebmM9zPMghVRzU8QMhGu2tIzWxG3RAZgY8fS8U5AQ1BEEQhLBYvw2+8nxiLtpPBhuGiGUhYLrt8NgPofVwZHrPR0LABctoflvz+QHS2cU0nwIJGCaeKnQDClyeZlPETqeea/gROXTzVy7gNS51HddciLeZOViwD0ubADjW382hQ5toP7yZfT1dABRZ8ijJn0Z5bgHF1nHMTN3GPsrppQBwUDPkWYZUDzEXiNd4NPoGemk5vJ0Dhxo4NCTkc7LGU1pYw6SikyjJwEusai7it5zJn0nFwYtczR+4Pqp/rSP9exWJiZ3WxiKbR66FBb5t74IgCFHlu38wUq7SEizaIRnEstgwhIDJtcBTq+HRZ+FQV/hxNO4+22CygENlNL+t9/O+xuthR3CzNRTTAkCbLvXoXLeVOn7M3azkFc7hJWaygf/Rd7NZzQNS2cwc8uiihTJaVTm9Os/DQ1uU7mSRLZMm2zW0D6Rw6OBGDh7+gC0H1lN/AFKUotiSz5zcJvJyprDEepDNaafRluIphkc7d18MOvrp7G2ls7eFzt4WjthbONo3lO6RVci0iSczobCW3Oyi49cIaNJGYkYF3VzJz6lmKw3U8X0epi0GbaYj/XtlepvDyWd2OOHU2SKUBUGIH6svMBbsH+o2Mt6FwJHKshA0B7vg0R9AZ294gjmWleXRqoO+vp/PGhqY4TNVwhTD7mMHPB7zqBSTx3Je5zp+RAGHeY9l/IFryB1K2xjp/EeyABQ4mjncs4/GbjuHu5vZZR/AOfReTkvJwJJVgCUzH0tmAeMyM6lI76RNlXFM5WLBzkS1jxbKsSsrfQO99A30cqy/x/X/o/1d9B475DpmdkYe+dZSCqylFBdUeghkb6y6mxv4AafwNwZI5/+4iZe5DK1iY5aL1u9VqJX5/kEYlwPfvheyM8MehiAIQshs2wuf/VFidfdLhsqyiGUhJFoPwaPPQc/R0Gao0fQs+xKYlboBDTS5Rb95p2H4auxRQz3vs9TnGH2JJ/fHnKQO22eBbud8/sBZvEQag/yFi/gtN5PGQNDnbx4rnT6KHHt4q9dG+1E7u/sy6eyzY+/r5GhfJ07tCGh/SqWQmWYlM8NKVnoOeZYS8q2lVFvAkT5+VM9uqh7kLF7iSn5GNnbWcCrvsYzNzIv6XQP3cUXj9ypUAe50gga+cAvUxqf/iSAIgge/eB3++C9DLCeCfzkZxLIU4oWQsBUalozP/BCO9gVfYR4toiwcfKU/WOn2GbdmHsvXQi3TFuHr9rsvWwN4NrzwJaiOqGJ+ye2s1cs4hxc5nxdYyhu8xNW8x8kBn795/EFSWcR7vJ16OlPyFNl5M1jodmytna6KsdZONNr4qjUaJ6DITLeSmW4lIy0b5eMvp8OH7WQe7wz5okFpJwt4m+v4b0o5QBNV/JS72KZmDbOshEog0X+9WD1+r8znzYYmof5e+UsB8XdOWoMTuORkEcqCICQO15wB722FfR1ixwgUqSwLYbG7BR7/EfT1J1ZLzUjeiveuIAfbXtnfcSt1A9fzQ2bwAb3k8Fcu4FUu5YgaP+q5tWGjli3sZRJWtwWCbdjwXtwXLt7Xsw0bZeyhjGZW8Bql7KeDYv7M5fyLlfSoAo9tw40EDMVGE807FYGcU/8gTCyCb3xM4poEQUgs9rbDJ79vTOpT42zHSIbKsohlIWx27IPP/RgGBhNLMI/kMQ1G/PgS3aZneaQ0DPesX3Ofo4mrKr2Vi/gtC/kXDtL4F2fwZ65kn5oyYofBIjrYTaVHFdWsrkYjq9q8nn1kMYf3WMnLWLCziyo2sJBXuZQuVTji9uFGsAUT/RerdJWRcDiN25tfuwsmRT4hTxAEIWz++LZhyYh3d79kEMsJJG2EZGVaGTx+Izz1UyNLNhGqaJFo0jHi7XcfIszdC+3aP9UuoWx+P5Jg7CGPb6vHKdH7OZ/fczqvsYLX2KpnsoFFHKSYTXqhR9KGt43FtBlEo8lGkT7Acl6nku2cxPtoFO8OeZL7yaSFMr9C2eO6BNAcxRejpVzEOl1lJLQ2/t14jghlQRASlwuXwjv1xqI/sWP4J6zKslJqFfB5YAawWGu91u25TwO3Ag7gPq31q6PtTyrLyc0HjfClXxiLmuIpmAO5JR9IFTKcSuhI+w/ULpCjO1nJy5zMP5jMLgD2Mpl1LGUfk9nIopDFYKDnlacPs4B/s4Q3mMEHpOGgk3ze4XR2UsMOaimhNahKbjjV32SpLA84YOYUeOKmxFltLgiC4Iv2I/DAM/EtdCVDZTlcsTwDYw3LD4CHTbGslKoDfgksBiYCrwM1Wvtfli9iOflZvw2++rxRWYvXGy9QMRiJJh3+GGn/wQr1CbqZRfyL0/gLE9gHGMK5kRqaqKaJanZTSb/KCmhcvgR7FVvoI5sSWplMI9PYShUNpKA5SBHrWcK/OYNtzECr1GFdAoPxCIdy3ePpWQ6GgUHIzoJv3yNd+gRBSA7e2AjffSF+doxkEMthFd611luGDub91KXA81rrPqBJKbUDQzj/O5zjCYnP/Bp4cBV88zeGbzMeCwd8VX3dbQoQWpOOYPC3/0DsAu6WhQOqnDX6FEBzgDLmsJbxdDCLdZzG6wA4SWGfnsw+yukhjx5yh/7l0UMe/aSTzVEs9JKNnXwOcQavkKYHKWcX42knFWMu20cme6jgd9zAWk6mmQoff0FTPdppB5pmEup1Hy09JZx0lUi1s3ZqUCnwiVUilAVBSB5OnQ1vb4b12yPTnXcsEi2XShnwjtv3e4ceE04AlsyAuy+DZ/4QP8Hsj1CjwCK1/0AEo3vXOLu2MJONrGE5raqcLXrO0P6nkc7gULe87VSynck0kUM3OXSTgtPvOPvJ4BhZ7Gcy73Aau6liN5W0MHHUBiKBTEiCvS6BHs9d3JrHMxc2uh9/tPGYhOulhqGYOCectxhmVwW8mSAIQtxRyvjMvudpONaXGOuOEo1RxbJS6nWg1MdTn9FavxDuAJRSdwB3AEyePDnc3QkJwqmzjVvSP/hjfAWzr6phCS1G1TUKGc/gvwqKJmDBaFagp7OJzcxxdRJ031+rmshhiljPyR7bKu0kGzs5dJFDNxn0k00vhxjPQWykMMAUmrBjpYxmjypxtAg3W9v8WbqLW4BiWsjxkaMdKJFoZz3oMGLibjg7pCEIgiDElVwL3H8FfGXIRpkIzUoSiVHFstb6rBD2uw9wNyNOGnrM1/6fBZ4Fw7McwrGEBGXlfCNr9scvG1W3eCx2CqVBSbj4q7ra9P6ABaNZgd7KbIpoNVIzfKRf+EKrFOzkYCeHNrf9VbCdY2S58phLaKWBGRGtrI9EKNVod9xTQJqopo4NZGPnKBZXvnWohJOk4XBAWho8cl1iRScKgiAEw/waOHUWvLlJqsveREu+vAhcq5TKVEpVANXAu1E6lpDAnLcYbjrXWAXq9O8KiAo9Kp8mjKrhBN0cl0Vf7rSqiT4ryCPlOzdheJbNc8jRnX73b9P7h70mR3di0/td16KGeuxYKBmqoLYO7d9Kb8Dn4e840cL9Z5lLF9nYGSCD5qGs6XDwtsaMdp1NtAYU3H4hTBy5j4wgCEJSsPoCyLMad4aF44QllpVSlyul9gInA39SSr0KoLXeDPwaqAdeAe4eLQlDGLtcuBSuX2ksgIqXYO7AqBp2YIubUA4Gn5aFAAStWX01xZ4pus0mKT0qnx3UkUeXx7XwJdi9cRfI5nFsutn1uPtxooX5s6xgOwBN1AQlbn0R6sQEYNAJC2pgxdyQDy8IgpAwWDLhoVXGnWCn3Ot3EZZY1lr/Xms9SWudqbW2aa3PdXvuP7TWVVrrWq31y+EPVUhmLl0OV6+IT4U51KphPAm0Au3NaJX0cK6FuxDvUfm0YWMJb5FD7GLacnQn5TSSTh9HsdBNXlDi1hehTkwGBqHACh+/TPx9giCMHWZMgfOXGJ/VCdTkOa4kWE6BMJa58nS4fPlQhTlGb8BwqobJykiV9HCvhbcQL6GVzcwlj86YVOyP51OXso5l1DPXrcIcnI3EnVAmJo4hD/6nPwLWwOKtBUEQkobrzoTiAqPJkiBiWYgx15wBF50cO8EcatXQJBBvbjz8u/4YqXocyrXwPrcelY8dK9P5ADsWLPTGrGJvjr9R1RoLA93GH0jVPVJoDRr46HlQMSEmhxQEQYgpGWnw8DVGklU87JOJhohlIaYoZcRrnb84NoI5VDuDyWge4EBfEyv8VY9DuRbe52bTzcxkAx0UM5ONtGELq2IfzEQj3J9lpBh0wsIaOHeRjycP7Qe71zWwdxqPC4IgJBFTS2HVCqM4cKLbMUQsCzFHKbj5XENsJLonKpA0jURK3PCuHlvppQ2bR/U4mKq3+7lV6XqW8BZrWE4bZaxhOSVukXahWCESaaIRCAODMC4H7r58BJ9ylhUObD8umO2dxvdZiXk+giAI/rjsFCgvMbLkT2RELAtxQSm45Tw4Z5Hh/0x0wTxamkaiJG54V197sVJCq0t8hiJGzXObTJOrOUqrmjgscs5flXekCrIp7hNhojEaDiekpsJjHzFWjPvEkg8Tqg2B3NFsfJ1QbTwuCIKQZKSmGukYqanG38ATFRHLQtxQClafD2cvBIdOXMEcSIJEoiZuhFP1NgWue3OU8bRTqRs89h+IDcJfBTlRJhr+MH83V58PU3z1M3XHkg/5Nji0z/gqQlkQhCRmwnjjbjAk7ud0tBGxLMQVpeDWC+Cs+YlZYQ4kQSLREzdCFaO9WKljA3VsoIlquskDoIiWoM/N6NSXSx0bPEQ7QIVuSMiJhjsOJyyaDmctCODF9k7obIXCMuOrt4dZEAQhyThnIVRPOnHtGCKWhbijFNx2IZw5P/EqzIEkSISbuOFONJI1zMrwAOmU0zhM6I+07x6VTztGGTWXLirYTj1zqWduSOfWTinZ2KlgGx3YAKhjA8W0JOxEAwyf8vh8+PilAeQpmx7lCdVQVH7ckiGCWRCEJCYlBR64CtLTTkzBLGJZSAiUgtsvgjPnJVaFOZAEhkimNER6wZt71XsX0wBDoJr2ipH2bYr2JlVLM5WUsg87lrBj2o5iIZ1+aviQOjbQQSn1zI3IRCMaDDogPR0evwGyR/Ipu3Os19OjbHqYjyXG+QiCIITK+Dy442Lj8zpRPqNjhYhlIWEwBfPZCxJLMMeSSCdruFe9e1Q+9Rh9maeyw+++3dtZF9FKF3nMZCMQWknBFOb1zGUbJzFAJtnYaaM0IeLgfOHUgIIHroSJRQFuVDhxuEfZkm88LgiCkOScNhtmV514i/1ELAsJhVJw64VGrJwjhp3+EolILnjzrnr3qHyaqSSdATTDPQWmLcO9nbUdKxbsHlFxwWKKdoAiWmmimqNYKKEl5HOLJnrod+/ikw2vsiAIgmB8Rt99GWRlnFh2DBHLQsKhFNxyfnQalyRatz1fRDNZw33fFnpclgzzOU9bRqpHO2vvqLhgMCvF7gshDe9zd0L5k00GnVA7yWj5KgiCIBwn3wr3XH5i2TFELAsJidm45MIlRuOSUASzL2EMDuazJuZNMHyNpUI3eMSwGa9rZh7vRGXBm3dqh2nJ8E6oMCvRvViHtbMOxyIRyYWQ0WRgEPIs8MlrjVavgiAIgieLpsPSOqOwcCIgHwVCwqIU3HgOXHLKkGAO8k3pa7FcCa00MCPmTTB8jaWYFo8YthzdSS1b2EZdVASlL7Faz1zs5AyzfEQjDs+0hLhPHEzxnSjVfbPxyGdugFxLvEcjCIKQuNx+EeRkGwWGsY6IZSGhUQquPxMuOxWcBCeYR1os16rKY94Ew9dYzBg298fWs4RWVT5s21Y1MWwLia/UDgCFHmb5iGYVOFFbXOuh2MI7L4aKCXEdiiAIQsJjzTLi5FTK2LdjiFgWEh6l4LqVcPWKIQ9zkILZWxjHq9uer7EEs5gvmrFy3tXjSMbheRPpxI9IoLVRVT5rAayYG7dhCIIgJBWzK+GMucaC/LGMiGUhabjyNLjhbEMwBxpb4y2MbW7iLNZNMHyJ9GCEezRj5dz3HwsPcaK1uHY4oabcWFgqCIIgBM5Hz4N8y9i2Y4hYFpKKi5fB6guOVwL94atyWkM9bW7iLFCBaFog3K0Q7t+PZoXwNRb3VtKBCvdoxsqZ+/dVPY50iki8qvu+6B+Eghz41HWQlhq3YQiCICQlWRnw0NVGl7+xGvcqYllIOs5dBHdeAhpw+Ml59FU5fZ+lgKciCsReYFogwOFq1uH+/WhWCF9jaaeUDremHIEI93iJzEhaQLwnDj3kekTYma+JxYK/QQdkpMNnbzYWqgiCIAjBM30ynDcU9zoW/csiloWkZOU8uPdyQI0cjB5J360pZEtoxY51qFmHhZKhBhujVXh9jaVJ1dKoagNOh4hGQkWgRNIC4j1xaKcUwNWgJFYL/pxOww//8DVQFmiHPkEQBMEn158FRXljs1mJiGUhaVk+Cx5aZQieWLw5TQtEHp3sYhp5dEXEbxto1dZdZJpC2r0SHe1qbKQsIL66CpoNSmK14E9rI13lujNh3jS3Jw7tB7vX5MPeaTwuCIIgjEhGGnzCtGOMsfxlEctCUrN4Bjz2EePNGe3FBaYFoot8prKDLvIiYoUItGrrLjKP20JwVaJDqcYG40WOpgUklgv+TL/7splwyTKvJ7OscGD7ccFs7zS+z4pvrJ0gCEIyUDkRLlt+PIpzrCBiWUh6ZlfB5z9qeE/7oySYTTHahg0LfGK9bgAAEjtJREFUvaxhORbstGGLiBUiWLEYKVtEoFXtaFtAYunFHnTCFBt87FLjroQHlnyYUG0I5I5m4+uEauNxQRAEYVSuOh1s42FgDNkxRCwLY4LacnhqNVgyoyOYTQsEpLoam7h/H27cWihiMRLV2EBFdyAxc6EmZsTSi90/CONy4PEbjVuGPrHkQ74NDu0zvopQFgRBCJi0VPjEKkgdQ3YMEcvCmKFiAnzpdsiNQvtN0wLhboVw/z6cZh2hisVIVWMDEd2BLJYMNTEjVnnPA4OQnQFfuAXy/A3J3gmdrVBYZnz19jALgiAIfplsg1UrjLUhY8GOIWJZGFOUFcFX7oRxuYY4isebNNgKayhiMZLV2EiK7lCsIdHsFmjicEBqKnzmRigt9PNC06M8oRqKyo9bMkQwC4IgBMVlp0B58diwY4hYFpKLANIKigsMwTyxyPCnxlowB1thHUksmtu6Y4ruSFVjI22BSLTOfGDcBtQK7rvCsOv45Vivp0fZ9DAfi35XQ0EQhLFEaio8uMqwZQTadTdREbEsJBcBphUU5BiWjOmTjTdpLAVzLBbfRaoaG2kLRCJ15oOhiDgN16+Ek2cGsEHhxOEeZUu+8bggCIIQFGVFcP2ZRhOxZLZjiFgWkosg0gosmfDZm2DpTHDo2LbhjOXiu3CIpAUink1TfGFGxK2YC5ecEpchCIIgnPBcsBQqSpO7WYmIZSH5CCKtIC0VHrgSLlpq3I6P1a2gWC6+SxRitVAvEEyhPLMC7rjIR0ScIAiCEBNSU+DBq5LbjiFiWUg+gkwrUApuPAduOd+4FRTt2W0iLr6LBaF4r6OB1oZXfWopfOo6wzcnCIIgxA9bIdx0rvH/ZLRjiFgWkosw0grOW2y04kyNcre/RF18Fy9CjZQLlUGnkXjx2ZsgMz0qhxAEQRCC5JyFMK0sOdMxRCwLyUWYaQWLp8OTq8GaDYWO0JpojEaiLr4LhVAbjbgTC++1ycBQ05EvfNT4GQuCIAiJQUoK3H8lpKclnx1DxLKQXEQgrWBaGXz9Y5A7zsoUZ+wqnsHiLbpNgeouuqNpZ4DIVYVj4b0eGDQE8pOrjZxtQRAEIbEoLoDV5xv/TyY7hohl4YRkfB589q58sqdWM0VvxxblimckiLWdAUavCgdaeY6293pgEDIzjIqybVxEdy0IgiBEkDPnQ015cqVjiFgWTliyMuD+G/Opm23DpvfRqhM7bSKWdgbv445UFQ5EwEfbez3ogLQ0w6M82RaRXQqCIAhRQik3O0aSCGYRy8IJTcqxTi6b1crpK8soppWswcRePBePKDl/VeFABHyg3utQ/NGDDsMH9+j1UD0pEmcrCIIgRJvxeXD7RYAyUqoSHRHLwomLW7LG0uXlXH19NXWZ28lydCasl8pduE6jHptuHvZ8JD3MgVSFRxPwgS54DNZmYgrlT18PsysjcbaCIAhCrDh9DtRNjW46VaQQsSycuHgla0ybls+tt1ZTW9QbtRbZ4aRLeAvXbdSxhLdcgtl83kL3sGNU6gYqdEPQxw2kKhzJBiyB2kzcK8qzq0I6nCAIghBHlIJ7LodcS7xHMjoiloUTFx/JGgUl+Tx010RWzjOibSIdbxPOIj1v4dqqylnDcmrZ4iEu2ykddowiWiimJejjjlYVjrQfORCbiSmUP3UdzBGhLAiCkLQU5sJjH0n8okdavAcgCCFxaD9kWT3Frr3TqBYHESPni7RUuPMSwwP73J+gfxAyIvRO6VH5NGlDUHZoG0W0BrxIz1dOc6sqJ0VDKftoocy1H+9j1DMXIKTj+sNn5Vkblecegt+3d5W6W+d5jHHQASkKHrkO5k4La+iCIAhCAnBSRbxHMDpSWRaSkyyrZ+c+03+cFbkYtZXz4anVxi2iAUfkbBmRXKQ3kgXC1zGisTjQV+XZSu+winUglo/RqtSDDuO23SPXwTwRyoIgCEKMELEsJCdm574D26Gj+XgLbO+GJWEyrQyevtcQZw4dGVtGpDy+/sSlr2P4O24kOvWZhGo18eePHhg8br2YVx30kARBEAQhZJROoGX/Cxcu1GvXro33MIRkoqMZDu2DwjIoKo/aYbSGv6yDH79sVDjTU40qZ7C4C9welT/s+2Cw6f30YvXYLkd3UkILVro9jlHHBgDqmevzuJEcl/t5dhC+5WNgEDLS4fEbYfrkkHYhCIIgCMNQSq3TWi8c7XXiWRaSF3sndLYaQrmzFSx5Ea8smygF5yyEuinwlV9C22FITQleMEfS4+vLw9yj8rHqXtoo9ThGhy5FD/3f13HD8VL7wjimbZiXOljMFtZf+Kg0HBEEQRDig1SWheTELSMZS/7w76NI/wD85FX423pwOo0uRGOFCbrZJXAPqNAr9eFWlrWGQaexUvrJW6BEWlgLgiAIESbQyrJ4loXkxCsj2eVhPtbrf7sIkJEOd1wEn7oeciyGLcOZOHPOkImFlzoQTKFcVgRfuVOEsiAIghBfRCwLyYmPjGQs+WHHxgXDvGnwzP1w5gJD4PUPRqeRSSyIZF5yoO2tfaGHFlHWlsN/3Ab5kQs3EQRBEISQELEsCGFgyTSqzF+4BYrzjcQMZ4QbmQRCuGkW4QhcbwJtb+2N2QTmtNnw2ZuMaysIgiAI8UbEsiBEgNpy+Na9cNly0MS+yhxOZ0AIXeBGioFB4+ttF8Ldl48tH7ggCIKQ3MhHkiBEiIw0uG4lnDoLnv0jbNsLTofRETCUmLlgiHSaRaww/cmWLHjsBqiZFO8RCYIgCIInUlkWhAgzqdiwZXzqOijMMxb/RaKZyWhEo0NfNDH9yVNt8M27RSgLgiAIiUlYYlkptUoptVkp5VRKLXR7fKpS6qhSasPQv++HP1RBSB6UMjrNPXM/3HSOUV0eiHJqRqTSLEIhWM/0oMPwd6+YayzkG5cbi1EKgiAIQvCEa8P4ELgC+IGP53ZqreeGuX9BSGrSUuGCpXDqbPjV3+D19YZoTk2FlAhaM7w77nXrPON7HRsrhumZNo/nPh53TNtFdiZ87BJYWhf1oQmCIAhCWIQllrXWWwBUtA2ZgpDk5FrgtovgslPht/+Ef2yIrGiOZGfAUAjEMz0wCCrF8HTfcj7kZEd9WIIgCIIQNtFc4FehlHof6AIe11q/GcVjCUJSUJQPd10CV53uJpqdRuvscETzSK2vYyGU3Y/nq8W1cyhOryAH7rsSTqqI2ZAEQRAEIWxGFctKqdeBUh9PfUZr/cIImx0AJmutDyqlFgB/UErN1Fp3+dj/HcAdAJMnTw585IKQxJii+crTDNH8z42GPUFhVJuTEW/PdLfO45Ajn9QUw4py7UrITI/3KAVBEAQhOJSOQBisUuofwMNa67WhPG+ycOFCvXat35cIwpjkSA/8ZS289A70D4AjRpFzkcLdo9xFPhZnJ1VqO4U11Vx8Vj5lRfEeoSAIgiB4opRap7VeONrromLDUEoVA4e01g6lVCVQDTRG41iCMBYoyIFVK+DyU2HNFqPafODg/2/v7kPruus4jn8+TeKypObO2K5r07KuNBO6brZ1lLmCaH2q21jZQJioIPqP4GDCQKwFRUUQBiqoIKLiHxZF0KFsjq3D4kDmNp19mu3sgw99iK01Np2JdUv79Y9zYm7be253bJbfOTfvF1xufreh+eZLmvvpOd/zO9LkpNTTJc2r+CaP/RrX4RjW6WhonqX1axu699ZhLewdlwYrtIXd6HGpt//CW6VPjElnx2f1VukAgPq4orBs+x5JX5e0UNKjtndGxHslvU3SF2y/Ium8pI9HxOgVVwt0uO4uacNq6fabpIPHpMeeycJzRHZXwKoF54jswr2R7iWSpTvWS5s3TG0F18gfFdLbL40ckBYPZ4F5Ymx6DQBACzMyhjFTGMMALjV5TtrzJ+lXO6Vn90lyNqrRne+kMdujGlMBubs7+3jV9dLGddm+0v29s1vL/2UqIDcWSWMnpoMzAGBOSTqGAWDmdHdJa1dmj1cmpd2HpV/vyZ5fmsh20nh5MnvumjcdnhfFcY2r/4Lt2+bHmPo13nL3jFYi8jsQnsv+3p7ubH3zCukda6V1N9YkIDfra2RBefSYNDhEUAYAtEVYBmqkp1t6y43ZQ5JGz0j7j0i7D0m7Dkn/OJONaoSkf072a4UP6M8a1vi8hgY8fRFe8wmlUB6Kz0+H46552dc6l99AZOVQtuXbyiFpxRKp76oU3/0MmRjLjigPDmXPfQMEZgBAIcIyUGODA9l88+03Zevxf0sjo9LJ09KJ0YZOHh/WdScO6ND4Il0zeUKHNawz0dD5mA7IV/VIjfnZnPEbB6Rr3yAtGJAWDUorFnfYraibZ5T7GllQbl4DAHARwjLQQfqvzo7+rhyaeqUhnWoaOVgwxwPh2fELg3FfI1ufHScsAwBaIiwDnYyRgwu12h6urzG3ewIAaKtCm1ABmFHNIwcLlmXPIwey1+tu9Pil38fEWPY6AAAziLAM1EmZkNhu5KDupvZLnurF1H8MevvT1gUA6DiEZaBOyoTEwSWXjhf0NTrjTnVTwX/kgHTqCBfpAQBeM8wsA3XSHBLn+k012C8ZADALOLIM1E1zSGwsmrsh8eKLFzthFhsAUDmEZaBuCImdffEiAKBSCMtAnRASM5188SIAoFKYWQbqhJtqZNgvGQAwSwjLQJ0QEgEAmFWMYQAAAAAFCMsAAABAAcIyAAAAUICwDAAAABQgLAMAAAAFCMsAAABAAcIyAAAAUICwDAAAABQgLAMAAAAFCMsAAABAAcIyAAAAUICwDAAAABQgLAMAAAAFCMsAAABAAcIyAAAAUMARkbqG/7H9d0l/SfTlF0g6lehr1xH9Kod+lUO/yqFf5dCvcuhXOfSrnJT9uj4iFl7ukyoVllOy/duIuDV1HXVBv8qhX+XQr3LoVzn0qxz6VQ79KqcO/WIMAwAAAChAWAYAAAAKEJanfTt1ATVDv8qhX+XQr3LoVzn0qxz6VQ79Kqfy/WJmGQAAACjAkWUAAACgAGG5BdsP2g7bC1LXUmW2v2h7t+2dtp+wvSR1TVVm+yHb+/OePWz7mtQ1VZnt99t+wfZ525W+Ujol25tsv2j7oO1Pp66nymx/z/ZJ23tT11IHtpfZ3mH7D/m/xQdS11RltnttP2t7V96vz6euqQ5sd9n+ve1HUtdShLB8EdvLJL1H0l9T11IDD0XELRGxRtIjkj6buqCK2y5pdUTcIumPkrYkrqfq9kq6V9JTqQupKttdkr4p6X2SVkn6gO1VaauqtO9L2pS6iBqZlPRgRKySdJukT/Dz1dZ/JG2MiDdLWiNpk+3bEtdUBw9I2pe6iHYIy5f6qqRPSWKY+zIi4kzTsl/0rK2IeCIiJvPlbyQtTVlP1UXEvoh4MXUdFbde0sGIOBwRL0v6kaTNiWuqrIh4StJo6jrqIiJGIuL5/OOXlAWaobRVVVdk/pUve/IH74tt2F4q6U5J30ldSzuE5Sa2N0s6FhG7UtdSF7a/ZPuIpA+KI8tlfFTSY6mLQO0NSTrStD4qwgxeA7aXS1or6Zm0lVRbPlKwU9JJSdsjgn619zVlByjPpy6kne7UBcw2209Kuq7FH22V9BllIxjItetXRPwsIrZK2mp7i6T7JX1uVgusmMv1K/+crcpOb26bzdqq6NX0C0BatudL+omkT150RhEXiYhzktbk16Q8bHt1RDAj34LtuySdjIjf2X576nramXNhOSLe1ep12zdLukHSLttSdor8edvrI+Jvs1hipRT1q4Vtkn6hOR6WL9cv2x+RdJekdwb7Npb5+UJrxyQta1ovzV8DZoTtHmVBeVtE/DR1PXUREadt71A2I09Ybm2DpLtt3yGpV9KA7R9ExIcS13UJxjByEbEnIq6NiOURsVzZ6cx1czkoX47t4ablZkn7U9VSB7Y3KTvddHdETKSuBx3hOUnDtm+w/TpJ90n6eeKa0CGcHTn6rqR9EfGV1PVUne2FU7sc2b5a0rvF+2KhiNgSEUvzzHWfpF9WMShLhGVcmS/b3mt7t7LxFbYVau8bkl4vaXu+3d63UhdUZbbvsX1U0lslPWr78dQ1VU1+wej9kh5XdvHVjyPihbRVVZftH0p6WtKbbB+1/bHUNVXcBkkflrQx/521Mz8KiNYWS9qRvyc+p2xmubLboeHV4w5+AAAAQAGOLAMAAAAFCMsAAABAAcIyAAAAUICwDAAAABQgLAMAAAAFCMsAAABAAcIyAAAAUICwDAAAABT4L7W0p+pcJ6WgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(m, np.diag(v), data_x, data_y, x, \"bootstrapped_shared_NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(x, np.diag(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpl_keras",
   "language": "python",
   "name": "dpl_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
